{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'balance' from 'G:\\\\Python\\\\MarketDataEnrichment\\\\dataset_mngr\\\\balance.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "# import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import random as rd\n",
    "import itertools\n",
    "from datetime import datetime as dt\n",
    "\n",
    "# from pathlib import Path\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import matplotlib.pyplot as plt\n",
    "# from pprint import pprint\n",
    "import seaborn as sns\n",
    "# import statsmodels.api as sma\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold, TimeSeriesSplit\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "import joblib\n",
    "\n",
    "import sqlite_io as sio\n",
    "import add_indicators as indic\n",
    "import split_merge as sm\n",
    "import balance\n",
    "import lgbm_mngr\n",
    "# import model_mngr as modmgr\n",
    "\n",
    "# reload(modmgr)\n",
    "reload(balance)\n",
    "reload(lgbm_mngr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_DATA = \"C:\\\\Projets\\\\Data\"\n",
    "PATH_DATA = \"G:\\\\Python\\\\Data\"\n",
    "PATH_DB_FWK=PATH_DATA+\"\\\\sqlite\\\\dataset_market.db\"\n",
    "PATH_DB_STOCK=PATH_DATA+\"\\\\sqlite\\\\dataset_paris_stock_adjusted.db\"\n",
    "PATH_DATA_DTS=PATH_DATA+\"\\\\DTS_FULL\\\\\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONNECTION TO SQLITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"con_stock\" in locals():\n",
    "        sio.close_connection(con_stock)\n",
    "con_stock = sio.get_connection(str_db_path=PATH_DB_STOCK)\n",
    "\n",
    "if \"con_fwk\" in locals():\n",
    "        sio.close_connection(con_fwk)\n",
    "con_fwk = sio.get_connection(str_db_path=PATH_DB_FWK)\n",
    "\n",
    "my_session_maker = sessionmaker(bind=con_fwk)\n",
    "session=my_session_maker()\n",
    "\n",
    "table_stock=\"DS_PARIS_1D_ADJ_CLEAN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: SELECT CODE,OPEN_DATETIME, OPEN,HIGH,LOW,CLOSE,VOLUME FROM DS_PARIS_1D_ADJ_CLEAN can WHERE can.TIMEFRAME=1440 AND can.SK_SYMBOL IN (SELECT SK_SYMBOL FROM SYMBOL WHERE TRADABLE=1)   \n",
      "                         OPEN    HIGH     LOW   CLOSE  VOLUME\n",
      "CODE    OPEN_DATETIME                                        \n",
      "ABCA.PA 2000-01-03     1.0267  1.0267  1.0267  1.0267  3490.0\n",
      "        2000-01-04     1.0215  1.0215  1.0215  1.0215  4250.0\n",
      "        2000-01-05     1.0382  1.0382  1.0382  1.0382  5960.0\n"
     ]
    }
   ],
   "source": [
    "dts_name=\"PARIS_TREND_1D_20D_V3\"\n",
    "multi_symbol=\"PARIS_STOCK\"\n",
    "\n",
    "df_base=sio.get_candles_to_df(session=session,con=con_stock, target_table=table_stock,tradable=True)\n",
    "print(df_base[0:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work=pd.DataFrame()\n",
    "for code_value in df_base.index.get_level_values('CODE').unique():\n",
    "    sub_df=df_base[df_base.index.get_level_values('CODE') == code_value]\n",
    "    df_work_tmp = indic.add_indicators_to_df(con=con_fwk, df_in=sub_df, dts_name=dts_name,symbol=multi_symbol)\n",
    "    df_work = pd.concat([df_work, df_work_tmp])\n",
    "    \n",
    "df_work.sort_index(inplace=True)\n",
    "df_work.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_base.index.get_level_values('CODE').unique())\n",
    "# df_work[10000:10010]\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# print(df_work.describe())\n",
    "\n",
    "df_work.round(5).to_csv(\n",
    "    PATH_DATA_DTS+\"PARIS_TREND_1D_20D_V3_BASE_c\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " FROM HERE TO LOAD THE BASE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>sma20</th>\n",
       "      <th>pos_sma20</th>\n",
       "      <th>sma50</th>\n",
       "      <th>sma200</th>\n",
       "      <th>pos_sma50</th>\n",
       "      <th>...</th>\n",
       "      <th>perf_atr14_5d</th>\n",
       "      <th>perf_adx14_5d</th>\n",
       "      <th>perf_adx14_neg_5d</th>\n",
       "      <th>perf_adx14_pos_5d</th>\n",
       "      <th>perf_adx14_dif_5d</th>\n",
       "      <th>avg_vol50</th>\n",
       "      <th>pos_avg_vol50</th>\n",
       "      <th>perf_williamsr_14_5d</th>\n",
       "      <th>williamsr_14_perf_10d</th>\n",
       "      <th>trix12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPEN_DATETIME</th>\n",
       "      <th>CODE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-04-26</th>\n",
       "      <th>AB.PA</th>\n",
       "      <td>12.98</td>\n",
       "      <td>12.98</td>\n",
       "      <td>12.20</td>\n",
       "      <td>12.68</td>\n",
       "      <td>62866.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-27</th>\n",
       "      <th>AB.PA</th>\n",
       "      <td>12.74</td>\n",
       "      <td>12.83</td>\n",
       "      <td>12.61</td>\n",
       "      <td>12.70</td>\n",
       "      <td>22370.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-28</th>\n",
       "      <th>AB.PA</th>\n",
       "      <td>12.70</td>\n",
       "      <td>12.70</td>\n",
       "      <td>12.41</td>\n",
       "      <td>12.50</td>\n",
       "      <td>8211.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-29</th>\n",
       "      <th>AB.PA</th>\n",
       "      <td>12.60</td>\n",
       "      <td>12.65</td>\n",
       "      <td>12.46</td>\n",
       "      <td>12.64</td>\n",
       "      <td>4676.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <th>AB.PA</th>\n",
       "      <td>12.63</td>\n",
       "      <td>12.71</td>\n",
       "      <td>12.55</td>\n",
       "      <td>12.65</td>\n",
       "      <td>4470.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      OPEN   HIGH    LOW  CLOSE   VOLUME  sma20  pos_sma20  \\\n",
       "OPEN_DATETIME CODE                                                           \n",
       "2010-04-26    AB.PA  12.98  12.98  12.20  12.68  62866.0    NaN        NaN   \n",
       "2010-04-27    AB.PA  12.74  12.83  12.61  12.70  22370.0    NaN        NaN   \n",
       "2010-04-28    AB.PA  12.70  12.70  12.41  12.50   8211.0    NaN        NaN   \n",
       "2010-04-29    AB.PA  12.60  12.65  12.46  12.64   4676.0    NaN        NaN   \n",
       "2010-04-30    AB.PA  12.63  12.71  12.55  12.65   4470.0    NaN        NaN   \n",
       "\n",
       "                     sma50  sma200  pos_sma50  ...  perf_atr14_5d  \\\n",
       "OPEN_DATETIME CODE                             ...                  \n",
       "2010-04-26    AB.PA    NaN     NaN        NaN  ...            NaN   \n",
       "2010-04-27    AB.PA    NaN     NaN        NaN  ...            NaN   \n",
       "2010-04-28    AB.PA    NaN     NaN        NaN  ...            NaN   \n",
       "2010-04-29    AB.PA    NaN     NaN        NaN  ...            NaN   \n",
       "2010-04-30    AB.PA    NaN     NaN        NaN  ...            NaN   \n",
       "\n",
       "                     perf_adx14_5d  perf_adx14_neg_5d  perf_adx14_pos_5d  \\\n",
       "OPEN_DATETIME CODE                                                         \n",
       "2010-04-26    AB.PA            NaN                NaN                NaN   \n",
       "2010-04-27    AB.PA            NaN                NaN                NaN   \n",
       "2010-04-28    AB.PA            NaN                NaN                NaN   \n",
       "2010-04-29    AB.PA            NaN                NaN                NaN   \n",
       "2010-04-30    AB.PA            NaN                NaN                NaN   \n",
       "\n",
       "                     perf_adx14_dif_5d  avg_vol50  pos_avg_vol50  \\\n",
       "OPEN_DATETIME CODE                                                 \n",
       "2010-04-26    AB.PA                NaN        NaN            NaN   \n",
       "2010-04-27    AB.PA                NaN        NaN            NaN   \n",
       "2010-04-28    AB.PA                NaN        NaN            NaN   \n",
       "2010-04-29    AB.PA                NaN        NaN            NaN   \n",
       "2010-04-30    AB.PA                NaN        NaN            NaN   \n",
       "\n",
       "                     perf_williamsr_14_5d  williamsr_14_perf_10d  trix12  \n",
       "OPEN_DATETIME CODE                                                        \n",
       "2010-04-26    AB.PA                   NaN                    NaN     NaN  \n",
       "2010-04-27    AB.PA                   NaN                    NaN     NaN  \n",
       "2010-04-28    AB.PA                   NaN                    NaN     NaN  \n",
       "2010-04-29    AB.PA                   NaN                    NaN     NaN  \n",
       "2010-04-30    AB.PA                   NaN                    NaN     NaN  \n",
       "\n",
       "[5 rows x 159 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dts_name=\"PARIS_TREND_1D_20D_V3\"\n",
    "# dts_name=\"PARIS_TREND_1D_50D_V1\"\n",
    "multi_symbol=\"PARIS_STOCK\"\n",
    "\n",
    "df_work=pd.read_csv(PATH_DATA_DTS+dts_name+\"_BASE.zip\",sep=\",\",index_col=[\"OPEN_DATETIME\",\"CODE\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "df_work.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  extract 100 samples from 1000th line of COD AI.PA and write in a file for analyse\n",
    "df_work.loc[(df_work.index.get_level_values('CODE') == \"AI.PA\")].iloc[5500:5600].to_csv(\n",
    "    PATH_DATA_DTS+dts_name+\"_BASE_AI_SAMPLES.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benoit\\AppData\\Local\\Temp\\ipykernel_16596\\4180702997.py:2: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df_work[\"lab_perf_5d\"]=df_work.groupby(\"CODE\")[\"CLOSE\"].pct_change(periods=5).shift(-5)\n"
     ]
    }
   ],
   "source": [
    "# add the column lab_perf_5d with this formula $$CLOSE$$.pct_change(periods=5).shift(-5)\n",
    "df_work[\"lab_perf_5d\"]=df_work.groupby(\"CODE\")[\"CLOSE\"].pct_change(periods=5).shift(-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CNV.PA'], dtype='object', name='CODE')\n"
     ]
    }
   ],
   "source": [
    "df_check=df_work[df_work['stdev20_1d'] > 100]\n",
    "# df_check=df_check[df_check['ret_1d'] <= 2]\n",
    "print(df_check.index.get_level_values('CODE').unique())\n",
    "# print(df_check.info())\n",
    "# df_check[df_check.index.get_level_values('CODE')=='AKW.PA']\n",
    "# df_check=df_work[df_work.index.get_level_values('CODE')=='AI.PA']\n",
    "# CATG\n",
    "# mask = df_work['stdev20_1d'] > 100\n",
    "# df_work.drop(df_work[mask].index, inplace=True)\n",
    "# # print 10 first lines of df_check with code=AAA.PA \n",
    "# code=\"CBR.PA\"#'CBE.PA', 'CNV.PA'\n",
    "# print(df_check[df_check.index.get_level_values('CODE')==code][0:20])\n",
    "\n",
    "# # print the graph of DGE.PA with candles mode\n",
    "# df_work[df_work.index.get_level_values('CODE')==code].plot(y=[\"OPEN\",\"HIGH\",\"LOW\",\"CLOSE\"],kind='line',figsize=(15, 10))  \n",
    "# plt.show()\n",
    "\n",
    "# drop lines where CODE=CBE.PA\n",
    "# df_work.drop(df_work[df_work.index.get_level_values('CODE') == \"CBE.PA\"].index, inplace=True)\n",
    "# df_work.round(5).to_csv(\n",
    "#     PATH_DATA_DTS+\"PARIS_TREND_1D_20D_V3_BASE_d\", sep=\",\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "           LABEL\n",
      "0  lab_perf_250d\n",
      "1   lab_perf_20d\n",
      "2   lab_perf_50d\n",
      "3   lab_perf_10d\n",
      "4    lab_perf_5d\n"
     ]
    }
   ],
   "source": [
    "print(df_work.shape)\n",
    "df_work = indic.drop_indicators_by_type(\n",
    "    con=con_fwk, df_in=df_work, dts_name=dts_name, symbol=multi_symbol, ind_type=0)\n",
    "print(df_work.shape)\n",
    "list_label = indic.get_ind_list_by_type_for_dts(\n",
    "    con=con_fwk, dts_name=dts_name, symbol_code=multi_symbol, ind_type=2)\n",
    "# print(type(list_label))\n",
    "print(list_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  prepare the dataframe for the indictor analysis\n",
    "lab_split='lab_perf_50d'\n",
    "df_work['CODE'] = df_work.index.get_level_values('CODE')\n",
    "df_work=df_work.droplevel('CODE')\n",
    "df_work.sort_index(inplace=True)\n",
    "\n",
    "df_split=sm.split_df_by_label_strat(\n",
    "        df_in=df_work, list_label=[lab_split], split_timeframe=\"M\",random_split=False,split_strat=(80,10,10))\n",
    "\n",
    "df_class = df_split['df_'+lab_split+'_train']\n",
    "df_class.sort_index(inplace=True)\n",
    "\n",
    "for label in list_label['LABEL']:\n",
    "    df_class = balance.add_class_by_lab_nb_lines(\n",
    "        df_in=df_class, str_label=label, nb_class=10, bool_replace_label=False)\n",
    "    print(df_class[label+\"_class\"].value_counts())\n",
    "# df_work.sort_index(inplace=True)\n",
    "# df_class=balance.add_class_by_lab_nb_lines(df_in=df_work,str_label=\"lab_perf_20d\",nb_class=5,bool_replace_label=False)\n",
    "# df_class=balance.add_class_by_lab_nb_lines(df_in=df_class,str_label=\"lab_perf_50d\",nb_class=5,bool_replace_label=False)\n",
    "df_class.sort_index(inplace=True)\n",
    "#  count lines per class in lab_perf_20d\n",
    "# print(df_class['lab_perf_20d_class'].value_counts())\n",
    "# print(df_class['lab_perf_50d_class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SAVE !!!!##############\n",
    "df_class.round(5).to_csv(\n",
    "    PATH_DATA_DTS+\"PARIS_TREND_1D_20D_V3_CLASS_TRAIN\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis of the datafarme with some indicators to find a filter\n",
    "list_indic_test=['pos_sma20','pos_sma50','pos_sma200','pos_sma20_50','pos_sma50_200',\n",
    "'pos_sma20_200','perf_sma200_10d','pos_ema20','pos_ema50','pos_ema200','pos_ema20_50',\n",
    "'pos_ema50_200','pos_ema20_200','perf_ema200_10d','ret_5d','aroon14_dif','macd_dif',\n",
    "'stdev20_1d','pos_stdev20_sma20','stoch14_dif','adx14_dif','trix12']\n",
    "\n",
    "for label in list_label['LABEL']:#list_label['LABEL']:\n",
    "    df_indic_test=df_class[label+\"_class\"].value_counts()\n",
    "    df_indic_test.sort_index(inplace=True)\n",
    "    # convert to dataframe\n",
    "    df_indic_test=pd.DataFrame(df_indic_test)\n",
    "    print(type(df_indic_test))\n",
    "    # print(df_class[df_class['rsi14'] > 50][label+\"_class\"].value_counts().sort_index())\n",
    "    df_indic_test['rsi14']=df_class[df_class['rsi14'] > 50][label+\"_class\"].value_counts().sort_index()\n",
    "    df_indic_test['williamsr_14']=df_class[df_class['williamsr_14'] > -50][label+\"_class\"].value_counts().sort_index()\n",
    "    for indic_name in list_indic_test:\n",
    "        print(indic_name)\n",
    "        df_indic_test[indic_name]=df_class[df_class[indic_name] > 0][label+'_class'].value_counts().sort_index()\n",
    "    \n",
    "    df_indic_test.round(5).to_csv(PATH_DATA_DTS+\"PARIS_TREND_1D_20D_indic_test_\"+label, sep=\",\")\n",
    "        \n",
    "# print(df_indic_test)\n",
    "\n",
    "# print nb lines with pos_sma200>0 and pos_sma200<0\n",
    "# print(df_class[df_class['pos_sma50_200'] > 0].shape)\n",
    "# print(df_class[df_class['pos_sma50_200'] < 0].shape)\n",
    "\n",
    "# # print nb linesper class with pos_sma200>0 and pos_sma200<0\n",
    "# print(df_class[df_class['pos_sma50_200'] > 0]['lab_perf_20d_class'].value_counts().sort_index())\n",
    "# print(df_class[df_class['pos_sma50_200'] < 0]['lab_perf_20d_class'].value_counts().sort_index())\n",
    "\n",
    "# print(df_class[df_class['pos_sma50_200'] > 0]['lab_perf_50d_class'].value_counts().sort_index())\n",
    "# print(df_class[df_class['pos_sma50_200'] < 0]['lab_perf_50d_class'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1299247, 138)\n",
      "(1299247, 117)\n"
     ]
    }
   ],
   "source": [
    "#  drop label lab_perf_250d and lab_perf_10d\n",
    "# df_work.drop(columns=['lab_perf_250d','lab_perf_10d'],inplace=True)\n",
    "list_rem=[\"lab_perf_250d\",\"lab_perf_125d\",\"pos_ema5_20\",\"pos_ema10_20\",\"perf_ema20_10d\"\n",
    ",\"perf_ema50_5d\",\"pos_ema5_50\",\"perf_ema20_5d\",\"perf_ema10_5d\",\"pos_ema10_50\",\"pos_ema20_50\"\n",
    ",\"perf_ema10_10d\",\"perf_ema200_10d\",\"pos_ema20_200\",\"perf_ema50_10d\",\"pos_ema5_10\",\"pos_ema50\"\n",
    ",\"perf_ema200_5d\",\"pos_ema5_200\",\"pos_ema10_200\",\"pos_ema200\",\"pos_ema20\"]\n",
    "# df_work.drop(columns=['lab_perf_250d'],inplace=True)\n",
    "\n",
    "# TODO MAKE A FUNCTION FOR THIS\n",
    "df_filtered = df_work.copy()\n",
    "list_feat = df_filtered.columns.values.tolist()\n",
    "print(df_filtered.shape)\n",
    "\n",
    "for item in list_rem:\n",
    "    if item in list_feat:\n",
    "        df_filtered.drop(columns=[item],inplace=True)\n",
    "print(df_filtered.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  filter the dataframe with pos_sma20_200>=0\n",
    "df_filtered=df_filtered[df_filtered['pos_sma20_200']>=0]\n",
    "df_filtered.sort_index(inplace=True)\n",
    "df_filtered.round(5).to_csv(\n",
    "    PATH_DATA_DTS+\"PARIS_TREND_1D_20D_V4_filtered\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start here for new datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(716338, 117)\n"
     ]
    }
   ],
   "source": [
    "# Start here for new datasets\n",
    "dts_name=\"PARIS_TREND_1D_20D_V4\"\n",
    "df_filtered=pd.read_csv(PATH_DATA_DTS+dts_name+\"_filtered.zip\",sep=\",\",index_col=[\"OPEN_DATETIME\",\"CODE\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "print(df_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME', 'pos_sma20', 'pos_sma50', 'pos_sma200', 'pos_sma50_200', 'pos_sma20_50', 'rsi14', 'sma5_rsi14', 'sma20_rsi14', 'pos_bb20_hi', 'pos_bb20_lo', 'ret_1d', 'ret_5d', 'pos_top20', 'pos_top50', 'pos_bot20', 'pos_bot50', 'aroon14_up', 'aroon14_down', 'aroon14_dif', 'macd_dif', 'pos_top_200', 'pos_bot_200', 'stdev20_1d', 'stdev20_sma5', 'pos_stdev20_sma5', 'stdev20_sma20', 'pos_stdev20_sma20', 'pos_rsi14_sma5', 'pos_rsi14_sma20', 'pos_rsi14_sma5_20', 'lab_perf_20d', 'lab_perf_50d', 'stoch14', 'stoch14_signal', 'stoch14_dif', 'adx14', 'adx14_neg', 'adx14_pos', 'adx14_dif', 'pos_avg_vol14', 'tr_atr14', 'pos_sma20_200', 'williamsr_14', 'perf_sma_50_5d', 'perf_sma_200_5d', 'pos_sma10', 'pos_sma5', 'perf_sma_20_5d', 'perf_sma_10_5d', 'lab_perf_10d', 'perf_sma5_5d', 'perf_pos_sma10_10d', 'perf_sma10_5d', 'perf_sma10_10d', 'perf_pos_sma20_10d', 'perf_sma20_5d', 'perf_sma20_10d', 'perf_pos_sma50_10d', 'perf_sma50_5d', 'perf_sma50_10d', 'perf_pos_sma200_10d', 'perf_sma200_5d', 'perf_sma200_10d', 'pos_sma5_10', 'pos_sma5_20', 'pos_sma5_50', 'pos_sma5_200', 'pos_sma10_20', 'pos_sma10_50', 'pos_sma10_200', 'pos_ema5', 'perf_ema5_5d', 'pos_ema10', 'perf_pos_ema10_5d', 'perf_pos_ema10_10d', 'perf_pos_ema20_5d', 'perf_pos_ema20_10d', 'pos_ema50_perf_5d', 'pos_ema50_perf_10d', 'perf_pos_ema200_5d', 'perf_pos_ema200_10d', 'pos_ema50_200', 'perf_rsi14_5d', 'perf_rsi14_10d', 'pos_bb20_hi_lag_5d', 'pos_bb20_lo_lag_5d', 'ret_10d', 'ret_20d', 'pos_top20_lag_5d', 'pos_top50_lag_10d', 'pos_bot20_lag_5d', 'pos_bot50_lag_10d', 'pos_top20_lag_20d', 'pos_bot20_lag_20d', 'aroon14_up_lag_5d', 'aroon14_down_lag_5d', 'aroon14_dif_lag_5d', 'macd_fast', 'macd_slow', 'perf_stoch14_5d', 'perf_stoch14_signal_5d', 'perf_stoch14_dif_5d', 'perf_atr14_5d', 'perf_adx14_5d', 'perf_adx14_neg_5d', 'perf_adx14_pos_5d', 'perf_adx14_dif_5d', 'pos_avg_vol50', 'perf_williamsr_14_5d', 'williamsr_14_perf_10d', 'trix12', 'lab_perf_5d']\n"
     ]
    }
   ],
   "source": [
    "# print list of columns\n",
    "print(df_filtered.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>pos_sma20</th>\n",
       "      <th>pos_sma50</th>\n",
       "      <th>pos_sma200</th>\n",
       "      <th>pos_sma50_200</th>\n",
       "      <th>pos_sma20_50</th>\n",
       "      <th>...</th>\n",
       "      <th>perf_adx14_5d</th>\n",
       "      <th>perf_adx14_neg_5d</th>\n",
       "      <th>perf_adx14_pos_5d</th>\n",
       "      <th>perf_adx14_dif_5d</th>\n",
       "      <th>pos_avg_vol50</th>\n",
       "      <th>perf_williamsr_14_5d</th>\n",
       "      <th>williamsr_14_perf_10d</th>\n",
       "      <th>trix12</th>\n",
       "      <th>lab_perf_5d</th>\n",
       "      <th>CODE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPEN_DATETIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1991-10-09</th>\n",
       "      <td>0.703</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.703</td>\n",
       "      <td>1792.0</td>\n",
       "      <td>-0.03047</td>\n",
       "      <td>-0.02040</td>\n",
       "      <td>0.12800</td>\n",
       "      <td>0.15150</td>\n",
       "      <td>0.01038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03223</td>\n",
       "      <td>2.51985</td>\n",
       "      <td>-2.51986</td>\n",
       "      <td>-5.03971</td>\n",
       "      <td>0.15837</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.07907</td>\n",
       "      <td>-0.03001</td>\n",
       "      <td>BOI.PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-10-10</th>\n",
       "      <td>0.703</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.703</td>\n",
       "      <td>864.0</td>\n",
       "      <td>-0.02844</td>\n",
       "      <td>-0.02040</td>\n",
       "      <td>0.12678</td>\n",
       "      <td>0.15025</td>\n",
       "      <td>0.00827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>10.51980</td>\n",
       "      <td>-10.51981</td>\n",
       "      <td>-21.03961</td>\n",
       "      <td>0.07732</td>\n",
       "      <td>-31.91489</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.10139</td>\n",
       "      <td>-0.01508</td>\n",
       "      <td>BOI.PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-10-11</th>\n",
       "      <td>0.703</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.703</td>\n",
       "      <td>17920.0</td>\n",
       "      <td>-0.02578</td>\n",
       "      <td>-0.02040</td>\n",
       "      <td>0.12556</td>\n",
       "      <td>0.14900</td>\n",
       "      <td>0.00552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11071</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.57693</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-5.48523</td>\n",
       "      <td>-0.11993</td>\n",
       "      <td>-0.01508</td>\n",
       "      <td>BOI.PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-10-14</th>\n",
       "      <td>0.703</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.703</td>\n",
       "      <td>13984.0</td>\n",
       "      <td>-0.02311</td>\n",
       "      <td>-0.02033</td>\n",
       "      <td>0.12434</td>\n",
       "      <td>0.14768</td>\n",
       "      <td>0.00284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10024</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.20180</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-10.97046</td>\n",
       "      <td>-0.13459</td>\n",
       "      <td>-0.00754</td>\n",
       "      <td>BOI.PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-10-15</th>\n",
       "      <td>0.703</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.703</td>\n",
       "      <td>2208.0</td>\n",
       "      <td>-0.02105</td>\n",
       "      <td>-0.02033</td>\n",
       "      <td>0.12316</td>\n",
       "      <td>0.14647</td>\n",
       "      <td>0.00074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09098</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.18969</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-10.97046</td>\n",
       "      <td>-0.14550</td>\n",
       "      <td>-0.01508</td>\n",
       "      <td>BOI.PA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                OPEN   HIGH    LOW  CLOSE   VOLUME  pos_sma20  pos_sma50  \\\n",
       "OPEN_DATETIME                                                              \n",
       "1991-10-09     0.703  0.703  0.703  0.703   1792.0   -0.03047   -0.02040   \n",
       "1991-10-10     0.703  0.703  0.703  0.703    864.0   -0.02844   -0.02040   \n",
       "1991-10-11     0.703  0.703  0.703  0.703  17920.0   -0.02578   -0.02040   \n",
       "1991-10-14     0.703  0.703  0.703  0.703  13984.0   -0.02311   -0.02033   \n",
       "1991-10-15     0.703  0.703  0.703  0.703   2208.0   -0.02105   -0.02033   \n",
       "\n",
       "               pos_sma200  pos_sma50_200  pos_sma20_50  ...  perf_adx14_5d  \\\n",
       "OPEN_DATETIME                                           ...                  \n",
       "1991-10-09        0.12800        0.15150       0.01038  ...        0.03223   \n",
       "1991-10-10        0.12678        0.15025       0.00827  ...        0.12260   \n",
       "1991-10-11        0.12556        0.14900       0.00552  ...        0.11071   \n",
       "1991-10-14        0.12434        0.14768       0.00284  ...        0.10024   \n",
       "1991-10-15        0.12316        0.14647       0.00074  ...        0.09098   \n",
       "\n",
       "               perf_adx14_neg_5d  perf_adx14_pos_5d  perf_adx14_dif_5d  \\\n",
       "OPEN_DATETIME                                                            \n",
       "1991-10-09               2.51985           -2.51986           -5.03971   \n",
       "1991-10-10              10.51980          -10.51981          -21.03961   \n",
       "1991-10-11              -0.00001           -0.00001            0.00000   \n",
       "1991-10-14              -0.00001           -0.00001            0.00000   \n",
       "1991-10-15              -0.00001           -0.00001            0.00000   \n",
       "\n",
       "               pos_avg_vol50  perf_williamsr_14_5d  williamsr_14_perf_10d  \\\n",
       "OPEN_DATETIME                                                               \n",
       "1991-10-09           0.15837               0.00000                0.00000   \n",
       "1991-10-10           0.07732             -31.91489                0.00000   \n",
       "1991-10-11           1.57693               0.00000               -5.48523   \n",
       "1991-10-14           1.20180               0.00000              -10.97046   \n",
       "1991-10-15           0.18969               0.00000              -10.97046   \n",
       "\n",
       "                trix12  lab_perf_5d    CODE  \n",
       "OPEN_DATETIME                                \n",
       "1991-10-09    -0.07907     -0.03001  BOI.PA  \n",
       "1991-10-10    -0.10139     -0.01508  BOI.PA  \n",
       "1991-10-11    -0.11993     -0.01508  BOI.PA  \n",
       "1991-10-14    -0.13459     -0.00754  BOI.PA  \n",
       "1991-10-15    -0.14550     -0.01508  BOI.PA  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered['CODE'] = df_filtered.index.get_level_values('CODE')\n",
    "df_filtered=df_filtered.droplevel('CODE')\n",
    "df_filtered.sort_index(inplace=True)\n",
    "df_filtered.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected: df_selected.shape=(486879, 118) valid: df_valid.shape=(102506, 118) confirm: df_confirm.shape=(120468, 118)\n"
     ]
    }
   ],
   "source": [
    "label = \"lab_perf_20d\"\n",
    "# algo_studied = \"XG_BOOST_CLASS\"\n",
    "dts_name=\"PARIS_TREND_1D_20D_V4\"\n",
    "\n",
    "# df_work_lab = indic.drop_indicators_not_selected(con=con_fwk, df_in=df_work, dts_name=dts_name, symbol=multi_symbol,label=lab_studied,algo=algo_studied)\n",
    "\n",
    "df_split=sm.split_df_by_label_strat(\n",
    "    df_in=df_filtered, list_label=[label], split_timeframe=\"M\",random_split=False,split_strat=(80,10,10))\n",
    "df_selected = df_split['df_'+label+'_train']\n",
    "df_valid = df_split['df_'+label+'_valid']\n",
    "df_confirm = df_split['df_'+label+'_confirm']\n",
    "df_selected.sort_index(inplace=True)\n",
    "df_valid.sort_index(inplace=True)\n",
    "df_confirm.sort_index(inplace=True)\n",
    "\n",
    "print(f\"selected: {df_selected.shape=} valid: {df_valid.shape=} confirm: {df_confirm.shape=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       min      max\n",
      "lab_perf_5d_class                  \n",
      "0                 -0.78866 -0.03894\n",
      "1                 -0.03893 -0.02209\n",
      "2                 -0.02208 -0.01198\n",
      "3                 -0.01197 -0.00437\n",
      "4                 -0.00436  0.00110\n",
      "5                  0.00111  0.00816\n",
      "6                  0.00817  0.01667\n",
      "7                  0.01668  0.02816\n",
      "8                  0.02817  0.04797\n",
      "9                  0.04798  2.64539\n"
     ]
    }
   ],
   "source": [
    "label = \"lab_perf_5d\"\n",
    "df_class=balance.add_class_by_lab_nb_lines(df_in=df_selected,str_label=label,nb_class=10,bool_replace_label=False)\n",
    "min_max_lab_by_class = df_class.groupby(label+'_class')[label].agg(['min', 'max'])\n",
    "print(min_max_lab_by_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"lab_perf_20d\"\n",
    "df_class=balance.add_class_by_lab_nb_lines(df_in=df_selected,str_label=label,nb_class=5,bool_replace_label=False)\n",
    "df_class.sort_index(inplace=True)\n",
    "# categ_5={0:[-1,-0.02209],1:[-0.02209,-0.00437],2:[-0.00437,0.00816],3:[0.00816,0.02816],4:[0.02816,5]}\n",
    "# categ_10={0:[-1,-0.03071],1:[-0.03071,-0.00522],2:[-0.00522,0.01406],3:[0.01406,0.04314],4:[0.04314,5]}\n",
    "categ_20={0:[-1,-0.04141],1:[-0.04141,-0.00522],2:[-0.00522,0.02439],3:[0.02439,0.06687],4:[0.06687,5]}\n",
    "# categ_50={0:[-1,-0.05826],1:[-0.05826,0.00124],2:[0.00124,0.05301],3:[0.05301,0.12161],4:[0.12161,5]}\n",
    "df_class_val=balance.add_lab_by_class(df_in=df_valid,str_label=label, categ=categ_20,bool_replace_label=False) # categ\n",
    "df_class_val.sort_index(inplace=True)\n",
    "df_class_conf=balance.add_lab_by_class(df_in=df_confirm,str_label=label, categ=categ_20,bool_replace_label=False) # categ\n",
    "df_class_conf.sort_index(inplace=True)\n",
    "print(df_class.loc[:, label].dropna().iloc[[0, -1]])\n",
    "print(df_class_val.loc[:, label].dropna().iloc[[0, -1]])\n",
    "print(df_class_conf.loc[:, label].dropna().iloc[[0, -1]])\n",
    "# df_class_clean=df_class.drop(['OPEN','HIGH','LOW','CLOSE','VOLUME','lab_perf_125d','lab_perf_20d','lab_perf_50d'],axis=1)\n",
    "data = df_class[label]\n",
    "print(data.value_counts().sort_index())\n",
    "data_val = df_class_val[label]\n",
    "print(data_val.value_counts().sort_index())\n",
    "data_conf = df_class_conf[label]\n",
    "print(data_conf.value_counts().sort_index())\n",
    "# min_max_lab_by_class = df_class.groupby(label+'_class')[label].agg(['min', 'max'])\n",
    "# print(min_max_lab_by_class)\n",
    "\n",
    "#                         min      max\n",
    "# lab_perf_20d_class                  \n",
    "# 0                  -0.87743 -0.05172\n",
    "# 1                  -0.05171 -0.00868\n",
    "# 2                  -0.00867  0.02272\n",
    "# 3                   0.02273  0.07058\n",
    "# 4                   0.07059  3.82176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected.round(5).to_pickle(PATH_DATA+\"\\DTS_FULL\\PARIS_TREND_1D_V4_TRAIN.pkl\")\n",
    "df_valid.round(5).to_pickle(PATH_DATA+\"\\DTS_FULL\\PARIS_TREND_1D_V4_VAL.pkl\")\n",
    "df_confirm.round(5).to_pickle(PATH_DATA+\"\\DTS_FULL\\PARIS_TREND_1D_V4_CONF.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(486879, 118)\n",
      "['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME', 'pos_sma20', 'pos_sma50', 'pos_sma200', 'pos_sma50_200', 'pos_sma20_50', 'rsi14', 'sma5_rsi14', 'sma20_rsi14', 'pos_bb20_hi', 'pos_bb20_lo', 'ret_1d', 'ret_5d', 'pos_top20', 'pos_top50', 'pos_bot20', 'pos_bot50', 'aroon14_up', 'aroon14_down', 'aroon14_dif', 'macd_dif', 'pos_top_200', 'pos_bot_200', 'stdev20_1d', 'stdev20_sma5', 'pos_stdev20_sma5', 'stdev20_sma20', 'pos_stdev20_sma20', 'pos_rsi14_sma5', 'pos_rsi14_sma20', 'pos_rsi14_sma5_20', 'lab_perf_20d', 'lab_perf_50d', 'stoch14', 'stoch14_signal', 'stoch14_dif', 'adx14', 'adx14_neg', 'adx14_pos', 'adx14_dif', 'pos_avg_vol14', 'tr_atr14', 'pos_sma20_200', 'williamsr_14', 'perf_sma_50_5d', 'perf_sma_200_5d', 'pos_sma10', 'pos_sma5', 'perf_sma_20_5d', 'perf_sma_10_5d', 'lab_perf_10d', 'perf_sma5_5d', 'perf_pos_sma10_10d', 'perf_sma10_5d', 'perf_sma10_10d', 'perf_pos_sma20_10d', 'perf_sma20_5d', 'perf_sma20_10d', 'perf_pos_sma50_10d', 'perf_sma50_5d', 'perf_sma50_10d', 'perf_pos_sma200_10d', 'perf_sma200_5d', 'perf_sma200_10d', 'pos_sma5_10', 'pos_sma5_20', 'pos_sma5_50', 'pos_sma5_200', 'pos_sma10_20', 'pos_sma10_50', 'pos_sma10_200', 'pos_ema5', 'perf_ema5_5d', 'pos_ema10', 'perf_pos_ema10_5d', 'perf_pos_ema10_10d', 'perf_pos_ema20_5d', 'perf_pos_ema20_10d', 'pos_ema50_perf_5d', 'pos_ema50_perf_10d', 'perf_pos_ema200_5d', 'perf_pos_ema200_10d', 'pos_ema50_200', 'perf_rsi14_5d', 'perf_rsi14_10d', 'pos_bb20_hi_lag_5d', 'pos_bb20_lo_lag_5d', 'ret_10d', 'ret_20d', 'pos_top20_lag_5d', 'pos_top50_lag_10d', 'pos_bot20_lag_5d', 'pos_bot50_lag_10d', 'pos_top20_lag_20d', 'pos_bot20_lag_20d', 'aroon14_up_lag_5d', 'aroon14_down_lag_5d', 'aroon14_dif_lag_5d', 'macd_fast', 'macd_slow', 'perf_stoch14_5d', 'perf_stoch14_signal_5d', 'perf_stoch14_dif_5d', 'perf_atr14_5d', 'perf_adx14_5d', 'perf_adx14_neg_5d', 'perf_adx14_pos_5d', 'perf_adx14_dif_5d', 'pos_avg_vol50', 'perf_williamsr_14_5d', 'williamsr_14_perf_10d', 'trix12', 'lab_perf_5d', 'CODE']\n"
     ]
    }
   ],
   "source": [
    "list_feat = df_selected.columns.values.tolist()\n",
    "# list_feat.remove(label)\n",
    "# df_x_train, col_y_train = sm.split_df_x_y(\n",
    "#     df_in=df_class, list_features=list_feat, str_label=label, drop_na=True)\n",
    "# df_x_val, col_y_val = sm.split_df_x_y(\n",
    "#     df_in=df_class_val, list_features=list_feat, str_label=label, drop_na=True)\n",
    "# df_x_conf, col_y_conf = sm.split_df_x_y(\n",
    "#     df_in=df_class_conf, list_features=list_feat, str_label=label, drop_na=True)\n",
    "\n",
    "print(df_selected.shape)\n",
    "print(list_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(486879, 118)\n",
      "(102506, 118)\n",
      "(120468, 118)\n"
     ]
    }
   ],
   "source": [
    "dts_name=\"PARIS_TREND_1D_V4\"\n",
    "multi_symbol=\"PARIS_STOCK\"\n",
    "label = \"lab_perf_20d\"\n",
    "\n",
    "# df_class=pd.read_csv(PATH_DATA_DTS+dts_name+\"_TRAIN.zip\",sep=\",\",index_col=[\"OPEN_DATETIME\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "# df_class.dropna(subset=[label], inplace=True)\n",
    "# df_class.sort_index(inplace=True)\n",
    "\n",
    "# df_class_val=pd.read_csv(PATH_DATA_DTS+dts_name+\"_VAL.zip\",sep=\",\",index_col=[\"OPEN_DATETIME\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "# df_class_val.dropna(subset=[label], inplace=True)\n",
    "# df_class_val.sort_index(inplace=True)\n",
    "\n",
    "# df_class_conf=pd.read_csv(PATH_DATA_DTS+dts_name+\"_CONF.zip\",sep=\",\",index_col=[\"OPEN_DATETIME\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "# df_class_conf.dropna(subset=[label], inplace=True)\n",
    "# df_class_conf.sort_index(inplace=True)\n",
    "df_class=pd.read_pickle(PATH_DATA_DTS+dts_name+\"_TRAIN.pkl\")\n",
    "df_class_val=pd.read_pickle(PATH_DATA_DTS+dts_name+\"_VAL.pkl\")\n",
    "df_class_conf=pd.read_pickle(PATH_DATA_DTS+dts_name+\"_CONF.pkl\")\n",
    "\n",
    "print(df_class.shape)\n",
    "print(df_class_val.shape)\n",
    "print(df_class_conf.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_label='lab_perf_5d' nb_class=3 lab_added='lab_perf_5d_class_3' my_list_categ_to_add[nb_class]={0: [-1, -0.00925], 1: [-0.00925, 0.01359], 2: [0.01359, 20]}\n",
      "lab_perf_5d_class_3\n",
      "0.0    162253\n",
      "1.0    162301\n",
      "2.0    162325\n",
      "Name: count, dtype: int64\n",
      "lab_perf_5d_class_3\n",
      "0.0    36657\n",
      "1.0    34239\n",
      "2.0    31610\n",
      "Name: count, dtype: int64\n",
      "lab_perf_5d_class_3\n",
      "0.0    44562\n",
      "1.0    34987\n",
      "2.0    40919\n",
      "Name: count, dtype: int64\n",
      "my_label='lab_perf_5d' nb_class=5 lab_added='lab_perf_5d_class_5' my_list_categ_to_add[nb_class]={0: [-1, -0.02209], 1: [-0.02209, -0.00437], 2: [-0.00437, 0.00816], 3: [0.00816, 0.02816], 4: [0.02816, 5]}\n",
      "lab_perf_5d_class_5\n",
      "0.0    97348\n",
      "1.0    97380\n",
      "2.0    97382\n",
      "3.0    97381\n",
      "4.0    97388\n",
      "Name: count, dtype: int64\n",
      "lab_perf_5d_class_5\n",
      "0.0    22829\n",
      "1.0    20863\n",
      "2.0    20187\n",
      "3.0    20264\n",
      "4.0    18363\n",
      "Name: count, dtype: int64\n",
      "lab_perf_5d_class_5\n",
      "0.0    29037\n",
      "1.0    22871\n",
      "2.0    20153\n",
      "3.0    22709\n",
      "4.0    25698\n",
      "Name: count, dtype: int64\n",
      "my_label='lab_perf_5d' nb_class=10 lab_added='lab_perf_5d_class_10' my_list_categ_to_add[nb_class]={0: [-1, -0.03894], 1: [-0.03894, -0.02209], 2: [-0.02209, -0.01198], 3: [-0.01198, -0.00437], 4: [-0.00437, 0.0011], 5: [0.0011, 0.00816], 6: [0.00816, 0.01667], 7: [0.01667, 0.02816], 8: [0.02816, 0.04797], 9: [0.04797, 20]}\n",
      "lab_perf_5d_class_10\n",
      "0.0    48666\n",
      "1.0    48682\n",
      "2.0    48696\n",
      "3.0    48684\n",
      "4.0    48707\n",
      "5.0    48675\n",
      "6.0    48664\n",
      "7.0    48717\n",
      "8.0    48682\n",
      "9.0    48706\n",
      "Name: count, dtype: int64\n",
      "lab_perf_5d_class_10\n",
      "0.0    12764\n",
      "1.0    10065\n",
      "2.0    10319\n",
      "3.0    10544\n",
      "4.0     9732\n",
      "5.0    10455\n",
      "6.0    10411\n",
      "7.0     9853\n",
      "8.0     9302\n",
      "9.0     9061\n",
      "Name: count, dtype: int64\n",
      "lab_perf_5d_class_10\n",
      "0.0    16147\n",
      "1.0    12890\n",
      "2.0    11766\n",
      "3.0    11105\n",
      "4.0     9848\n",
      "5.0    10305\n",
      "6.0    11288\n",
      "7.0    11421\n",
      "8.0    11818\n",
      "9.0    13880\n",
      "Name: count, dtype: int64\n",
      "my_label='lab_perf_10d' nb_class=3 lab_added='lab_perf_10d_class_3' my_list_categ_to_add[nb_class]={0: [-1, -0.01226], 1: [-0.01226, 0.02207], 2: [0.02207, 20]}\n",
      "lab_perf_10d_class_3\n",
      "0.0    162269\n",
      "1.0    162302\n",
      "2.0    162308\n",
      "Name: count, dtype: int64\n",
      "lab_perf_10d_class_3\n",
      "0.0    37516\n",
      "1.0    34215\n",
      "2.0    30775\n",
      "Name: count, dtype: int64\n",
      "lab_perf_10d_class_3\n",
      "0.0    45310\n",
      "1.0    35477\n",
      "2.0    39681\n",
      "Name: count, dtype: int64\n",
      "my_label='lab_perf_10d' nb_class=5 lab_added='lab_perf_10d_class_5' my_list_categ_to_add[nb_class]={0: [-1, -0.03071], 1: [-0.03071, -0.00522], 2: [-0.00522, 0.01406], 3: [0.01406, 0.04314], 4: [0.04314, 5]}\n",
      "lab_perf_10d_class_5\n",
      "0.0    97365\n",
      "1.0    97357\n",
      "2.0    97400\n",
      "3.0    97357\n",
      "4.0    97400\n",
      "Name: count, dtype: int64\n",
      "lab_perf_10d_class_5\n",
      "0.0    23529\n",
      "1.0    20786\n",
      "2.0    20555\n",
      "3.0    19876\n",
      "4.0    17760\n",
      "Name: count, dtype: int64\n",
      "lab_perf_10d_class_5\n",
      "0.0    29591\n",
      "1.0    23045\n",
      "2.0    20980\n",
      "3.0    21869\n",
      "4.0    24983\n",
      "Name: count, dtype: int64\n",
      "my_label='lab_perf_10d' nb_class=10 lab_added='lab_perf_10d_class_10' my_list_categ_to_add[nb_class]={0: [-1, -0.05387], 1: [-0.05387, -0.03071], 2: [-0.03071, -0.01624], 3: [-0.01624, -0.00522], 4: [-0.00522, 0.00367], 5: [0.00367, 0.01406], 6: [0.01406, 0.02657], 7: [0.02657, 0.04314], 8: [0.04314, 0.07055], 9: [0.07055, 20]}\n",
      "lab_perf_10d_class_10\n",
      "0.0    48677\n",
      "1.0    48688\n",
      "2.0    48665\n",
      "3.0    48692\n",
      "4.0    48712\n",
      "5.0    48688\n",
      "6.0    48682\n",
      "7.0    48675\n",
      "8.0    48703\n",
      "9.0    48697\n",
      "Name: count, dtype: int64\n",
      "lab_perf_10d_class_10\n",
      "0.0    13640\n",
      "1.0     9889\n",
      "2.0    10525\n",
      "3.0    10261\n",
      "4.0    10098\n",
      "5.0    10457\n",
      "6.0    10273\n",
      "7.0     9603\n",
      "8.0     8958\n",
      "9.0     8802\n",
      "Name: count, dtype: int64\n",
      "lab_perf_10d_class_10\n",
      "0.0    16896\n",
      "1.0    12695\n",
      "2.0    11959\n",
      "3.0    11086\n",
      "4.0    10250\n",
      "5.0    10730\n",
      "6.0    10835\n",
      "7.0    11034\n",
      "8.0    11337\n",
      "9.0    13646\n",
      "Name: count, dtype: int64\n",
      "my_label='lab_perf_20d' nb_class=3 lab_added='lab_perf_20d_class_3' my_list_categ_to_add[nb_class]={0: [-1, -0.01542], 1: [-0.01542, 0.03633], 2: [0.03633, 20]}\n",
      "lab_perf_20d_class_3\n",
      "0.0    162289\n",
      "1.0    162282\n",
      "2.0    162308\n",
      "Name: count, dtype: int64\n",
      "lab_perf_20d_class_3\n",
      "0.0    39216\n",
      "1.0    33981\n",
      "2.0    29309\n",
      "Name: count, dtype: int64\n",
      "lab_perf_20d_class_3\n",
      "0.0    46165\n",
      "1.0    36117\n",
      "2.0    38186\n",
      "Name: count, dtype: int64\n",
      "my_label='lab_perf_20d' nb_class=5 lab_added='lab_perf_20d_class_5' my_list_categ_to_add[nb_class]={0: [-1, -0.04141], 1: [-0.04141, -0.00522], 2: [-0.00522, 0.02439], 3: [0.02439, 0.06687], 4: [0.06687, 5]}\n",
      "lab_perf_20d_class_5\n",
      "0.0    97369\n",
      "1.0    97365\n",
      "2.0    97366\n",
      "3.0    97387\n",
      "4.0    97392\n",
      "Name: count, dtype: int64\n",
      "lab_perf_20d_class_5\n",
      "0.0    25430\n",
      "1.0    20736\n",
      "2.0    20359\n",
      "3.0    19113\n",
      "4.0    16860\n",
      "Name: count, dtype: int64\n",
      "lab_perf_20d_class_5\n",
      "0.0    30410\n",
      "1.0    23235\n",
      "2.0    21349\n",
      "3.0    21548\n",
      "4.0    23926\n",
      "Name: count, dtype: int64\n",
      "my_label='lab_perf_20d' nb_class=10 lab_added='lab_perf_20d_class_10' my_list_categ_to_add[nb_class]={0: [-1, -0.07407], 1: [-0.07407, -0.04141], 2: [-0.04141, -0.02099], 3: [-0.02099, -0.00522], 4: [-0.00522, 0.00872], 5: [0.00872, 0.02439], 6: [0.02439, 0.04295], 7: [0.04295, 0.06687], 8: [0.06687, 0.10603], 9: [0.10603, 20]}\n",
      "lab_perf_20d_class_10\n",
      "0.0    48687\n",
      "1.0    48682\n",
      "2.0    48675\n",
      "3.0    48690\n",
      "4.0    48680\n",
      "5.0    48686\n",
      "6.0    48692\n",
      "7.0    48695\n",
      "8.0    48702\n",
      "9.0    48690\n",
      "Name: count, dtype: int64\n",
      "lab_perf_20d_class_10\n",
      "0.0    14808\n",
      "1.0    10622\n",
      "2.0    10352\n",
      "3.0    10384\n",
      "4.0    10235\n",
      "5.0    10124\n",
      "6.0     9956\n",
      "7.0     9157\n",
      "8.0     8383\n",
      "9.0     8485\n",
      "Name: count, dtype: int64\n",
      "lab_perf_20d_class_10\n",
      "0.0    16948\n",
      "1.0    13462\n",
      "2.0    11988\n",
      "3.0    11247\n",
      "4.0    10698\n",
      "5.0    10651\n",
      "6.0    10856\n",
      "7.0    10692\n",
      "8.0    10911\n",
      "9.0    13015\n",
      "Name: count, dtype: int64\n",
      "my_label='lab_perf_50d' nb_class=3 lab_added='lab_perf_50d_class_3' my_list_categ_to_add[nb_class]={0: [-1, -0.01566], 1: [-0.01566, 0.07241], 2: [0.07241, 20]}\n",
      "lab_perf_50d_class_3\n",
      "0.0    162278\n",
      "1.0    162297\n",
      "2.0    162304\n",
      "Name: count, dtype: int64\n",
      "lab_perf_50d_class_3\n",
      "0.0    43772\n",
      "1.0    33168\n",
      "2.0    25566\n",
      "Name: count, dtype: int64\n",
      "lab_perf_50d_class_3\n",
      "0.0    48152\n",
      "1.0    35847\n",
      "2.0    36469\n",
      "Name: count, dtype: int64\n",
      "my_label='lab_perf_50d' nb_class=5 lab_added='lab_perf_50d_class_5' my_list_categ_to_add[nb_class]={0: [-1, -0.05826], 1: [-0.05826, 0.00124], 2: [0.00124, 0.05301], 3: [0.05301, 0.12161], 4: [0.12161, 15]}\n",
      "lab_perf_50d_class_5\n",
      "0.0    97366\n",
      "1.0    97375\n",
      "2.0    97372\n",
      "3.0    97388\n",
      "4.0    97378\n",
      "Name: count, dtype: int64\n",
      "lab_perf_50d_class_5\n",
      "0.0    29424\n",
      "1.0    21370\n",
      "2.0    20005\n",
      "3.0    16891\n",
      "4.0    14814\n",
      "Name: count, dtype: int64\n",
      "lab_perf_50d_class_5\n",
      "0.0    30933\n",
      "1.0    24911\n",
      "2.0    21353\n",
      "3.0    20566\n",
      "4.0    22705\n",
      "Name: count, dtype: int64\n",
      "my_label='lab_perf_50d' nb_class=10 lab_added='lab_perf_50d_class_10' my_list_categ_to_add[nb_class]={0: [-1, -0.11173], 1: [-0.11173, -0.05826], 2: [-0.05826, -0.02501], 3: [-0.02501, 0.00124], 4: [0.00124, 0.02632], 5: [0.02632, 0.05301], 6: [0.05301, 0.08305], 7: [0.08305, 0.12161], 8: [0.12161, 0.186], 9: [0.186, 20]}\n",
      "lab_perf_50d_class_10\n",
      "0.0    48684\n",
      "1.0    48682\n",
      "2.0    48688\n",
      "3.0    48687\n",
      "4.0    48678\n",
      "5.0    48694\n",
      "6.0    48690\n",
      "7.0    48698\n",
      "8.0    48685\n",
      "9.0    48693\n",
      "Name: count, dtype: int64\n",
      "lab_perf_50d_class_10\n",
      "0.0    18368\n",
      "1.0    11056\n",
      "2.0    10818\n",
      "3.0    10552\n",
      "4.0    10122\n",
      "5.0     9883\n",
      "6.0     8932\n",
      "7.0     7959\n",
      "8.0     6908\n",
      "9.0     7908\n",
      "Name: count, dtype: int64\n",
      "lab_perf_50d_class_10\n",
      "0.0    16626\n",
      "1.0    14307\n",
      "2.0    13069\n",
      "3.0    11842\n",
      "4.0    10713\n",
      "5.0    10640\n",
      "6.0    10310\n",
      "7.0    10256\n",
      "8.0    10471\n",
      "9.0    12234\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "categ_50_3={0:[-1,-0.01566],1:[-0.01566,0.07241],2:[0.07241,20]}\n",
    "categ_50_5={0:[-1,-0.05826],1:[-0.05826,0.00124],2:[0.00124,0.05301],3:[0.05301,0.12161],4:[0.12161,15]}\n",
    "categ_50_10={0:[-1,-0.11173],1:[-0.11173,-0.05826],2:[-0.05826,-0.02501],3:[-0.02501,0.00124],4:[0.00124,0.02632],\n",
    "             5:[0.02632,0.05301],6:[0.05301,0.08305],7:[0.08305,0.12161],8:[0.12161,0.18600],9:[0.18600,20]}\n",
    "list_categ_50_to_add={3:categ_50_3,5:categ_50_5,10:categ_50_10}\n",
    "\n",
    "categ_20_3={0:[-1,-0.01542],1:[-0.01542,0.03633],2:[0.03633,20]}\n",
    "categ_20_5={0:[-1,-0.04141],1:[-0.04141,-0.00522],2:[-0.00522,0.02439],3:[0.02439,0.06687],4:[0.06687,5]}\n",
    "categ_20_10={0:[-1,-0.07407],1:[-0.07407,-0.04141],2:[-0.04141,-0.02099],3:[-0.02099,-0.00522],4:[-0.00522,0.00872],\n",
    "             5:[0.00872,0.02439],6:[0.02439,0.04295],7:[0.04295,0.06687],8:[0.06687,0.10603],9:[0.10603,20]}\n",
    "list_categ_20_to_add={3:categ_20_3,5:categ_20_5,10:categ_20_10}\n",
    "\n",
    "categ_10_3={0:[-1,-0.01226],1:[-0.01226,0.02207],2:[0.02207,20]}\n",
    "categ_10_5={0:[-1,-0.03071],1:[-0.03071,-0.00522],2:[-0.00522,0.01406],3:[0.01406,0.04314],4:[0.04314,5]}\n",
    "categ_10_10={0:[-1,-0.05387],1:[-0.05387,-0.03071],2:[-0.03071,-0.01624],3:[-0.01624,-0.00522],4:[-0.00522,0.00367],\n",
    "             5:[0.00367,0.01406],6:[0.01406,0.02657],7:[0.02657,0.04314],8:[0.04314,0.07055],9:[0.07055,20]}\n",
    "list_categ_10_to_add={3:categ_10_3,5:categ_10_5,10:categ_10_10}\n",
    "\n",
    "categ_5_3={0:[-1,-0.00925],1:[-0.00925,0.01359],2:[0.01359,20]}\n",
    "categ_5_5={0:[-1,-0.02209],1:[-0.02209,-0.00437],2:[-0.00437,0.00816],3:[0.00816,0.02816],4:[0.02816,5]}\n",
    "categ_5_10={0:[-1,-0.03894],1:[-0.03894,-0.02209],2:[-0.02209,-0.01198],3:[-0.01198,-0.00437],4:[-0.00437,0.00110],\n",
    "             5:[0.00110,0.00816],6:[0.00816,0.01667],7:[0.01667,0.02816],8:[0.02816,0.04797],9:[0.04797,20]}\n",
    "list_categ_5_to_add={3:categ_5_3,5:categ_5_5,10:categ_5_10}\n",
    "\n",
    "list_label=['lab_perf_5d','lab_perf_10d','lab_perf_20d','lab_perf_50d']\n",
    "dic_list_categ_to_add={'lab_perf_5d':list_categ_5_to_add,'lab_perf_10d':list_categ_10_to_add,\n",
    "                       'lab_perf_20d':list_categ_20_to_add,'lab_perf_50d':list_categ_50_to_add}\n",
    "\n",
    "for my_label in list_label:\n",
    "    my_list_categ_to_add=dic_list_categ_to_add[my_label]\n",
    "    for nb_class in my_list_categ_to_add.keys():\n",
    "        suffix_added=\"_class_\"+str(nb_class)\n",
    "        lab_added=my_label+suffix_added\n",
    "        print(f\"{my_label=} {nb_class=} {lab_added=} {my_list_categ_to_add[nb_class]=}\")\n",
    "        df_class=balance.add_lab_by_class(df_in=df_class,str_label=my_label, categ=my_list_categ_to_add[nb_class],\n",
    "                                        bool_replace_label=False,str_suffix_class=suffix_added) # categ\n",
    "        df_class_val=balance.add_lab_by_class(df_in=df_class_val,str_label=my_label, categ=my_list_categ_to_add[nb_class],\n",
    "                                            bool_replace_label=False,str_suffix_class=suffix_added) # categ\n",
    "        df_class_conf=balance.add_lab_by_class(df_in=df_class_conf,str_label=my_label, categ=my_list_categ_to_add[nb_class],\n",
    "                                            bool_replace_label=False,str_suffix_class=suffix_added) # categ\n",
    "\n",
    "        df_class.sort_index(inplace=True)\n",
    "        df_class_val.sort_index(inplace=True)\n",
    "        df_class_conf.sort_index(inplace=True)\n",
    "\n",
    "        print(df_class[lab_added].value_counts().sort_index()) # min 97366 \n",
    "        print(df_class_val[lab_added].value_counts().sort_index()) # min 14774\n",
    "        print(df_class_conf[lab_added].value_counts().sort_index()) # min 20566\n",
    "\n",
    "# df_class=balance.add_lab_by_class(df_in=df_class,str_label=label, categ=categ_20_5,bool_replace_label=False) # categ\n",
    "# df_class.sort_index(inplace=True)\n",
    "# df_class_val=balance.add_lab_by_class(df_in=df_class_val,str_label=label, categ=categ_20_5,bool_replace_label=False) # categ\n",
    "# df_class_val.sort_index(inplace=True)\n",
    "# df_class_conf=balance.add_lab_by_class(df_in=df_class_conf,str_label=label, categ=categ_20_5,bool_replace_label=False) # categ\n",
    "# df_class_conf.sort_index(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(486879, 130)\n",
      "(102506, 130)\n",
      "(120468, 130)\n"
     ]
    }
   ],
   "source": [
    "# save the 3 df in pkl format\n",
    "df_class.to_pickle(PATH_DATA_DTS+dts_name+\"_class_TRAIN.pkl\")\n",
    "df_class_val.to_pickle(PATH_DATA_DTS+dts_name+\"_class_VAL.pkl\")\n",
    "df_class_conf.to_pickle(PATH_DATA_DTS+dts_name+\"_class_CONF.pkl\")\n",
    "\n",
    "print(df_class.shape)\n",
    "print(df_class_val.shape)\n",
    "print(df_class_conf.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "START HERE !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_class.shape=(486879, 130) df_class_val.shape=(102506, 130) df_class_conf.shape=(120468, 130)\n"
     ]
    }
   ],
   "source": [
    "dts_name=\"PARIS_TREND_1D_V4_class\"\n",
    "multi_symbol=\"PARIS_STOCK\"\n",
    "label = \"lab_perf_20d\"\n",
    "\n",
    "# load the 3 pkl files in 3 df\n",
    "df_class=pd.read_pickle(PATH_DATA_DTS+dts_name+\"_TRAIN.pkl\")\n",
    "df_class_val=pd.read_pickle(PATH_DATA_DTS+dts_name+\"_VAL.pkl\")\n",
    "df_class_conf=pd.read_pickle(PATH_DATA_DTS+dts_name+\"_CONF.pkl\")\n",
    "\n",
    "print(f\"{df_class.shape=} {df_class_val.shape=} {df_class_conf.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455900, 127)\n",
      "(98665, 127)\n",
      "(117005, 127)\n"
     ]
    }
   ],
   "source": [
    "# clean V4 dataset to make a V5\n",
    "\n",
    "new_dts_name=\"PARIS_TREND_1D_V5_class\"\n",
    "\n",
    "df_class_v5=df_class.copy()\n",
    "df_class_val_v5=df_class_val.copy()\n",
    "df_class_conf_v5=df_class_conf.copy()\n",
    "\n",
    "#add column CODE to the index to get a multi index\n",
    "df_class_v5=df_class_v5.set_index('CODE',append=True)\n",
    "df_class_val_v5=df_class_val_v5.set_index('CODE',append=True)\n",
    "df_class_conf_v5=df_class_conf_v5.set_index('CODE',append=True)\n",
    "\n",
    "# drop col stdev20_sma20 and stdev20_sma5\n",
    "df_class_v5.drop(columns=['stdev20_sma20','stdev20_sma5'],inplace=True)\n",
    "df_class_val_v5.drop(columns=['stdev20_sma20','stdev20_sma5'],inplace=True)\n",
    "df_class_conf_v5.drop(columns=['stdev20_sma20','stdev20_sma5'],inplace=True)\n",
    "\n",
    "# delete ALVDM.PA before 2017\n",
    "df_class_v5.drop(df_class_v5[(df_class_v5.index.get_level_values('CODE') == \"ALVDM.PA\") & \n",
    "                             (df_class_v5.index.get_level_values('OPEN_DATETIME') < \"2017-01-01\")].index,inplace=True)\n",
    "df_class_val_v5.drop(df_class_val_v5[(df_class_val_v5.index.get_level_values('CODE') == \"ALVDM.PA\") &\n",
    "                                    (df_class_val_v5.index.get_level_values('OPEN_DATETIME') < \"2017-01-01\")].index,inplace=True)\n",
    "df_class_conf_v5.drop(df_class_conf_v5[(df_class_conf_v5.index.get_level_values('CODE') == \"ALVDM.PA\") &\n",
    "                                      (df_class_conf_v5.index.get_level_values('OPEN_DATETIME') < \"2017-01-01\")].index,inplace=True)\n",
    "\n",
    "# delete SAMS.PA LOUP.PA ELEC.PA CRSU.PA IMDA.PA LOCAL.PA EUR.PA ALFLE.PA BUR.PA\n",
    "list_code_to_del=[\"SAMS.PA\",\"LOUP.PA\",\"ELEC.PA\",\"CRSU.PA\",\"IMDA.PA\",\"LOCAL.PA\",\"EUR.PA\",\"ALFLE.PA\",\"BUR.PA\"]\n",
    "for code in list_code_to_del:\n",
    "    df_class_v5.drop(df_class_v5[(df_class_v5.index.get_level_values('CODE') == code)].index,inplace=True)\n",
    "    df_class_val_v5.drop(df_class_val_v5[(df_class_val_v5.index.get_level_values('CODE') == code)].index,inplace=True)\n",
    "    df_class_conf_v5.drop(df_class_conf_v5[(df_class_conf_v5.index.get_level_values('CODE') == code)].index,inplace=True)\n",
    "\n",
    "# delete ALGIL.PA before 2012\n",
    "df_class_v5.drop(df_class_v5[(df_class_v5.index.get_level_values('CODE') == \"ALGIL.PA\") & \n",
    "                             (df_class_v5.index.get_level_values('OPEN_DATETIME') < \"2012-01-01\")].index,inplace=True)\n",
    "df_class_val_v5.drop(df_class_val_v5[(df_class_val_v5.index.get_level_values('CODE') == \"ALGIL.PA\") &\n",
    "                                    (df_class_val_v5.index.get_level_values('OPEN_DATETIME') < \"2012-01-01\")].index,inplace=True)\n",
    "df_class_conf_v5.drop(df_class_conf_v5[(df_class_conf_v5.index.get_level_values('CODE') == \"ALGIL.PA\") &\n",
    "                                      (df_class_conf_v5.index.get_level_values('OPEN_DATETIME') < \"2012-01-01\")].index,inplace=True)\n",
    "\n",
    "# delete EIFF.PA before 2007\n",
    "df_class_v5.drop(df_class_v5[(df_class_v5.index.get_level_values('CODE') == \"EIFF.PA\") & \n",
    "                             (df_class_v5.index.get_level_values('OPEN_DATETIME') < \"2007-01-01\")].index,inplace=True)\n",
    "df_class_val_v5.drop(df_class_val_v5[(df_class_val_v5.index.get_level_values('CODE') == \"EIFF.PA\") &\n",
    "                                    (df_class_val_v5.index.get_level_values('OPEN_DATETIME') < \"2007-01-01\")].index,inplace=True)\n",
    "df_class_conf_v5.drop(df_class_conf_v5[(df_class_conf_v5.index.get_level_values('CODE') == \"EIFF.PA\") &\n",
    "                                      (df_class_conf_v5.index.get_level_values('OPEN_DATETIME') < \"2007-01-01\")].index,inplace=True)\n",
    "\n",
    "# delete ALMDT.PA before 2020\n",
    "df_class_v5.drop(df_class_v5[(df_class_v5.index.get_level_values('CODE') == \"ALMDT.PA\") & \n",
    "                             (df_class_v5.index.get_level_values('OPEN_DATETIME') < \"2020-01-01\")].index,inplace=True)\n",
    "df_class_val_v5.drop(df_class_val_v5[(df_class_val_v5.index.get_level_values('CODE') == \"ALMDT.PA\") &\n",
    "                                    (df_class_val_v5.index.get_level_values('OPEN_DATETIME') < \"2020-01-01\")].index,inplace=True)\n",
    "df_class_conf_v5.drop(df_class_conf_v5[(df_class_conf_v5.index.get_level_values('CODE') == \"ALMDT.PA\") &\n",
    "                                      (df_class_conf_v5.index.get_level_values('OPEN_DATETIME') < \"2020-01-01\")].index,inplace=True)\n",
    "\n",
    "# delete GFC.PA before 1998\n",
    "df_class_v5.drop(df_class_v5[(df_class_v5.index.get_level_values('CODE') == \"GFC.PA\") & \n",
    "                             (df_class_v5.index.get_level_values('OPEN_DATETIME') < \"1998-01-01\")].index,inplace=True)\n",
    "df_class_val_v5.drop(df_class_val_v5[(df_class_val_v5.index.get_level_values('CODE') == \"GFC.PA\") &\n",
    "                                    (df_class_val_v5.index.get_level_values('OPEN_DATETIME') < \"1998-01-01\")].index,inplace=True)\n",
    "df_class_conf_v5.drop(df_class_conf_v5[(df_class_conf_v5.index.get_level_values('CODE') == \"GFC.PA\") &\n",
    "                                      (df_class_conf_v5.index.get_level_values('OPEN_DATETIME') < \"1998-01-01\")].index,inplace=True)\n",
    "\n",
    "print(f\"{df_class_v5.shape=} {df_class_val_v5.shape=} {df_class_conf_v5.shape=}\")\n",
    "\n",
    "df_class_v5.to_pickle(PATH_DATA_DTS+new_dts_name+\"_TRAIN.pkl\")\n",
    "df_class_val_v5.to_pickle(PATH_DATA_DTS+new_dts_name+\"_VAL.pkl\")\n",
    "df_class_conf_v5.to_pickle(PATH_DATA_DTS+new_dts_name+\"_CONF.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts_name=\"PARIS_TREND_1D_V5_class\"\n",
    "print(df_class_v5.head(5))\n",
    "# print list of columns of df_class in a txt file\n",
    "with open(PATH_DATA_DTS+dts_name+\"_class_TRAIN_columns.txt\", \"w\") as output:\n",
    "    output.write(str(df_class.columns.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class=df_class_v5.copy()\n",
    "df_class_val=df_class_val_v5.copy()\n",
    "df_class_conf=df_class_conf_v5.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUND THE DATASETS\n",
    "# round_to_significant_digits(df : pd.DataFrame, digits : int, list_col_int:list=None, list_col_ignore:list=None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "digits=3\n",
    "list_col_int=[\"rsi14\",\"sma5_rsi14\",\"sma20_rsi14\",\"aroon14_up\",\"aroon14_down\",\"aroon14_dif\",\n",
    "\"stoch14\",\"stoch14_signal\",\"stoch14_dif\",\"adx14\",\"adx14_neg\",\"adx14_pos\",\n",
    "\"perf_rsi14_5d\",\"perf_rsi14_10d\",\"aroon14_up_lag_5d\",\"aroon14_down_lag_5d\",\n",
    "\"aroon14_dif_lag_5d\",\t\"perf_stoch14_5d\",\"perf_stoch14_signal_5d\",\n",
    "\"perf_stoch14_dif_5d\",\"perf_adx14_neg_5d\",\t\"perf_adx14_pos_5d\",\t\n",
    "\"perf_williamsr_14_5d\",\"williamsr_14_perf_10d\",\"williamsr_14\"\t]\n",
    "\n",
    "list_col_ignore=[\"CODE\",\"OPEN\", \"HIGH\", \"LOW\", \"CLOSE\", \"VOLUME\",\"lab_perf_20d\",\"lab_perf_50d\",\"lab_perf_125d\",\n",
    "                  \"lab_perf_10d\",\"lab_perf_5d\", \"lab_perf_5d_class_3\",\n",
    " \"lab_perf_5d_class_5\", \"lab_perf_5d_class_10\", \"lab_perf_10d_class_3\", \"lab_perf_10d_class_5\",\n",
    " \"lab_perf_10d_class_10\", \"lab_perf_20d_class_3\", \"lab_perf_20d_class_5\", \"lab_perf_20d_class_10\",\n",
    " \"lab_perf_50d_class_3\", \"lab_perf_50d_class_5\", \"lab_perf_50d_class_10\"]\n",
    "\n",
    "df_class_r=balance.round_to_significant_digits(df=df_class,digits=digits,\n",
    "                                               list_col_int=list_col_int,list_col_ignore=list_col_ignore)\n",
    "df_class_val_r=balance.round_to_significant_digits(df=df_class_val,digits=digits,\n",
    "                                               list_col_int=list_col_int,list_col_ignore=list_col_ignore)\n",
    "df_class_conf_r=balance.round_to_significant_digits(df=df_class_conf,digits=digits,\n",
    "                                               list_col_int=list_col_int,list_col_ignore=list_col_ignore)\n",
    "\n",
    "\n",
    "df_class_r.to_pickle(PATH_DATA_DTS+dts_name+\"_R\"+str(digits)+\"_TRAIN.pkl\")\n",
    "df_class_val_r.to_pickle(PATH_DATA_DTS+dts_name+\"_R\"+str(digits)+\"_VAL.pkl\")\n",
    "df_class_conf_r.to_pickle(PATH_DATA_DTS+dts_name+\"_R\"+str(digits)+\"_CONF.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the 3 pkl files\n",
    "dts_name=\"PARIS_TREND_1D_V5_class_R3\"\n",
    "\n",
    "df_class=pd.read_pickle(PATH_DATA_DTS+dts_name+\"_TRAIN.pkl\")\n",
    "df_class_val=pd.read_pickle(PATH_DATA_DTS+dts_name+\"_VAL.pkl\")\n",
    "df_class_conf=pd.read_pickle(PATH_DATA_DTS+dts_name+\"_CONF.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "print(f\"{df_class.shape=} {df_class_val.shape=} \")\n",
    "print(f\"{df_class.describe()}\")\n",
    "print(f\"{df_class[1000:1050]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip of the features \n",
    "feature_limits = {\n",
    "    'pos_sma20': [-0.5, 0.5],\n",
    "    'pos_sma50': [-0.5, 1],\n",
    "    'pos_sma200': [-0.5, 1],\n",
    "    'pos_sma50_200': [-0.25, 1],\n",
    "    'ret_1d': [-0.25, 0.25],\n",
    "    'ret_5d': [-0.5, 0.5],\n",
    "    'stdev20_1d': [None, 5],\n",
    "    'pos_stdev20_sma20': [None, 4],\n",
    "    'macd_dif': [-5, 5],\n",
    "    'pos_stdev20_sma5': [None, 1],\n",
    "    'pos_ema50_perf_5d': [-10, 10],\n",
    "    'pos_ema50_perf_10d': [-10, 10],\n",
    "    'pos_bb20_lo_lag_5d': [None, 2],\n",
    "    'pos_bot20_lag_5d': [None, 1],\n",
    "    'pos_bot50_lag_10d': [None, 1],\n",
    "    'perf_atr14_5d': [None, 2],\n",
    "    'perf_adx14_5d': [None, 2],\n",
    "    'pos_avg_vol50': [None, 10],\n",
    "    'pos_bot20': [None, 1],\n",
    "    'pos_bot50': [None, 1],\n",
    "    'pos_bot_200': [None, 4],\n",
    "    'pos_rsi14_sma5': [-0.75, 0.75],\n",
    "    'pos_rsi14_sma20': [-0.75, 0.75],\n",
    "    'pos_rsi14_sma5_20': [-0.75, 0.75],\n",
    "    'pos_sma20_200': [None, 1],\n",
    "    'pos_sma10': [-0.5, 0.5],\n",
    "    'pos_sma5': [-0.25, 0.25],\n",
    "    'perf_pos_sma10_10d': [-0.5, 0.5],\n",
    "    'perf_sma10_5d': [-0.25, 0.25],\n",
    "    'perf_sma10_10d': [-0.5, 0.5],\n",
    "    'perf_pos_sma20_10d': [-0.5, 0.5],\n",
    "    'perf_sma20_10d': [-0.25, 0.25],\n",
    "    'perf_pos_sma50_10d': [-0.5, 0.5],\n",
    "    'perf_pos_sma200_10d': [-0.5, 0.5],\n",
    "    'pos_sma5_50': [-0.5, 0.5],\n",
    "    'pos_sma5_200': [-0.5, 1],\n",
    "    'pos_sma10_50': [-0.5, 0.5],\n",
    "    'pos_sma10_200': [-0.25, 1],\n",
    "    'perf_ema5_5d': [-0.25, 0.25],\n",
    "    'pos_ema10': [-0.25, 0.25],\n",
    "    'perf_pos_ema10_5d': [-0.25, 0.25],\n",
    "    'perf_pos_ema10_10d': [-0.25, 0.25],\n",
    "    'perf_pos_ema20_5d': [-0.25, 0.25],\n",
    "    'perf_pos_ema20_10d': [-0.5, 0.5],\n",
    "    'perf_pos_ema200_5d': [-0.5, 0.5],\n",
    "    'perf_pos_ema200_10d': [-0.5, 0.5],\n",
    "    'pos_bb20_lo_lag_5d': [-0.5, 0.5],\n",
    "    'ret_10d': [-0.5, 0.5],\n",
    "    'ret_20d': [-0.5, 0.5],\n",
    "    'pos_bot20_lag_5d': [None, 0.5],\n",
    "    'pos_bot50_lag_10d': [None, 1],\n",
    "    'macd_fast': [-5, 5],\n",
    "    'macd_slow': [-5, 5],\n",
    "    'perf_atr14_5d': [None, 2]\n",
    "}\n",
    "\n",
    "for feature, limits in feature_limits.items():\n",
    "    min_val, max_val = limits\n",
    "    try:\n",
    "        df_class = balance.clipping_col(df_class, feature, min_val, max_val)\n",
    "    except KeyError:\n",
    "        print(f\"Feature '{feature}' not found in df_class. Skipping...\")\n",
    "    try:\n",
    "        df_class_val = balance.clipping_col(df_class_val, feature, min_val, max_val)\n",
    "    except KeyError:\n",
    "        print(f\"Feature '{feature}' not found in df_class_val. Skipping...\")\n",
    "    try:\n",
    "        df_class_conf = balance.clipping_col(df_class_conf, feature, min_val, max_val)\n",
    "    except KeyError:\n",
    "        print(f\"Feature '{feature}' not found in df_class_conf. Skipping...\")\n",
    "\n",
    "\n",
    "df_class.to_pickle(PATH_DATA_DTS+dts_name+\"_CLIP_TRAIN.pkl\")\n",
    "df_class_val.to_pickle(PATH_DATA_DTS+dts_name+\"_CLIP_VAL.pkl\")\n",
    "df_class_conf.to_pickle(PATH_DATA_DTS+dts_name+\"_CLIP_CONF.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_col=['pos_sma20','pos_sma50','pos_sma200','pos_sma50_200','ret_1d','ret_5d'\n",
    ",'stdev20_1d','pos_stdev20_sma20','macd_dif','pos_stdev20_sma5'\n",
    ",'pos_ema50_perf_5d','pos_ema50_perf_10d','pos_bb20_lo_lag_5d','pos_bot20_lag_5d','pos_bot50_lag_10d'\n",
    ",'perf_atr14_5d','perf_adx14_5d','pos_avg_vol50','pos_bot20','pos_bot50','pos_bot_200'\n",
    ",'pos_rsi14_sma5','pos_rsi14_sma20','pos_rsi14_sma5_20','pos_sma20_200','pos_sma10'\n",
    ",'pos_sma5','perf_pos_sma10_10d','perf_sma10_5d','perf_sma10_10d'  ,'perf_pos_sma20_10d'\n",
    ",'perf_sma20_10d'  ,'perf_pos_sma50_10d','perf_pos_sma200_10d','pos_sma5_50'   \n",
    ",'pos_sma5_200','pos_sma10_50' ,'pos_sma10_200','perf_ema5_5d'      ,'pos_ema10'  \n",
    ",'perf_pos_ema10_5d'  ,'perf_pos_ema10_10d','perf_pos_ema20_5d'  ,'perf_pos_ema20_10d'  \n",
    ",'perf_pos_ema200_5d'  ,'perf_pos_ema200_10d'\n",
    ",'pos_bb20_lo_lag_5d','ret_10d'        ,'ret_20d','pos_bot20_lag_5d'  ,'pos_bot50_lag_10d'\n",
    ",'macd_fast'      ,'macd_slow','perf_atr14_5d']\n",
    "\n",
    "# for each col in list_col print a graph of the distribution of the values\n",
    "for col in list_col:\n",
    "    print(col)\n",
    "    sns.histplot(data=df_class, x=col, kde=True, bins=50, color='blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print lines from df_class with stdev20_sma20>4 and open_datetime > 2018-01-01\n",
    "df_check=df_class[(df_class['macd_fast'] >5) \n",
    "                   & (df_class.index.get_level_values('OPEN_DATETIME') > '2016-01-01')\n",
    "                # & (df_class['CODE'] =='ABVX.PA')\n",
    "                  ]\n",
    "\n",
    "print(df_check.loc[:, ['CODE', 'macd_fast']].head(20))\n",
    "\n",
    "# print(df_class['CODE'].unique().shape)\n",
    "\n",
    "# print(df_check['CODE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the candle graph of BUR.PA from '2015-10-01' to '2016-02-01'\n",
    "df_graph = df_class[(df_class['CODE'] == 'BUR.PA') & (df_class.index > '2015-10-01') & (df_class.index < '2016-02-01')]\n",
    "df_graph.plot(y=[\"stdev20_1d\",\"pos_stdev20_sma20\"],kind='line',figsize=(15, 10))\n",
    "plt.show()\n",
    "\n",
    "# print(df_graph.loc[:, [ 'pos_stdev20_sma20']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class.drop(columns=list_rem,inplace=True,errors=\"ignore\")\n",
    "\n",
    "list_feat = df_class.columns.values.tolist()\n",
    "# remove list_rem from list_feat, don't crash if not in list\n",
    "\n",
    "print(f\"{list_feat.__len__()=}\")\n",
    "list_feat = [x for x in list_feat if x not in list_rem]\n",
    "\n",
    "print(f\"{list_feat.__len__()=}\")\n",
    "\n",
    "df_x_train, col_y_train = sm.split_df_x_y(\n",
    "    df_in=df_class,list_features=list_feat, str_label=label, drop_na=True)\n",
    "# df_x_train.drop(list_rem, axis=1, inplace=True)\n",
    "print(df_x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lab_perf_20d', 'lab_perf_50d', 'lab_perf_10d', 'lab_perf_5d']\n"
     ]
    }
   ],
   "source": [
    "# print all columns starting by lab_perf\n",
    "list_perf = [col for col in df_class.columns if col.startswith('lab_perf')]\n",
    "print(list_perf)\n",
    "# ['lab_perf_250d', 'lab_perf_20d', 'lab_perf_50d', 'lab_perf_10d', 'lab_perf_5d', 'lab_perf_20d_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_class.shape=(486879, 109) df_class_val.shape=(102506, 109)\n",
      "df_class[label].mean()=0.014540433187711938 df_class[label].min()=-0.80165 df_class[label].max()=2.4383\n",
      "df_class_val[label].mean()=0.002089393986693463 df_class_val[label].min()=-0.76396 df_class_val[label].max()=10.14943\n"
     ]
    }
   ],
   "source": [
    "# df_class=df_selected.copy()\n",
    "# df_class_val=df_valid.copy()\n",
    "\n",
    "list_perf=[\"OPEN\", \"HIGH\", \"LOW\", \"CLOSE\", \"VOLUME\",\n",
    "\"lab_perf_50d\",\"lab_perf_10d\",\"lab_perf_125d\",\"lab_perf_5d\", \"CODE\"]\n",
    "\n",
    "# remove columns from list_perf except label\n",
    "df_class.drop(columns=list_perf,inplace=True,errors=\"ignore\")\n",
    "df_class_val.drop(columns=list_perf,inplace=True,errors=\"ignore\")\n",
    "\n",
    "# for class datasets \n",
    "# rename column  label+'_class' by label\n",
    "# df_class.rename(columns={label+'_class':label},inplace=True)\n",
    "# df_class_val.rename(columns={label+'_class':label},inplace=True)\n",
    "\n",
    "# print(df_class[label].value_counts().sort_index())\n",
    "# print(df_class_val[label].value_counts().sort_index())\n",
    "\n",
    "# for regression datasets\n",
    "print(f\"{df_class.shape=} {df_class_val.shape=}\")\n",
    "print(f\"{df_class[label].mean()=} {df_class[label].min()=} {df_class[label].max()=}\")\n",
    "print(f\"{df_class_val[label].mean()=} {df_class_val[label].min()=} {df_class_val[label].max()=}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_x_train.shape=(486500, 106) df_x_val.shape=(84250, 106) col_y_train.size=486500 col_y_val.size=84250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['G:\\\\Python\\\\Data\\\\DTS_FULL\\\\PARIS_TREND_1D_20D_V4_Y_VAL_FILT_R3.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  for classification datasets !!!!\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# print(df_x_train.describe())\n",
    "\n",
    "# list_feat=df_x_train.columns.values.tolist()\n",
    "list_feat=None\n",
    "\n",
    "# add_indicators.round_to_significant_digits(df_in: pd.DataFrame, digits: int = 4, list_min2:list=[]) -> pd.DataFrame: \n",
    "def round_to_significant_digits(df, digits):\n",
    "    list_zero=[\"rsi14\",\"sma5_rsi14\",\"sma20_rsi14\",\"aroon14_up\",\"aroon14_down\",\"aroon14_dif\",\n",
    "\"stoch14\",\"stoch14_signal\",\"stoch14_dif\",\"adx14\",\"adx14_neg\",\"adx14_pos\",\n",
    "\"perf_rsi14_5d\",\"perf_rsi14_10d\",\"aroon14_up_lag_5d\",\"aroon14_down_lag_5d\",\n",
    "\"aroon14_dif_lag_5d\",\t\"perf_stoch14_5d\",\"perf_stoch14_signal_5d\",\n",
    "\"perf_stoch14_dif_5d\",\"perf_adx14_neg_5d\",\t\"perf_adx14_pos_5d\",\t\n",
    "\"perf_williamsr_14_5d\",\"williamsr_14_perf_10d\",\"williamsr_14\"\t]\n",
    "    df_temp=df.copy()\n",
    "    for col in df_temp.columns:\n",
    "        if col in list_zero:\n",
    "            df_temp[col]=df_temp[col].apply(lambda x:round(x,digits-2))\n",
    "        else:\n",
    "            df_temp[col]=df_temp[col].apply(lambda x:round(x,digits))\n",
    "    return df_temp\n",
    "\n",
    "\n",
    "df_x_train, col_y_train = sm.split_df_x_y(\n",
    "    df_in=df_class, list_features=list_feat, str_label=label, drop_na=True)\n",
    "\n",
    "df_x_val, col_y_val = sm.split_df_x_y(\n",
    "    df_in=df_class_val, list_features=list_feat, str_label=label, drop_na=True)\n",
    "\n",
    "#  for classification datasets\n",
    "method = RandomUnderSampler(sampling_strategy={0:97300,1:97300,2:97300,3:97300,4:97300}) # 97300 pour lab 20 et 97300 pour lab 50\n",
    "df_x_train, col_y_train=  method.fit_resample(df_x_train, col_y_train)\n",
    "\n",
    "method = RandomUnderSampler(sampling_strategy={0:16850,1:16850,2:16850,3:16850,4:16850}) # 16850 pour lab 20 et 14750 pour lab 50\n",
    "df_x_val, col_y_val=  method.fit_resample(df_x_val, col_y_val)\n",
    "\n",
    "print(f\"{df_x_train.shape=} {df_x_val.shape=} {col_y_train.size=} {col_y_val.size=}\")\n",
    "\n",
    "nb_digits = 3\n",
    "# round df_x_train and df_x_val\n",
    "# df_x_train_r = df_x_train.map(lambda x:round_to_significant_digits(x,nb_digits),na_action='ignore')\n",
    "# df_x_val_r = df_x_val.map(lambda x:round_to_significant_digits(x,nb_digits),na_action='ignore')\n",
    "\n",
    "df_x_train_r = round_to_significant_digits(df_x_train, nb_digits)\n",
    "df_x_val_r = round_to_significant_digits(df_x_val, nb_digits)\n",
    "\n",
    "# save objects in a pickle files\n",
    "joblib.dump(df_x_train_r, PATH_DATA_DTS+dts_name+\"_X_TRAIN_FILT_R\"+str(nb_digits)+\".pkl\")\n",
    "joblib.dump(col_y_train, PATH_DATA_DTS+dts_name+\"_Y_TRAIN_FILT_R\"+str(nb_digits)+\".pkl\")\n",
    "joblib.dump(df_x_val_r, PATH_DATA_DTS+dts_name+\"_X_VAL_FILT_R\"+str(nb_digits)+\".pkl\")\n",
    "joblib.dump(col_y_val, PATH_DATA_DTS+dts_name+\"_Y_VAL_FILT_R\"+str(nb_digits)+\".pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455900, 127) (98665, 127)\n"
     ]
    }
   ],
   "source": [
    "dts_name=\"PARIS_TREND_1D_V5_class_R3_CLIP\"\n",
    "df_class=pd.read_pickle(PATH_DATA_DTS+dts_name+\"_TRAIN.pkl\")\n",
    "df_class_val=pd.read_pickle(PATH_DATA_DTS+dts_name+\"_VAL.pkl\")\n",
    "\n",
    "print(f\"{df_class.shape} {df_class_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455900, 107) (98665, 107)\n"
     ]
    }
   ],
   "source": [
    "# remove useless columns from df_class\n",
    "list_rem=['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME',\n",
    "'lab_perf_20d','lab_perf_50d','lab_perf_10d','lab_perf_5d', 'lab_perf_5d','CODE',\n",
    "'lab_perf_5d_class_3',\n",
    "'lab_perf_5d_class_5',\n",
    "'lab_perf_5d_class_10',\n",
    "'lab_perf_10d_class_3',\n",
    "'lab_perf_10d_class_5',\n",
    "'lab_perf_10d_class_10',\n",
    "'lab_perf_20d_class_3',\n",
    "'lab_perf_20d_class_5', # the label to predict\n",
    "# 'lab_perf_20d_class_10',\n",
    "'lab_perf_50d_class_3',\n",
    "'lab_perf_50d_class_5',\n",
    "'lab_perf_50d_class_10']\n",
    "\n",
    "# remove columns from df_x_train_r don't crash if not in list\n",
    "df_class.drop(columns=list_rem, inplace=True, errors='ignore')\n",
    "df_class_val.drop(columns=list_rem, inplace=True, errors='ignore')\n",
    "\n",
    "print(f\"{df_class.shape} {df_class_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lab_perf_20d_class_10\n",
      "0.0    46448\n",
      "1.0    45837\n",
      "2.0    45473\n",
      "3.0    45017\n",
      "4.0    43939\n",
      "5.0    45248\n",
      "6.0    45673\n",
      "7.0    46008\n",
      "8.0    46364\n",
      "9.0    45893\n",
      "Name: count, dtype: int64\n",
      "lab_perf_20d_class_10\n",
      "0.0    14521\n",
      "1.0    10314\n",
      "2.0     9859\n",
      "3.0     9863\n",
      "4.0     9697\n",
      "5.0     9616\n",
      "6.0     9545\n",
      "7.0     8830\n",
      "8.0     8129\n",
      "9.0     8291\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label='lab_perf_20d_class_10'\n",
    "print(df_class[label].value_counts().sort_index()) # min 43939  >> 43900\n",
    "print(df_class_val[label].value_counts().sort_index()) # min 8129 >> 8100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G:\\\\Python\\\\Data\\\\DTS_FULL\\\\PARIS_TREND_1D_V5_class_R3_CLIP_lab_perf_20d_class_10_Y_VAL.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UNDERSAMPLE THE TRAIN AND VAL AND SAVE DATASET FOR TRAINING\n",
    "list_feat=df_class.columns.values.tolist()\n",
    "list_feat.remove(label)\n",
    "\n",
    "df_x_train, col_y_train = sm.split_df_x_y(\n",
    "    df_in=df_class, list_features=list_feat, str_label=label, drop_na=True)\n",
    "\n",
    "df_x_val, col_y_val = sm.split_df_x_y(\n",
    "    df_in=df_class_val, list_features=list_feat, str_label=label, drop_na=True)\n",
    "\n",
    "#  for classification datasets\n",
    "lim_train=43900\n",
    "lim_val=8100\n",
    "method = RandomUnderSampler(sampling_strategy={0:lim_train,1:lim_train,2:lim_train,3:lim_train,4:lim_train,\n",
    "                                               5:lim_train,6:lim_train,7:lim_train,8:lim_train,9:lim_train}) \n",
    "df_x_train, col_y_train=  method.fit_resample(df_x_train, col_y_train)\n",
    "\n",
    "method = RandomUnderSampler(sampling_strategy={0:lim_val,1:lim_val,2:lim_val,3:lim_val,4:lim_val,\n",
    "                                               5:lim_val,6:lim_val,7:lim_val,8:lim_val,9:lim_val}) \n",
    "df_x_val, col_y_val=  method.fit_resample(df_x_val, col_y_val)\n",
    "\n",
    "joblib.dump(df_x_train, PATH_DATA_DTS+dts_name+\"_\"+label+\"_X_TRAIN.pkl\")\n",
    "joblib.dump(col_y_train, PATH_DATA_DTS+dts_name+\"_\"+label+\"_Y_TRAIN.pkl\")\n",
    "joblib.dump(df_x_val, PATH_DATA_DTS+dts_name+\"_\"+label+\"_X_VAL.pkl\")\n",
    "joblib.dump(col_y_val, PATH_DATA_DTS+dts_name+\"_\"+label+\"_Y_VAL.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(486879, 39)\n",
      "(102506, 39)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['G:\\\\Python\\\\Data\\\\DTS_FULL\\\\PARIS_TREND_1D_20D_REG_V4_X_VAL_FILT_R3.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #ONLY FIRST TIME \n",
    "# list_rem=['perf_pos_ema20_10d','perf_pos_ema20_5d','perf_stoch14_5d','perf_stoch14_dif_5d'\n",
    "# ,'perf_williamsr_14_5d','pos_ema10','pos_ema5','pos_sma10','ret_1d','stoch14_dif','perf_pos_ema200_10d'\n",
    "# ,'pos_avg_vol14','aroon14_down','ret_10d','perf_sma10_5d','perf_adx14_neg_5d','ret_5d'\n",
    "# ,'perf_sma5_5d','perf_pos_ema200_5d','perf_pos_ema10_5d','perf_sma_10_5d','perf_pos_sma10_10d'\n",
    "# ,'stdev20_1d','perf_adx14_pos_5d','perf_pos_ema10_10d','perf_stoch14_signal_5d','pos_sma5_10'\n",
    "# ,'tr_atr14','pos_ema50_perf_5d','pos_ema50_perf_10d','pos_rsi14_sma5','williamsr_14_perf_10d'\n",
    "# ,'rsi14','perf_pos_sma200_10d','perf_pos_sma50_10d','pos_sma5','aroon14_up_lag_5d'\n",
    "# ,'pos_rsi14_sma20','pos_sma10_20','perf_rsi14_10d','perf_ema5_5d','aroon14_dif_lag_5d'\n",
    "# ,'perf_adx14_dif_5d','pos_bb20_hi_lag_5d','perf_pos_sma20_10d','aroon14_dif'\n",
    "# ,'pos_sma5_50','pos_rsi14_sma5_20','perf_rsi14_5d','sma5_rsi14','pos_sma20'\n",
    "# ,'stoch14','perf_sma10_10d','pos_sma5_20','pos_bb20_hi','pos_sma10_50','pos_stdev20_sma5'\n",
    "# ,'perf_sma20_5d','perf_sma50_5d','pos_sma50','aroon14_down_lag_5d','pos_bb20_lo_lag_5d'\n",
    "# ,'pos_bot20','pos_top20','pos_top20_lag_5d','perf_sma_20_5d','pos_bot20_lag_5d','perf_sma_200_5d','pos_sma50_200'\n",
    "# ]\n",
    "\n",
    "# # remove columns from df_x_train_r don't crash if not in list\n",
    "# df_x_train_r.drop(columns=list_rem, inplace=True, errors='ignore')\n",
    "# df_x_val_r.drop(columns=list_rem, inplace=True, errors='ignore')\n",
    "\n",
    "# print(df_x_train_r.shape)\n",
    "# print(df_x_val_r.shape)\n",
    "\n",
    "# # save the 2 df in pkl format\n",
    "# joblib.dump(df_x_train_r, PATH_DATA_DTS+dts_name+\"_X_TRAIN_FILT_R\"+nb_digits+\".pkl\")\n",
    "# joblib.dump(df_x_val_r, PATH_DATA_DTS+dts_name+\"_X_VAL_FILT_R\"+nb_digits+\".pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop from df_x_train_r and df_x_val_r the columns pos_sma50_200 and pos_sma20_200\n",
    "# save list of columns of df_x_train_r in an info file   \n",
    "nb_digits=\"3\"\n",
    "with open(PATH_DATA_DTS+dts_name+\"_X_TRAIN_FILT_R\"+nb_digits+\"_INFO.txt\", \"w\") as f:\n",
    "    for s in df_x_train_r.columns:\n",
    "        f.write(str(s) +\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_x_train_r.shape=(439000, 106) df_x_val_r.shape=(81000, 106) col_y_train.size=439000 col_y_val.size=81000\n"
     ]
    }
   ],
   "source": [
    "# Load datasets before training\n",
    "dts_name=\"PARIS_TREND_1D_V5_class_R3_CLIP\"\n",
    "label=\"lab_perf_20d_class_10\"\n",
    "\n",
    "df_x_train_r = joblib.load(PATH_DATA_DTS+dts_name+\"_\"+label+\"_X_TRAIN.pkl\")\n",
    "col_y_train = joblib.load(PATH_DATA_DTS+dts_name+\"_\"+label+\"_Y_TRAIN.pkl\")\n",
    "df_x_val_r = joblib.load(PATH_DATA_DTS+dts_name+\"_\"+label+\"_X_VAL.pkl\")\n",
    "col_y_val = joblib.load(PATH_DATA_DTS+dts_name+\"_\"+label+\"_Y_VAL.pkl\")\n",
    "\n",
    "print(f\"{df_x_train_r.shape=} {df_x_val_r.shape=} {col_y_train.size=} {col_y_val.size=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_x_train_r.shape=(439000, 59) df_x_val_r.shape=(81000, 59) col_y_train.size=439000 col_y_val.size=81000\n"
     ]
    }
   ],
   "source": [
    "list_keep=['pos_bot_200','pos_ema50_200','adx14','macd_dif','pos_sma50_200','pos_top_200','adx14_neg'\n",
    ",'pos_bot50','adx14_pos','perf_sma200_10d','macd_fast','pos_stdev20_sma20','pos_bot50_lag_10d','perf_sma50_10d'\n",
    ",'sma20_rsi14','pos_sma20_200','perf_adx14_5d','macd_slow','perf_atr14_5d','pos_sma200','pos_sma20_50','adx14_dif'\n",
    ",'pos_bot20_lag_20d','perf_sma20_10d','pos_top50','pos_avg_vol50','stoch14_signal','sma5_rsi14','pos_rsi14_sma5_20'\n",
    ",'pos_sma10_200','pos_top50_lag_10d','pos_bb20_hi_lag_5d','pos_top20_lag_20d','pos_sma5_200','pos_bot20'\n",
    ",'stoch14','pos_bb20_lo_lag_5d','pos_stdev20_sma5','trix12','aroon14_dif','pos_bb20_hi','rsi14','perf_adx14_neg_5d'\n",
    ",'tr_atr14','williamsr_14','pos_bb20_lo','pos_sma50','perf_adx14_pos_5d','perf_stoch14_dif_5d','ret_20d'\n",
    ",'pos_bot20_lag_5d','pos_sma10_50','pos_sma5_50','stdev20_1d','aroon14_dif_lag_5d','pos_top20','perf_sma200_5d'\n",
    ",'perf_sma_200_5d','perf_sma50_5d']\n",
    "\n",
    "# remove columns from df_x_train_r idf not in list_keep, don't crash if not in list\n",
    "df_x_train_r.drop(columns=[col for col in df_x_train_r.columns if col not in list_keep], inplace=True, errors='ignore')\n",
    "df_x_val_r.drop(columns=[col for col in df_x_val_r.columns if col not in list_keep], inplace=True, errors='ignore')\n",
    "\n",
    "print(f\"{df_x_train_r.shape=} {df_x_val_r.shape=} {col_y_train.size=} {col_y_val.size=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print df_x_train_r describe() but with all the columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(df_x_train_r.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIGHTGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : put this in a library\n",
    "# lgbm_mngr.py \n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score,classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "\n",
    "def custom_penalty_score(y_true, y_pred):\n",
    "    # print(f\"{y_true.shape=} {y_pred.shape=}\")\n",
    "    if isinstance(y_true, lgb.Dataset):\n",
    "        y_true = y_true.get_label()\n",
    "    # Convert predicted probabilities to class labels\n",
    "    if y_pred.ndim == 1:\n",
    "        # raise ValueError(f\"Expected 2D array for y_pred, got 1D array with shape {y_pred.shape}\")\n",
    "        y_pred_labels = y_pred\n",
    "    else :\n",
    "        y_pred_labels = np.argmax(y_pred, axis=1)  # Convert predicted probabilities to class labels\n",
    "    if y_true.shape[0] != y_pred_labels.shape[0]:\n",
    "        raise ValueError(f\"Shape mismatch: y_true has shape {y_true.shape} but y_pred_labels has shape {y_pred_labels.shape}\")\n",
    "  \n",
    "    error = (y_true - y_pred_labels) ** 2\n",
    "    return 'custom_penalty', error.mean(), False  # Return the mean squared error (lower is better)\n",
    "\n",
    "# Create a scorer object\n",
    "custom_scorer = metrics.make_scorer(custom_penalty_score, is_higher_better=False)\n",
    "\n",
    "def print_eval_metric(env):\n",
    "    # env is a callback environment that contains information about the training process\n",
    "    result = env.evaluation_result_list\n",
    "    for item in result:\n",
    "        metric_name, dataset_name, metric_value, is_higher_better = item\n",
    "        print(f\"Iteration {env.iteration}: {dataset_name} - {metric_name} = {metric_value}\")\n",
    "\n",
    "def calculate_tree_depth(tree):\n",
    "    if 'leaf_index' in tree:\n",
    "        return 0\n",
    "    else:\n",
    "        left_depth = calculate_tree_depth(tree['left_child'])\n",
    "        right_depth = calculate_tree_depth(tree['right_child'])\n",
    "        return 1 + max(left_depth, right_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for classification datasets !!!!!!!!!\n",
    "\n",
    "device_type='gpu'\n",
    "results_df = pd.DataFrame(columns=['params','accuracy_train', 'accuracy_val','penalty_score',\n",
    "                                   'precision','recall','best_iter','seed','max_max_depth','avg_max_depth'])\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.0001],  # 0.0005 ?\n",
    "    'max_depth': [20,25],  # np.linspace(11,15,3, endpoint=True,dtype=int),\n",
    "    'num_leaves': [47,63,79],  # 1023,1536],#np.linspace(15, 60,10, endpoint=True,dtype=int),\n",
    "    'min_data_in_leaf': [50],\n",
    "    'feature_fraction': [0.25],\n",
    "    'lambda_l1': [0.1,0.2],#[0,0.1,1,5] np.exp(np.random.default_rng().uniform(np.log(1e-4), np.log(10), 20)),\n",
    "    'lambda_l2': [0.5,1],#[0,0.1,1,5]  np.exp(np.random.default_rng().uniform(np.log(1e-4), np.log(10), 20)),\n",
    "}\n",
    "\n",
    "nb_class=10\n",
    "nb_seeds=3\n",
    "n_splits=3\n",
    "method='strat'\n",
    "\n",
    "if method=='time':\n",
    "    scv = TimeSeriesSplit(n_splits=1)\n",
    "elif method=='strat':\n",
    "    scv = StratifiedKFold(n_splits=n_splits, shuffle=False)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "# Generate all combinations of parameters\n",
    "keys, values = zip(*params.items())\n",
    "combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "# Print the list of parameter combinations\n",
    "print(f\"{combinations.__len__()=}\")\n",
    "for combo in combinations[:2]:  # Print only the first 3 combinations for brevity\n",
    "    print(combo)\n",
    "\n",
    "# params=[\n",
    "#     {'num_leaves': 511, 'min_data_in_leaf': 100, 'max_depth': 11, 'learning_rate': 0.01, 'lambda_l2': 0.025, 'lambda_l1': 0.01, 'feature_fraction': 0.4},\n",
    "    # {'num_leaves': 1023, 'min_data_in_leaf': 100, 'max_depth': 15, 'learning_rate': 0.01, 'lambda_l2': 0.5, 'lambda_l1': 0.25, 'feature_fraction': 0.6}\n",
    "#        ]\n",
    "\n",
    "seeds=np.random.default_rng().integers(0,1000,nb_seeds)\n",
    "\n",
    "print(f\"{seeds=}\")\n",
    "# loop over the parameters\n",
    "for param in combinations:\n",
    "    try:\n",
    "        for seed in seeds:\n",
    "            print(f\"{dt.now().strftime('%Y-%m-%d %H:%M:%S')} Try : {param}\")\n",
    "            clf=lgb.LGBMClassifier(objective='multiclass',metric='custom',device_type=device_type,verbosity=-1,\n",
    "                                seed=seed, num_class=nb_class,n_estimators=1000,#np.random.default_rng().integers(0,10000),\n",
    "                                **param)\n",
    "            \n",
    "            for train_index, val_index in scv.split(df_x_train_r, col_y_train):\n",
    "                X_train, X_val = df_x_train_r.iloc[train_index], df_x_train_r.iloc[val_index]\n",
    "                y_train, y_val = col_y_train.iloc[train_index], col_y_train.iloc[val_index]\n",
    "\n",
    "                # train the model with the best parameters and eval set without log\n",
    "                clf.fit(X_train, y_train,eval_set=[(X_val, y_val)],eval_metric=custom_penalty_score,\n",
    "                        callbacks=[lgb.early_stopping(stopping_rounds=20)])#print_eval_metric\n",
    "\n",
    "                print(f\"{dt.now().strftime('%Y-%m-%d %H:%M:%S')} Best iteration: {clf.best_iteration_}\")\n",
    "\n",
    "            y_pred = clf.predict(df_x_train_r)\n",
    "            accuracy_train = accuracy_score(col_y_train, y_pred)\n",
    "            penalty_score=custom_penalty_score(col_y_train, y_pred)\n",
    "            # print(f'Accuracy Train: {accuracy_train} Penalty Train: {penalty_score}')\n",
    "\n",
    "            y_pred = clf.predict(df_x_val_r)\n",
    "            accuracy_val = accuracy_score(col_y_val, y_pred)\n",
    "            penalty_score=custom_penalty_score(col_y_val, y_pred)\n",
    "            # print(f'Accuracy Val: {accuracy_val} Penalty Val: {penalty_score}')\n",
    "            \n",
    "            # Extract precision values\n",
    "            precision_vals = precision_score(col_y_val, y_pred, average=None)\n",
    "            precision_str ='precision:'+'-'.join([f'{i}:{precision_vals[i]:.2f}' for i in range(len(precision_vals))])\n",
    "            \n",
    "            # Extract recall values\n",
    "            recall_vals = recall_score(col_y_val, y_pred, average=None)\n",
    "            recall_str = 'recall:'+'-'.join([f'{i}:{recall_vals[i]:.2f}' for i in range(len(recall_vals))])\n",
    "\n",
    "            # print(classification_report(col_y_val, y_pred))\n",
    "            # print the confusion matrix\n",
    "            print(metrics.confusion_matrix(col_y_val, y_pred))\n",
    "\n",
    "            # Calculate the depth of each tree\n",
    "            booster = clf.booster_\n",
    "            tree_info = booster.dump_model()[\"tree_info\"]\n",
    "            # print(tree_info)\n",
    "            max_depths = [calculate_tree_depth(tree[\"tree_structure\"]) for tree in tree_info]\n",
    "            avg_max_depth = sum(max_depths) / len(max_depths)\n",
    "            max_max_depth = max(max_depths)\n",
    "            # print(f\"Max depth of trees: {avg_max_depth=} {max_max_depth=}\")\n",
    "\n",
    "\n",
    "            # save the values of param and accuracy_val in a dataframe\n",
    "            results_df = pd.concat([results_df, \n",
    "                                    pd.DataFrame([{'params': param,'accuracy_train':round(accuracy_train,3),\n",
    "                                                    'accuracy_val': round(accuracy_val,3),'penalty_score':round(penalty_score[1],3),\n",
    "                                                    'precision':precision_str,'recall':recall_str,'best_iter':clf.best_iteration_,\n",
    "                                                    'seed':seed,'max_max_depth':max_max_depth,'avg_max_depth':avg_max_depth}])],\n",
    "                                                    ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error with parameters: {param}\")\n",
    "        print(f\"Error message: {e}\")   \n",
    "\n",
    "    \n",
    "\n",
    "# save tje results in a file\n",
    "results_df.to_csv(PATH_DATA_DTS+dts_name+\"_LGBM_RESULTS_CLASS_10_V5_c.csv\", sep=\",\")\n",
    "# save the model\n",
    "\n",
    "# joblib.dump(clf, PATH_DATA_DTS+dts_name+\"_LGBM_MODEL_R2.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(PATH_DATA_DTS+dts_name+\"_LGBM_RESULTS_CLASS_10_V5_a.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's custom_penalty: 15.829\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's custom_penalty: 16.6834\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's custom_penalty: 16.6917\n",
      "Accuracy Val: 0.14679012345679013 Penalty Val: ('custom_penalty', 17.555234567901234, False)\n",
      "precision:0:0.16-1:0.12-2:0.11-3:0.13-4:0.17-5:0.13-6:0.12-7:0.11-8:0.13-9:0.21\n",
      "recall:0:0.35-1:0.06-2:0.05-3:0.08-4:0.17-5:0.17-6:0.12-7:0.09-8:0.11-9:0.26\n",
      "[[2808  447  297  320  362  636  627  621  623 1359]\n",
      " [1806  476  453  473  710  964  818  760  622 1018]\n",
      " [1407  433  440  619  972 1159  903  707  618  842]\n",
      " [1223  375  397  663 1085 1287  953  722  596  799]\n",
      " [1131  335  399  590 1379 1365  874  716  608  703]\n",
      " [1117  315  431  658 1104 1401  957  787  659  671]\n",
      " [1332  387  416  585  915 1342 1012  745  676  690]\n",
      " [1470  400  421  488  847 1183  915  725  797  854]\n",
      " [1978  475  422  379  570  916  744  668  904 1044]\n",
      " [2904  349  246  234  214  499  421  414  737 2082]]\n",
      "Max depth of trees: avg_max_depth=12.005263157894737 max_max_depth=20\n"
     ]
    }
   ],
   "source": [
    "#  TEST 1 SET OF PARAMETERS for classification datasets !!!!!!!!!\n",
    "device_type='gpu'\n",
    "param={'learning_rate': 0.0001, 'max_depth': 20, 'num_leaves': 47, 'min_data_in_leaf': 50, 'feature_fraction': 0.25, 'lambda_l1': 0.2, 'lambda_l2': 1}\n",
    "seed=464\n",
    "nb_class=10\n",
    "n_splits=3\n",
    "method='strat'\n",
    "\n",
    "if method=='time':\n",
    "    scv = TimeSeriesSplit(n_splits=1)\n",
    "elif method=='strat':\n",
    "    scv = StratifiedKFold(n_splits=n_splits, shuffle=False)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "clf=lgb.LGBMClassifier(objective='multiclass',metric='custom',device_type=device_type,verbosity=-1,\n",
    "                                seed=seed, num_class=nb_class,n_estimators=1000,#np.random.default_rng().integers(0,10000),\n",
    "                                **param)\n",
    "\n",
    "for train_index, val_index in scv.split(df_x_train_r, col_y_train):\n",
    "                X_train, X_val = df_x_train_r.iloc[train_index], df_x_train_r.iloc[val_index]\n",
    "                y_train, y_val = col_y_train.iloc[train_index], col_y_train.iloc[val_index]\n",
    "\n",
    "                # train the model with the best parameters and eval set without log\n",
    "                clf.fit(X_train, y_train,eval_set=[(X_val, y_val)],eval_metric=custom_penalty_score,\n",
    "                        callbacks=[lgb.early_stopping(stopping_rounds=20)])#print_eval_metric\n",
    "# clf.fit(df_x_train_r, col_y_train, eval_set=[(df_x_val_r, col_y_val)],eval_metric=custom_penalty_score,\n",
    "#         callbacks=[lgb.early_stopping(stopping_rounds=20)])#print_eval_metric\n",
    "\n",
    "y_pred = clf.predict(df_x_train_r)\n",
    "accuracy_train = accuracy_score(col_y_train, y_pred)\n",
    "penalty_score=custom_penalty_score(col_y_train, y_pred)\n",
    "# print(f'Accuracy Train: {accuracy_train} Penalty Train: {penalty_score}')\n",
    "\n",
    "y_pred = clf.predict(df_x_val_r)\n",
    "accuracy_val = accuracy_score(col_y_val, y_pred)\n",
    "penalty_score=custom_penalty_score(col_y_val, y_pred)\n",
    "print(f'Accuracy Val: {accuracy_val} Penalty Val: {penalty_score}')\n",
    "\n",
    "# Extract precision values\n",
    "precision_vals = precision_score(col_y_val, y_pred, average=None)\n",
    "precision_str ='precision:'+'-'.join([f'{i}:{precision_vals[i]:.2f}' for i in range(len(precision_vals))])\n",
    "print(precision_str)\n",
    "\n",
    "# Extract recall values\n",
    "recall_vals = recall_score(col_y_val, y_pred, average=None)\n",
    "recall_str = 'recall:'+'-'.join([f'{i}:{recall_vals[i]:.2f}' for i in range(len(recall_vals))])\n",
    "print(recall_str)\n",
    "\n",
    "print(metrics.confusion_matrix(col_y_val, y_pred))\n",
    "\n",
    "# Calculate the depth of each tree\n",
    "booster = clf.booster_\n",
    "tree_info = booster.dump_model()[\"tree_info\"]\n",
    "# print(tree_info)\n",
    "max_depths = [calculate_tree_depth(tree[\"tree_structure\"]) for tree in tree_info]\n",
    "avg_max_depth = sum(max_depths) / len(max_depths)\n",
    "max_max_depth = max(max_depths)\n",
    "print(f\"Max depth of trees: {avg_max_depth=} {max_max_depth=}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5 2.8722845946656324\n",
      "4.5 2.872299053564809\n"
     ]
    }
   ],
   "source": [
    "# calculate the mean and std of col_y_train and col_y_val\n",
    "print(f\"{col_y_train.mean()} {col_y_train.std()}\")\n",
    "print(f\"{col_y_val.mean()} {col_y_val.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  SAVE THE MODEL\n",
    "\n",
    "model_name=dts_name+\"_LGBM_MODEL_CLAS10_R3_2503_V1\"\n",
    "joblib.dump(clf, PATH_DATA_DTS+model_name+\".pkl\")\n",
    "\n",
    "#  Save the metadata of the model in a file : all the params and the results\n",
    "metadata = {'params': param,'accuracy_train':round(accuracy_train,3),\n",
    "            'accuracy_val': round(accuracy_val,3),'penalty_score':round(penalty_score[1],3),\n",
    "            'precision':precision_str,'recall':recall_str,'best_iter':clf.best_iteration_,\n",
    "            'seed':seed,'max_max_depth':max_max_depth,'avg_max_depth':avg_max_depth}\n",
    "#  in metadata, add the list of features and label\n",
    "metadata['features'] = df_x_train_r.columns\n",
    "metadata['label'] = label\n",
    "\n",
    "# save the metadata in a file\n",
    "with open(PATH_DATA_DTS+model_name+\".txt\", \"w\") as f:\n",
    "    for key in metadata:\n",
    "        f.write(f\"{key} : {metadata[key]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  print the feature importance\n",
    "feature_imp = pd.DataFrame(sorted(zip(clf.feature_importances_,df_x_train_r.columns)), columns=['Value','Feature'])\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# save the feature importance in a file\n",
    "feature_imp.to_csv(PATH_DATA_DTS+dts_name+\"_LGBM_FEATURES_D.csv\", sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print la map of the model\n",
    "lgb.plot_importance(clf,importance_type='split',max_num_features=10,figsize=(20,10),title='Feature importance(split)')\n",
    "lgb.plot_importance(clf,importance_type='gain',max_num_features=10,figsize=(20,10),title='Feature importance(gain)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(df_x_train_r)\n",
    "accuracy = accuracy_score(col_y_train, y_pred)\n",
    "print(f'Accuracy Train: {accuracy}')\n",
    "\n",
    "\n",
    "y_pred = clf.predict(df_x_val_r)\n",
    "accuracy = accuracy_score(col_y_val, y_pred)\n",
    "print(f'Accuracy Val: {accuracy}')\n",
    "print(classification_report(col_y_val, y_pred))\n",
    "# print the confusion matrix\n",
    "print(metrics.confusion_matrix(col_y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lgb.plot_importance(clf,max_num_features=40, figsize=(7,6), title=\"LightGBM Feature Importance\")\n",
    "plt.show()\n",
    "# save features importance in a file\n",
    "feature_imp=pd.DataFrame()\n",
    "feature_imp['features']=df_x_train_r.columns\n",
    "feature_imp['importance']=clf.feature_importances_\n",
    "feature_imp.to_csv(PATH_DATA_DTS+dts_name+\"_LGBM_FEATURE_IMPORTANCE.csv\", sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(device_type='gpu', feature_fraction=0.25, lambda_l1=0,\n",
      "               lambda_l2=0.1, learning_rate=0.0005, max_depth=25,\n",
      "               metric='custom', min_data_in_leaf=100, n_estimators=1000,\n",
      "               num_class=5, num_leaves=63, objective='multiclass', seed=323,\n",
      "               verbosity=-1)\n"
     ]
    }
   ],
   "source": [
    "# load the model PARIS_TREND_1D_20D_V3_LGBM_MODEL_R2.pkl and print the characteristics\n",
    "clf = joblib.load(PATH_DATA_DTS+\"PARIS_TREND_1D_V5_class_R3_CLIP_LGBM_MODEL_CLAS5_R3_2503_V1.pkl\")\n",
    "print(clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPARATION FOR BACKTEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.shape=(455900, 127) df_val.shape=(98665, 127) df_conf.shape=(117005, 127)\n"
     ]
    }
   ],
   "source": [
    "# Load datasets before training\n",
    "dts_name=\"PARIS_TREND_1D_V5_class_R3_CLIP\"\n",
    "\n",
    "df_train = joblib.load(PATH_DATA_DTS+dts_name+\"_TRAIN.pkl\")\n",
    "df_val = joblib.load(PATH_DATA_DTS+dts_name+\"_VAL.pkl\")\n",
    "df_conf = joblib.load(PATH_DATA_DTS+dts_name+\"_CONF.pkl\")\n",
    "\n",
    "print(f\"{df_train.shape=} {df_val.shape=} {df_conf.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455900, 107) (98665, 107) (117005, 107)\n",
      "df_x_train_10.shape=(455900, 59) df_x_val_10.shape=(98665, 59) df_x_conf_10.shape=(117005, 59) col_y_train_10.size=455900 col_y_val_10.size=98665 col_y_conf_10.size=117005\n"
     ]
    }
   ],
   "source": [
    "label=\"lab_perf_20d_class_10\"\n",
    "\n",
    "df_train_w=df_train.copy()\n",
    "df_val_w=df_val.copy()\n",
    "df_conf_w=df_conf.copy()\n",
    "\n",
    "list_rem=['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME',\n",
    "'lab_perf_20d','lab_perf_50d','lab_perf_10d','lab_perf_5d', 'lab_perf_5d','CODE',\n",
    "'lab_perf_5d_class_3',\n",
    "'lab_perf_5d_class_5',\n",
    "'lab_perf_5d_class_10',\n",
    "'lab_perf_10d_class_3',\n",
    "'lab_perf_10d_class_5',\n",
    "'lab_perf_10d_class_10',\n",
    "'lab_perf_20d_class_3',\n",
    "'lab_perf_20d_class_5', # the label to predict\n",
    "# 'lab_perf_20d_class_10',\n",
    "'lab_perf_50d_class_3',\n",
    "'lab_perf_50d_class_5',\n",
    "'lab_perf_50d_class_10']\n",
    "\n",
    "# remove columns from df_x_train_r don't crash if not in list\n",
    "df_train_w.drop(columns=list_rem, inplace=True, errors='ignore')\n",
    "df_val_w.drop(columns=list_rem, inplace=True, errors='ignore')\n",
    "df_conf_w.drop(columns=list_rem, inplace=True, errors='ignore')\n",
    "\n",
    "print(f\"{df_train_w.shape} {df_val_w.shape} {df_conf_w.shape}\")\n",
    "\n",
    "list_feat=df_train_w.columns.values.tolist()\n",
    "list_feat.remove(label)\n",
    "\n",
    "df_x_train_10, col_y_train_10 = sm.split_df_x_y(\n",
    "    df_in=df_train_w, list_features=list_feat, str_label=label, drop_na=False)\n",
    "\n",
    "df_x_val_10, col_y_val_10 = sm.split_df_x_y(\n",
    "    df_in=df_val_w, list_features=list_feat, str_label=label, drop_na=False)\n",
    "\n",
    "df_x_conf_10, col_y_conf_10 = sm.split_df_x_y(\n",
    "    df_in=df_conf_w, list_features=list_feat, str_label=label, drop_na=False)\n",
    "\n",
    "\n",
    "list_keep=['pos_bot_200','pos_ema50_200','adx14','macd_dif','pos_sma50_200','pos_top_200','adx14_neg'\n",
    ",'pos_bot50','adx14_pos','perf_sma200_10d','macd_fast','pos_stdev20_sma20','pos_bot50_lag_10d','perf_sma50_10d'\n",
    ",'sma20_rsi14','pos_sma20_200','perf_adx14_5d','macd_slow','perf_atr14_5d','pos_sma200','pos_sma20_50','adx14_dif'\n",
    ",'pos_bot20_lag_20d','perf_sma20_10d','pos_top50','pos_avg_vol50','stoch14_signal','sma5_rsi14','pos_rsi14_sma5_20'\n",
    ",'pos_sma10_200','pos_top50_lag_10d','pos_bb20_hi_lag_5d','pos_top20_lag_20d','pos_sma5_200','pos_bot20'\n",
    ",'stoch14','pos_bb20_lo_lag_5d','pos_stdev20_sma5','trix12','aroon14_dif','pos_bb20_hi','rsi14','perf_adx14_neg_5d'\n",
    ",'tr_atr14','williamsr_14','pos_bb20_lo','pos_sma50','perf_adx14_pos_5d','perf_stoch14_dif_5d','ret_20d'\n",
    ",'pos_bot20_lag_5d','pos_sma10_50','pos_sma5_50','stdev20_1d','aroon14_dif_lag_5d','pos_top20','perf_sma200_5d'\n",
    ",'perf_sma_200_5d','perf_sma50_5d']\n",
    "\n",
    "# remove columns from df_x_train_r idf not in list_keep, don't crash if not in list\n",
    "df_x_train_10.drop(columns=[col for col in df_x_train_10.columns if col not in list_keep], inplace=True, errors='ignore')\n",
    "df_x_val_10.drop(columns=[col for col in df_x_val_10.columns if col not in list_keep], inplace=True, errors='ignore')\n",
    "df_x_conf_10.drop(columns=[col for col in df_x_conf_10.columns if col not in list_keep], inplace=True, errors='ignore')\n",
    "\n",
    "print(f\"{df_x_train_10.shape=} {df_x_val_10.shape=} {df_x_conf_10.shape=} {col_y_train_10.size=} {col_y_val_10.size=} {col_y_conf_10.size=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455900, 107) (98665, 107) (117005, 107)\n",
      "df_x_train_5.shape=(455900, 59) df_x_val_5.shape=(98665, 59) df_x_conf_5.shape=(117005, 59) col_y_train_5.size=455900 col_y_val_5.size=98665 col_y_conf_5.size=117005\n"
     ]
    }
   ],
   "source": [
    "label=\"lab_perf_20d_class_5\"\n",
    "\n",
    "df_train_w=df_train.copy()\n",
    "df_val_w=df_val.copy()\n",
    "df_conf_w=df_conf.copy()\n",
    "\n",
    "list_rem=['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME',\n",
    "'lab_perf_20d','lab_perf_50d','lab_perf_10d','lab_perf_5d', 'lab_perf_5d','CODE',\n",
    "'lab_perf_5d_class_3',\n",
    "'lab_perf_5d_class_5',\n",
    "'lab_perf_5d_class_10',\n",
    "'lab_perf_10d_class_3',\n",
    "'lab_perf_10d_class_5',\n",
    "'lab_perf_10d_class_10',\n",
    "'lab_perf_20d_class_3',\n",
    "# 'lab_perf_20d_class_5', # the label to predict\n",
    "'lab_perf_20d_class_10',\n",
    "'lab_perf_50d_class_3',\n",
    "'lab_perf_50d_class_5',\n",
    "'lab_perf_50d_class_10']\n",
    "\n",
    "# remove columns from df_x_train_r don't crash if not in list\n",
    "df_train_w.drop(columns=list_rem, inplace=True, errors='ignore')\n",
    "df_val_w.drop(columns=list_rem, inplace=True, errors='ignore')\n",
    "df_conf_w.drop(columns=list_rem, inplace=True, errors='ignore')\n",
    "\n",
    "print(f\"{df_train_w.shape} {df_val_w.shape} {df_conf_w.shape}\")\n",
    "\n",
    "list_feat=df_train_w.columns.values.tolist()\n",
    "list_feat.remove(label)\n",
    "\n",
    "df_x_train_5, col_y_train_5 = sm.split_df_x_y(\n",
    "    df_in=df_train_w, list_features=list_feat, str_label=label, drop_na=False)\n",
    "\n",
    "df_x_val_5, col_y_val_5 = sm.split_df_x_y(\n",
    "    df_in=df_val_w, list_features=list_feat, str_label=label, drop_na=False)\n",
    "\n",
    "df_x_conf_5, col_y_conf_5 = sm.split_df_x_y(\n",
    "    df_in=df_conf_w, list_features=list_feat, str_label=label, drop_na=False)\n",
    "\n",
    "\n",
    "list_keep=['pos_bot_200','pos_ema50_200','adx14','macd_dif','pos_sma50_200','pos_top_200','adx14_neg'\n",
    ",'pos_bot50','adx14_pos','perf_sma200_10d','macd_fast','pos_stdev20_sma20','pos_bot50_lag_10d','perf_sma50_10d'\n",
    ",'sma20_rsi14','pos_sma20_200','perf_adx14_5d','macd_slow','perf_atr14_5d','pos_sma200','pos_sma20_50','adx14_dif'\n",
    ",'pos_bot20_lag_20d','perf_sma20_10d','pos_top50','pos_avg_vol50','stoch14_signal','sma5_rsi14','pos_rsi14_sma5_20'\n",
    ",'pos_sma10_200','pos_top50_lag_10d','pos_bb20_hi_lag_5d','pos_top20_lag_20d','pos_sma5_200','pos_bot20'\n",
    ",'stoch14','pos_bb20_lo_lag_5d','pos_stdev20_sma5','trix12','aroon14_dif','pos_bb20_hi','rsi14','perf_adx14_neg_5d'\n",
    ",'tr_atr14','williamsr_14','pos_bb20_lo','pos_sma50','perf_adx14_pos_5d','perf_stoch14_dif_5d','ret_20d'\n",
    ",'pos_bot20_lag_5d','pos_sma10_50','pos_sma5_50','stdev20_1d','aroon14_dif_lag_5d','pos_top20','perf_sma200_5d'\n",
    ",'perf_sma_200_5d','perf_sma50_5d']\n",
    "\n",
    "# remove columns from df_x_train_r idf not in list_keep, don't crash if not in list\n",
    "df_x_train_5.drop(columns=[col for col in df_x_train_5.columns if col not in list_keep], inplace=True, errors='ignore')\n",
    "df_x_val_5.drop(columns=[col for col in df_x_val_5.columns if col not in list_keep], inplace=True, errors='ignore')\n",
    "df_x_conf_5.drop(columns=[col for col in df_x_conf_5.columns if col not in list_keep], inplace=True, errors='ignore')\n",
    "\n",
    "print(f\"{df_x_train_5.shape=} {df_x_val_5.shape=} {df_x_conf_5.shape=} {col_y_train_5.size=} {col_y_val_5.size=} {col_y_conf_5.size=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the indices are aligned\n",
    "assert df_train.index.equals(df_x_train_10.index), \"Row order is not consistent!\"\n",
    "assert df_train.index.equals(df_x_train_5.index), \"Row order is not consistent!\"\n",
    "assert df_val.index.equals(df_x_val_10.index), \"Row order is not consistent!\"\n",
    "assert df_val.index.equals(df_x_val_5.index), \"Row order is not consistent!\"\n",
    "assert df_conf.index.equals(df_x_conf_10.index), \"Row order is not consistent!\"\n",
    "assert df_conf.index.equals(df_x_conf_5.index), \"Row order is not consistent!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(device_type='gpu', feature_fraction=0.25, lambda_l1=0.2,\n",
      "               lambda_l2=1, learning_rate=0.0001, max_depth=20, metric='custom',\n",
      "               min_data_in_leaf=50, n_estimators=1000, num_class=10,\n",
      "               num_leaves=47, objective='multiclass', seed=464, verbosity=-1)\n",
      "LGBMClassifier(device_type='gpu', feature_fraction=0.25, lambda_l1=0,\n",
      "               lambda_l2=0.1, learning_rate=0.0005, max_depth=25,\n",
      "               metric='custom', min_data_in_leaf=100, n_estimators=1000,\n",
      "               num_class=5, num_leaves=63, objective='multiclass', seed=323,\n",
      "               verbosity=-1)\n"
     ]
    }
   ],
   "source": [
    "clf_10 = joblib.load(PATH_DATA_DTS+\"PARIS_TREND_1D_V5_class_R3_CLIP_LGBM_MODEL_CLAS10_R3_2503_V1.pkl\")\n",
    "print(clf_10)\n",
    "\n",
    "clf_5 = joblib.load(PATH_DATA_DTS+\"PARIS_TREND_1D_V5_class_R3_CLIP_LGBM_MODEL_CLAS5_R3_2503_V1.pkl\")\n",
    "print(clf_5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.shape=(455900, 131) df_val.shape=(98665, 131) df_conf.shape=(117005, 131)\n"
     ]
    }
   ],
   "source": [
    "# predict the values of the 2 models\n",
    "df_train['predict_10']=clf_10.predict(df_x_train_10)\n",
    "df_train['predict_5']=clf_5.predict(df_x_train_5)\n",
    "df_val['predict_10']=clf_10.predict(df_x_val_10)\n",
    "df_val['predict_5']=clf_5.predict(df_x_val_5)\n",
    "df_conf['predict_10']=clf_10.predict(df_x_conf_10)\n",
    "df_conf['predict_5']=clf_5.predict(df_x_conf_5)\n",
    "\n",
    "df_train['predict_10_proba'] = clf_10.predict_proba(df_x_train_10).tolist()\n",
    "df_train['predict_5_proba'] = clf_5.predict_proba(df_x_train_5).tolist()\n",
    "df_val['predict_10_proba'] = clf_10.predict_proba(df_x_val_10).tolist()\n",
    "df_val['predict_5_proba'] = clf_5.predict_proba(df_x_val_5).tolist()\n",
    "df_conf['predict_10_proba'] = clf_10.predict_proba(df_x_conf_10).tolist()\n",
    "df_conf['predict_5_proba'] = clf_5.predict_proba(df_x_conf_5).tolist()\n",
    "\n",
    "print(f\"{df_train.shape=} {df_val.shape=} {df_conf.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all.shape=(671570, 132)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['G:\\\\Python\\\\Data\\\\DTS_FULL\\\\PARIS_TREND_1D_V5_lab_20_class_5_10_PREDICT_ALL.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['PART']='TRAIN'\n",
    "df_val['PART']='VAL'\n",
    "df_conf['PART']='CONF'\n",
    "\n",
    "df_all=pd.concat([df_train,df_val,df_conf],axis=0)\n",
    "print(f\"{df_all.shape=}\")\n",
    "# save the df_all in a file\n",
    "joblib.dump(df_all, PATH_DATA_DTS+\"PARIS_TREND_1D_V5_lab_20_class_5_10_PREDICT_ALL.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print list of columns and index of df_all in a file\n",
    "with open(PATH_DATA_DTS+\"PARIS_TREND_1D_V5_lab_20_class_5_10_PREDICT_ALL_INFO.txt\", \"w\") as f:\n",
    "    f.write(f\"Columns:\\n{list(df_all.columns)}\\n\")\n",
    "    f.write(f\"Index:\\n{list(df_all.index)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all.shape=(671570, 132)\n"
     ]
    }
   ],
   "source": [
    "df_all=joblib.load(PATH_DATA_DTS+\"PARIS_TREND_1D_V5_lab_20_class_5_10_PREDICT_ALL.pkl\")\n",
    "print(f\"{df_all.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all_ana.shape=(671570, 9)\n"
     ]
    }
   ],
   "source": [
    "df_all_ana=df_all.copy()\n",
    "col_keep=['pos_sma20_200','predict_10','predict_5','predict_10_proba','predict_5_proba','PART',\n",
    "          'lab_perf_20d','lab_perf_20d_class_5', 'lab_perf_20d_class_10']\n",
    "df_all_ana.drop(columns=[col for col in df_all_ana.columns if col not in col_keep], inplace=True, errors='ignore')\n",
    "print(f\"{df_all_ana.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO replace by lgbm_mngr.py\n",
    "def expand_probabilities(df, column_prefix, proba_column, num_classes):\n",
    "    \"\"\"\n",
    "    Expands a column of probabilities into separate columns for each class.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the probabilities column.\n",
    "    column_prefix (str): The prefix for the new columns (e.g., 'predict_10_proba').\n",
    "    proba_column (str): The name of the column containing the probabilities.\n",
    "    num_classes (int): The number of classes (length of the probability array).\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The updated DataFrame with expanded probability columns.\n",
    "    \"\"\"\n",
    "    for i in range(num_classes):\n",
    "        df[f'{column_prefix}_{i}'] = df[proba_column].apply(lambda x: x[i]).round(5)\n",
    "    return df\n",
    "\n",
    "# Expand probabilities for predict_10_proba\n",
    "df_all_ana = expand_probabilities(df_all_ana, 'predict_10_proba', 'predict_10_proba', 10)\n",
    "\n",
    "# Expand probabilities for predict_5_proba\n",
    "df_all_ana = expand_probabilities(df_all_ana, 'predict_5_proba', 'predict_5_proba', 5)\n",
    "\n",
    "# Print the first few rows to verify\n",
    "print(df_all_ana.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_10_proba_0    0.100285\n",
      "predict_10_proba_1    0.100040\n",
      "predict_10_proba_2    0.099894\n",
      "predict_10_proba_3    0.099835\n",
      "predict_10_proba_4    0.099813\n",
      "predict_10_proba_5    0.099797\n",
      "predict_10_proba_6    0.099845\n",
      "predict_10_proba_7    0.099877\n",
      "predict_10_proba_8    0.100016\n",
      "predict_10_proba_9    0.100598\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# if predict_10=9 what is the mean of each predict_10_proba_i\n",
    "# print(df_all_ana[df_all_ana['predict_10']==9].loc[:, 'predict_10_proba_0':'predict_10_proba_9'].mean())\n",
    "\n",
    "print(df_all_ana[df_all_ana['predict_10']==9].loc[:, 'predict_10_proba_0':'predict_10_proba_9'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for class 5 and predict_5 in (3,4), create a new df aggregated by PART, predict_5, lab_perf_20d_class_5\n",
    "# and calculate the count of line, mean of each predict_5_proba_i\n",
    "limit =0.202 # keep 0.202 instead of 0.2015\n",
    "df_w=df_all_ana[df_all_ana['predict_5_proba_4']>limit]\n",
    "df_all_ana_5=df_w[(df_w['predict_5'].isin([3,4])) ].groupby(['PART','predict_5','lab_perf_20d_class_5']).agg(\n",
    "    count=('predict_5','count'),\n",
    "    mean_0=('predict_5_proba_0','mean'),\n",
    "    mean_1=('predict_5_proba_1','mean'),\n",
    "    mean_2=('predict_5_proba_2','mean'),\n",
    "    mean_3=('predict_5_proba_3','mean'),\n",
    "    mean_4=('predict_5_proba_4','mean')\n",
    ").reset_index()\n",
    "df_all_ana_5.to_csv(PATH_DATA_DTS+\"PARIS_TREND_1D_V5_lab_20_class_5_10_PREDICT_5_3.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for class 10 and predict_10 in (8,9), create a new df aggregated by PART, predict_10, lab_perf_20d_class_10\n",
    "# and calculate the count of line, mean of each predict_10_proba_i\n",
    "limit =0.101 # keep \n",
    "df_w = df_all_ana[(df_all_ana['predict_10_proba_9'] > limit) | (df_all_ana['predict_10_proba_8'] > limit)]\n",
    "df_all_ana_10=df_w[(df_w['predict_10'].isin([8,9])) ].groupby(['PART','predict_10','lab_perf_20d_class_10']).agg(\n",
    "    count=('predict_10','count'),\n",
    "    mean_0=('predict_10_proba_0','mean'),\n",
    "    mean_1=('predict_10_proba_1','mean'),\n",
    "    mean_2=('predict_10_proba_2','mean'),\n",
    "    mean_3=('predict_10_proba_3','mean'),\n",
    "    mean_4=('predict_10_proba_4','mean'),\n",
    "    mean_5=('predict_10_proba_5','mean'),\n",
    "    mean_6=('predict_10_proba_6','mean'),\n",
    "    mean_7=('predict_10_proba_7','mean'),\n",
    "    mean_8=('predict_10_proba_8','mean'),\n",
    "    mean_9=('predict_10_proba_9','mean')\n",
    ").reset_index()\n",
    "\n",
    "df_all_ana_10.to_csv(PATH_DATA_DTS+\"PARIS_TREND_1D_V5_lab_20_class_5_10_PREDICT_10_2.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conf=df_all_ana[df_all_ana['PART']=='CONF']\n",
    "# df_conf_c5_4=df_conf[df_conf['predict_5']==4]\n",
    "df_conf_c10_9=df_conf[df_conf['predict_10']==9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a bar chart from df_conf_c5_4 with a serie by lab_perf_20d_class_5 [0-4] \n",
    "# X will the proba in 10 groupsand Y the count of line\n",
    "# bins = np.linspace(0.199, 0.21, 11)\n",
    "# df_conf_c5_4['predict_5_proba_4_bins'] = pd.cut(df_conf_c5_4['predict_5_proba_4'], bins=bins, include_lowest=True)\n",
    "# bar_data = df_conf_c5_4.groupby(['predict_5_proba_4_bins', 'lab_perf_20d_class_5']).size().unstack(1)\n",
    "\n",
    "bins = np.linspace(0.0995, 0.1035, 11)\n",
    "df_conf_c10_9['predict_10_proba_9_bins'] = pd.cut(df_conf_c10_9['predict_10_proba_9'], bins=bins, include_lowest=True)\n",
    "bar_data = df_conf_c10_9.groupby(['predict_10_proba_9_bins', 'lab_perf_20d_class_10']).size().unstack(1)\n",
    "\n",
    "\n",
    "# Plot the grouped bar chart\n",
    "bar_data.plot(kind='bar', figsize=(12, 6))\n",
    "plt.xlabel('Probability Bins')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Bar Chart of Predict_C_Proba_X by Lab_Perf_20d_Class_C')\n",
    "plt.legend(title='lab_perf_20d_class')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_stock_infos.shape=(403, 8)\n",
      "   SK_SYMBOL     CODE                    NAME   TYPE  REGION CODE_YAHOO  \\\n",
      "0         12   2MX.PA             2MX ORGANIC  Stock  France     2MX.PA   \n",
      "1         13   AAA.PA  ALAN ALLMAN ASSOCIATES  Stock  France     AAA.PA   \n",
      "2         14  ABCA.PA           ABC ARBITRAGE  Stock  France    ABCA.PA   \n",
      "3         15  ABEO.PA                    ABEO  Stock  France    ABEO.PA   \n",
      "4         16  ABIO.PA                 ALBIOMA  Stock  France    ABIO.PA   \n",
      "\n",
      "   TRADABLE SHARESOUTSTANDING  \n",
      "0         1              None  \n",
      "1         0          45675754  \n",
      "2         1          59608879  \n",
      "3         1           7543305  \n",
      "4         1          32370737  \n"
     ]
    }
   ],
   "source": [
    "# get stock info with get_info_all_stock\n",
    "\n",
    "df_stock_infos=sio.get_info_all_stock(con_fwk )\n",
    "print(f\"{df_stock_infos.shape=}\")\n",
    "print(df_stock_infos.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        OPEN    HIGH     LOW   CLOSE   VOLUME  pos_sma20  \\\n",
      "OPEN_DATETIME CODE                                                         \n",
      "1991-10-23    BOI.PA  0.6832  0.6832  0.6832  0.6832    640.0     -0.030   \n",
      "1991-10-24    BOI.PA  0.6635  0.6635  0.6635  0.6635   7840.0     -0.054   \n",
      "1991-10-25    BOI.PA  0.6635  0.6635  0.6635  0.6635   7744.0     -0.050   \n",
      "1991-10-28    BOI.PA  0.6543  0.6543  0.6543  0.6543  14848.0     -0.059   \n",
      "1991-10-29    BOI.PA  0.6622  0.6622  0.6622  0.6622    800.0     -0.043   \n",
      "\n",
      "                      pos_sma50  pos_sma200  pos_sma50_200  pos_sma20_50  ...  \\\n",
      "OPEN_DATETIME CODE                                                        ...   \n",
      "1991-10-23    BOI.PA     -0.046       0.085          0.138        -0.016  ...   \n",
      "1991-10-24    BOI.PA     -0.073       0.053          0.136        -0.019  ...   \n",
      "1991-10-25    BOI.PA     -0.071       0.053          0.134        -0.022  ...   \n",
      "1991-10-28    BOI.PA     -0.083       0.037          0.131        -0.026  ...   \n",
      "1991-10-29    BOI.PA     -0.071       0.049          0.129        -0.029  ...   \n",
      "\n",
      "                      lab_perf_50d_class_5  lab_perf_50d_class_10  predict_10  \\\n",
      "OPEN_DATETIME CODE                                                              \n",
      "1991-10-23    BOI.PA                   1.0                    3.0         6.0   \n",
      "1991-10-24    BOI.PA                   1.0                    2.0         8.0   \n",
      "1991-10-25    BOI.PA                   1.0                    3.0         6.0   \n",
      "1991-10-28    BOI.PA                   2.0                    5.0         9.0   \n",
      "1991-10-29    BOI.PA                   2.0                    4.0         8.0   \n",
      "\n",
      "                      predict_5  \\\n",
      "OPEN_DATETIME CODE                \n",
      "1991-10-23    BOI.PA        1.0   \n",
      "1991-10-24    BOI.PA        4.0   \n",
      "1991-10-25    BOI.PA        4.0   \n",
      "1991-10-28    BOI.PA        3.0   \n",
      "1991-10-29    BOI.PA        4.0   \n",
      "\n",
      "                                                       predict_10_proba  \\\n",
      "OPEN_DATETIME CODE                                                        \n",
      "1991-10-23    BOI.PA  [0.09985782399798895, 0.09992670388165456, 0.1...   \n",
      "1991-10-24    BOI.PA  [0.10004667817075666, 0.0998982506703846, 0.09...   \n",
      "1991-10-25    BOI.PA  [0.10002173869508071, 0.09990738056821478, 0.0...   \n",
      "1991-10-28    BOI.PA  [0.10002642307660348, 0.09988535349790527, 0.0...   \n",
      "1991-10-29    BOI.PA  [0.10000389870274415, 0.09989718304586509, 0.0...   \n",
      "\n",
      "                                                        predict_5_proba  \\\n",
      "OPEN_DATETIME CODE                                                        \n",
      "1991-10-23    BOI.PA  [0.19909589227087685, 0.20071967485772987, 0.1...   \n",
      "1991-10-24    BOI.PA  [0.19938673862426753, 0.19926126592536392, 0.1...   \n",
      "1991-10-25    BOI.PA  [0.19920730275897847, 0.19926594602352998, 0.1...   \n",
      "1991-10-28    BOI.PA  [0.19942715141097156, 0.19882110780624856, 0.1...   \n",
      "1991-10-29    BOI.PA  [0.19942952202688463, 0.1995544997359649, 0.19...   \n",
      "\n",
      "                       PART  SHARESOUTSTANDING    NAME  TRADABLE  \n",
      "OPEN_DATETIME CODE                                                \n",
      "1991-10-23    BOI.PA  TRAIN           17545408  BOIRON         1  \n",
      "1991-10-24    BOI.PA  TRAIN           17545408  BOIRON         1  \n",
      "1991-10-25    BOI.PA  TRAIN           17545408  BOIRON         1  \n",
      "1991-10-28    BOI.PA  TRAIN           17545408  BOIRON         1  \n",
      "1991-10-29    BOI.PA  TRAIN           17545408  BOIRON         1  \n",
      "\n",
      "[5 rows x 135 columns]\n"
     ]
    }
   ],
   "source": [
    "# Reset the index of df_all to make 'code' a regular column\n",
    "df_all_reset = df_all.reset_index()\n",
    "\n",
    "# Merge df_all with df_stock_infos on the 'code' column\n",
    "df_all_merged = df_all_reset.merge(df_stock_infos[['CODE', 'SHARESOUTSTANDING', 'NAME', 'TRADABLE']], on='CODE', how='left')\n",
    "\n",
    "# Restore the multi-index (datetime and code)\n",
    "df_all_2 = df_all_merged.set_index(['OPEN_DATETIME', 'CODE'])\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df_all_2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all_2['CLOSE'].dtype=dtype('float64') df_all_2['SHARESOUTSTANDING'].dtype=dtype('O')\n"
     ]
    }
   ],
   "source": [
    "#check type of f_all_2['CLOSE'] and df_all_2['SHARESOUTSTANDING']\n",
    "print(f\"{df_all_2['CLOSE'].dtype=} {df_all_2['SHARESOUTSTANDING'].dtype=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>pos_sma20</th>\n",
       "      <th>pos_sma50</th>\n",
       "      <th>pos_sma200</th>\n",
       "      <th>pos_sma50_200</th>\n",
       "      <th>pos_sma20_50</th>\n",
       "      <th>...</th>\n",
       "      <th>lab_perf_50d_class_10</th>\n",
       "      <th>predict_10</th>\n",
       "      <th>predict_5</th>\n",
       "      <th>predict_10_proba</th>\n",
       "      <th>predict_5_proba</th>\n",
       "      <th>PART</th>\n",
       "      <th>SHARESOUTSTANDING</th>\n",
       "      <th>NAME</th>\n",
       "      <th>TRADABLE</th>\n",
       "      <th>cap_M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPEN_DATETIME</th>\n",
       "      <th>CODE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1991-10-23</th>\n",
       "      <th>BOI.PA</th>\n",
       "      <td>0.6832</td>\n",
       "      <td>0.6832</td>\n",
       "      <td>0.6832</td>\n",
       "      <td>0.6832</td>\n",
       "      <td>640.0</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.09985782399798895, 0.09992670388165456, 0.1...</td>\n",
       "      <td>[0.19909589227087685, 0.20071967485772987, 0.1...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>17545408</td>\n",
       "      <td>BOIRON</td>\n",
       "      <td>1</td>\n",
       "      <td>11.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-10-24</th>\n",
       "      <th>BOI.PA</th>\n",
       "      <td>0.6635</td>\n",
       "      <td>0.6635</td>\n",
       "      <td>0.6635</td>\n",
       "      <td>0.6635</td>\n",
       "      <td>7840.0</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.136</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[0.10004667817075666, 0.0998982506703846, 0.09...</td>\n",
       "      <td>[0.19938673862426753, 0.19926126592536392, 0.1...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>17545408</td>\n",
       "      <td>BOIRON</td>\n",
       "      <td>1</td>\n",
       "      <td>11.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-10-25</th>\n",
       "      <th>BOI.PA</th>\n",
       "      <td>0.6635</td>\n",
       "      <td>0.6635</td>\n",
       "      <td>0.6635</td>\n",
       "      <td>0.6635</td>\n",
       "      <td>7744.0</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.134</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[0.10002173869508071, 0.09990738056821478, 0.0...</td>\n",
       "      <td>[0.19920730275897847, 0.19926594602352998, 0.1...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>17545408</td>\n",
       "      <td>BOIRON</td>\n",
       "      <td>1</td>\n",
       "      <td>11.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-10-28</th>\n",
       "      <th>BOI.PA</th>\n",
       "      <td>0.6543</td>\n",
       "      <td>0.6543</td>\n",
       "      <td>0.6543</td>\n",
       "      <td>0.6543</td>\n",
       "      <td>14848.0</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[0.10002642307660348, 0.09988535349790527, 0.0...</td>\n",
       "      <td>[0.19942715141097156, 0.19882110780624856, 0.1...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>17545408</td>\n",
       "      <td>BOIRON</td>\n",
       "      <td>1</td>\n",
       "      <td>11.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-10-29</th>\n",
       "      <th>BOI.PA</th>\n",
       "      <td>0.6622</td>\n",
       "      <td>0.6622</td>\n",
       "      <td>0.6622</td>\n",
       "      <td>0.6622</td>\n",
       "      <td>800.0</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.129</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[0.10000389870274415, 0.09989718304586509, 0.0...</td>\n",
       "      <td>[0.19942952202688463, 0.1995544997359649, 0.19...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>17545408</td>\n",
       "      <td>BOIRON</td>\n",
       "      <td>1</td>\n",
       "      <td>11.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        OPEN    HIGH     LOW   CLOSE   VOLUME  pos_sma20  \\\n",
       "OPEN_DATETIME CODE                                                         \n",
       "1991-10-23    BOI.PA  0.6832  0.6832  0.6832  0.6832    640.0     -0.030   \n",
       "1991-10-24    BOI.PA  0.6635  0.6635  0.6635  0.6635   7840.0     -0.054   \n",
       "1991-10-25    BOI.PA  0.6635  0.6635  0.6635  0.6635   7744.0     -0.050   \n",
       "1991-10-28    BOI.PA  0.6543  0.6543  0.6543  0.6543  14848.0     -0.059   \n",
       "1991-10-29    BOI.PA  0.6622  0.6622  0.6622  0.6622    800.0     -0.043   \n",
       "\n",
       "                      pos_sma50  pos_sma200  pos_sma50_200  pos_sma20_50  ...  \\\n",
       "OPEN_DATETIME CODE                                                        ...   \n",
       "1991-10-23    BOI.PA     -0.046       0.085          0.138        -0.016  ...   \n",
       "1991-10-24    BOI.PA     -0.073       0.053          0.136        -0.019  ...   \n",
       "1991-10-25    BOI.PA     -0.071       0.053          0.134        -0.022  ...   \n",
       "1991-10-28    BOI.PA     -0.083       0.037          0.131        -0.026  ...   \n",
       "1991-10-29    BOI.PA     -0.071       0.049          0.129        -0.029  ...   \n",
       "\n",
       "                      lab_perf_50d_class_10  predict_10  predict_5  \\\n",
       "OPEN_DATETIME CODE                                                   \n",
       "1991-10-23    BOI.PA                    3.0         6.0        1.0   \n",
       "1991-10-24    BOI.PA                    2.0         8.0        4.0   \n",
       "1991-10-25    BOI.PA                    3.0         6.0        4.0   \n",
       "1991-10-28    BOI.PA                    5.0         9.0        3.0   \n",
       "1991-10-29    BOI.PA                    4.0         8.0        4.0   \n",
       "\n",
       "                                                       predict_10_proba  \\\n",
       "OPEN_DATETIME CODE                                                        \n",
       "1991-10-23    BOI.PA  [0.09985782399798895, 0.09992670388165456, 0.1...   \n",
       "1991-10-24    BOI.PA  [0.10004667817075666, 0.0998982506703846, 0.09...   \n",
       "1991-10-25    BOI.PA  [0.10002173869508071, 0.09990738056821478, 0.0...   \n",
       "1991-10-28    BOI.PA  [0.10002642307660348, 0.09988535349790527, 0.0...   \n",
       "1991-10-29    BOI.PA  [0.10000389870274415, 0.09989718304586509, 0.0...   \n",
       "\n",
       "                                                        predict_5_proba  \\\n",
       "OPEN_DATETIME CODE                                                        \n",
       "1991-10-23    BOI.PA  [0.19909589227087685, 0.20071967485772987, 0.1...   \n",
       "1991-10-24    BOI.PA  [0.19938673862426753, 0.19926126592536392, 0.1...   \n",
       "1991-10-25    BOI.PA  [0.19920730275897847, 0.19926594602352998, 0.1...   \n",
       "1991-10-28    BOI.PA  [0.19942715141097156, 0.19882110780624856, 0.1...   \n",
       "1991-10-29    BOI.PA  [0.19942952202688463, 0.1995544997359649, 0.19...   \n",
       "\n",
       "                       PART  SHARESOUTSTANDING    NAME  TRADABLE  cap_M  \n",
       "OPEN_DATETIME CODE                                                       \n",
       "1991-10-23    BOI.PA  TRAIN           17545408  BOIRON         1  11.99  \n",
       "1991-10-24    BOI.PA  TRAIN           17545408  BOIRON         1  11.64  \n",
       "1991-10-25    BOI.PA  TRAIN           17545408  BOIRON         1  11.64  \n",
       "1991-10-28    BOI.PA  TRAIN           17545408  BOIRON         1  11.48  \n",
       "1991-10-29    BOI.PA  TRAIN           17545408  BOIRON         1  11.62  \n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import int64\n",
    "\n",
    "df_all_2['NAME']=df_all_2['NAME'].astype(str)\n",
    "df_all_2['TRADABLE']=df_all_2['TRADABLE'].astype(int)\n",
    "df_all_2['SHARESOUTSTANDING']=df_all_2['SHARESOUTSTANDING'].fillna(0)\n",
    "df_all_2['SHARESOUTSTANDING']=df_all_2['SHARESOUTSTANDING'].replace('',0)\n",
    "df_all_2['SHARESOUTSTANDING']=df_all_2['SHARESOUTSTANDING'].astype(int64)\n",
    "df_all_2['cap_M']=round((df_all_2['CLOSE']*df_all_2['SHARESOUTSTANDING'])/1000000.0,2)\n",
    "df_all_2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(671570, 136)\n"
     ]
    }
   ],
   "source": [
    "print(df_all_2.shape)\n",
    "joblib.dump(df_all_2, PATH_DATA_DTS+\"PARIS_TREND_1D_V5_lab_20_class_5_10_PREDICT_ALL2.pkl\")\n",
    "\n",
    "with open(PATH_DATA_DTS+\"PARIS_TREND_1D_V5_lab_20_class_5_10_PREDICT_ALL_INFO2.txt\", \"w\") as f:\n",
    "    f.write(f\"Columns:\\n{list(df_all_2.columns)}\\n\")\n",
    "    f.write(f\"Index:\\n{list(df_all_2.index.levels)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all_2.shape=(671570, 136)\n"
     ]
    }
   ],
   "source": [
    "df_all_2=joblib.load(PATH_DATA_DTS+\"PARIS_TREND_1D_V5_lab_20_class_5_10_PREDICT_ALL2.pkl\")\n",
    "print(f\"{df_all_2.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_base.shape=(1299247, 159)\n"
     ]
    }
   ],
   "source": [
    "#  load BASE eand merge it with df_all_2\n",
    "df_base = pd.read_csv(PATH_DATA_DTS+\"PARIS_TREND_1D_20D_V3_BASE.zip\",sep=\",\",index_col=[\"OPEN_DATETIME\",\"CODE\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "print(f\"{df_base.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all_3.shape=(1299247, 295)\n"
     ]
    }
   ],
   "source": [
    "# do a left join on df_base and df_all_2 on the index (OPEN_DATETIME, CODE)\n",
    "# keep all the columns of df_base and df_all_2\n",
    "df_all_3 = df_base.join(df_all_2, how='left', on=['OPEN_DATETIME','CODE'],  rsuffix='_val',)\n",
    "print(f\"{df_all_3.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1299247, 18)\n"
     ]
    }
   ],
   "source": [
    "df_merged=df_all_3.copy()\n",
    "df_merged=df_all_3[ ['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME','pos_sma20_200','adx14_pos',\n",
    "                    'lab_perf_20d_class_5', 'lab_perf_20d_class_10',\n",
    "                    'predict_10', 'predict_5', 'predict_10_proba', 'predict_5_proba',\n",
    "                      'PART', 'SHARESOUTSTANDING', 'NAME', 'TRADABLE', 'cap_M']]\n",
    "\n",
    "print(df_merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G:\\\\Python\\\\Data\\\\DTS_FULL\\\\PARIS_TREND_1D_V5_lab_20_class_5_10_PREDICT_ALL3.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save df_merged in a file\n",
    "joblib.dump(df_merged, PATH_DATA_DTS+\"PARIS_TREND_1D_V5_lab_20_class_5_10_PREDICT_ALL3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_merged.shape=(1299247, 18)\n"
     ]
    }
   ],
   "source": [
    "df_merged=joblib.load(PATH_DATA_DTS+\"PARIS_TREND_1D_V5_lab_20_class_5_10_PREDICT_ALL3.pkl\")\n",
    "print(f\"{df_merged.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             min        max\n",
      "PART                       \n",
      "CONF  2020-10-01 2023-11-01\n",
      "TRAIN 1991-10-23 2017-07-31\n",
      "VAL   2017-08-01 2020-09-30\n",
      "Nb line where PART is null: 627677\n"
     ]
    }
   ],
   "source": [
    "# print min and max of df_merged.index.get_level_values('OPEN_DATETIME') group by df_merged['PART']\n",
    "df_merged_reset = df_merged.reset_index()  # Reset the index to access 'OPEN_DATETIME' as a column\n",
    "print(df_merged_reset.groupby('PART')['OPEN_DATETIME'].agg(['min', 'max']))\n",
    "# print nb line where df_merged['PART']is null\n",
    "print(f\"Nb line where PART is null: {df_merged[df_merged['PART'].isnull()].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate values for 'PART', 'SHARESOUTSTANDING', 'NAME', 'TRADABLE', 'cap_M'\n",
    "df_merged['PART'] = df_merged.index.get_level_values('OPEN_DATETIME').map(\n",
    "    lambda x: 'TRAIN' if x < pd.Timestamp('2017-08-01') else \n",
    "              'VAL' if x < pd.Timestamp('2020-10-01') else \n",
    "              'CONF' if pd.notnull(x) else None\n",
    ")\n",
    "df_merged['NAME'] = df_merged.groupby(df_merged.index.get_level_values('CODE'))['NAME'].transform(lambda x: x.ffill().bfill())\n",
    "df_merged['SHARESOUTSTANDING'] = df_merged.groupby(df_merged.index.get_level_values('CODE'))['SHARESOUTSTANDING'].transform(lambda x: x.ffill().bfill())\n",
    "df_merged['TRADABLE'] = df_merged.groupby(df_merged.index.get_level_values('CODE'))['TRADABLE'].transform(lambda x: x.ffill().bfill())\n",
    "df_merged['cap_M'] = round((df_merged['CLOSE']*df_merged['SHARESOUTSTANDING'])/1000000.0,2)\n",
    "# drop line where NAME is null\n",
    "# df_merged.dropna(subset=['NAME'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb line where PART is null: 0\n",
      "Nb line where NAME is null: 65455\n",
      "Nb line where SHARESOUTSTANDING is null: 65455\n",
      "Nb line where TRADABLE is null: 65455\n",
      "Nb line where cap_M is null: 65455\n",
      "df_merged.shape=(1299247, 18)\n",
      "df_merged.shape=(1233792, 18)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nb line where PART is null: {df_merged[df_merged['PART'].isnull()].shape[0]}\")\n",
    "print(f\"Nb line where NAME is null: {df_merged[df_merged['NAME'].isnull()].shape[0]}\")\n",
    "print(f\"Nb line where SHARESOUTSTANDING is null: {df_merged[df_merged['SHARESOUTSTANDING'].isnull()].shape[0]}\")\n",
    "print(f\"Nb line where TRADABLE is null: {df_merged[df_merged['TRADABLE'].isnull()].shape[0]}\")\n",
    "print(f\"Nb line where cap_M is null: {df_merged[df_merged['cap_M'].isnull()].shape[0]}\")\n",
    "print(f\"{df_merged.shape=}\")\n",
    "\n",
    "df_merged.dropna(subset=['NAME'], inplace=True)\n",
    "print(f\"{df_merged.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AIR LIQUIDE']\n"
     ]
    }
   ],
   "source": [
    "# print for the code AI.PA the different NAME of the dataset \n",
    "print(df_merged[df_merged.index.get_level_values('CODE')=='AI.PA']['NAME'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G:\\\\Python\\\\Data\\\\DTS_FULL\\\\PARIS_TREND_1D_V5_lab_20_class_5_10_PREDICT_ALL4.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(df_merged, PATH_DATA_DTS+\"PARIS_TREND_1D_V5_lab_20_class_5_10_PREDICT_ALL4.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     YYYYMM  count\n",
      "264  202201     21\n",
      "265  202202     20\n",
      "266  202203     23\n",
      "267  202204     19\n",
      "268  202205     22\n",
      "269  202206     22\n",
      "270  202207     21\n",
      "271  202208     23\n",
      "272  202209     22\n",
      "273  202210     21\n",
      "274  202211     22\n",
      "275  202212     21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benoit\\AppData\\Local\\Temp\\ipykernel_12496\\2564425692.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ai['YYYYMM'] = df_ai.index.get_level_values('OPEN_DATETIME').strftime('%Y%m')\n"
     ]
    }
   ],
   "source": [
    "# Extract the datetime level from the MultiIndex and apply strftime\n",
    "df_ai = df_merged[df_merged.index.get_level_values('CODE') == 'AI.PA']\n",
    "df_ai['YYYYMM'] = df_ai.index.get_level_values('OPEN_DATETIME').strftime('%Y%m')\n",
    "# Count rows by YYYYMM and sort by YYYYMM\n",
    "df_ai_count = df_ai.groupby('YYYYMM').size().reset_index(name='count')\n",
    "# print df_ai for year 2022\n",
    "print(df_ai_count[df_ai_count['YYYYMM'].str.startswith('2022')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep for model not adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_filtered.shape=(716338, 117)\n"
     ]
    }
   ],
   "source": [
    "# load PARIS_TREND_1D_20D_V4_filtered.zip\n",
    "df_filtered = pd.read_csv(PATH_DATA_DTS+\"PARIS_TREND_1D_20D_V4_filtered.zip\",sep=\",\",index_col=[\"OPEN_DATETIME\",\"CODE\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "print(f\"{df_filtered.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_code=['BOI.PA', 'ELEC.PA', 'CDI.PA', 'TEP.PA', 'GFC.PA', 'LI.PA', 'RE.PA', 'SAVE.PA', 'VIRP.PA', 'LOUP.PA', 'BN.PA', 'TFI.PA', 'CRI.PA', 'MF.PA', 'ERF.PA', 'BEN.PA', 'TRI.PA', 'SOI.PA', 'GLO.PA', 'PIG.PA', 'ALDLT.PA', 'ALGIL.PA', 'AM.PA', 'BIG.PA', 'BNP.PA', 'CAT31.PA', 'CDA.PA', 'CEN.PA', 'CMO.PA', 'CRAP.PA', 'CRLO.PA', 'CRSU.PA', 'DIM.PA', 'DSY.PA', 'FGR.PA', 'IMDA.PA', 'LSS.PA', 'PERR.PA', 'RAL.PA', 'RCO.PA', 'RF.PA', 'RI.PA', 'SBT.PA', 'SDG.PA', 'TFF.PA', 'THEP.PA', 'VK.PA', 'GLE.PA', 'BUR.PA', 'AC.PA', 'BLC.PA', 'BON.PA', 'CA.PA', 'CGG.PA', 'CIV.PA', 'CRTO.PA', 'ES.PA', 'FII.PA', 'HO.PA', 'PVL.PA', 'RNO.PA', 'SAN.PA', 'SCR.PA', 'SU.PA', 'SCHP.PA', 'VCT.PA', 'ASY.PA', 'ENGI.PA', 'CRBP2.PA', 'MRN.PA', 'SGO.PA', 'AI.PA', 'EL.PA', 'ALFLE.PA', 'ML.PA', 'EXE.PA', 'FR.PA', 'PEUG.PA', 'BAIN.PA', 'KER.PA', 'KOF.PA', 'LPE.PA', 'VRAP.PA', 'DKUPL.PA', 'RUI.PA', 'STF.PA', 'ATE.PA', 'LACR.PA', 'CAP.PA', 'ATO.PA', 'PARP.PA', 'ERA.PA', 'LIN.PA', 'QDT.PA', 'VIE.PA', 'VIL.PA', 'NK.PA', 'SOP.PA', 'ALLAN.PA', 'UBI.PA', 'VIV.PA', 'MMB.PA', 'BB.PA', 'GBT.PA', 'ALMRB.PA', 'DBG.PA', 'EQS.PA', 'NRO.PA', 'LBIRD.PA', 'CGM.PA', 'SAMS.PA', 'CRLA.PA', 'MMT.PA', 'NRG.PA', 'PUB.PA', 'SAF.PA', 'GAM.PA', 'TNG.PA', 'INF.PA', 'CCN.PA', 'MC.PA', 'ALDEL.PA', 'DEC.PA', 'ALHRG.PA', 'NEX.PA', 'POM.PA', 'ABCA.PA', 'ESI.PA', 'AIR.PA', 'DGE.PA', 'ALLDL.PA', 'ALDAR.PA', 'GNE.PA', 'SWP.PA', 'ORP.PA', 'AUB.PA', 'GUI.PA', 'XIL.PA', 'SQI.PA', 'SESG.PA', 'BIM.PA', 'LOCAL.PA', 'NXI.PA', 'EIFF.PA', 'ICAD.PA', 'EUR.PA', 'CBOT.PA', 'COVH.PA', 'GPE.PA', 'AF.PA', 'ALO.PA', 'MERY.PA', 'ETL.PA', 'IPN.PA', 'TTE.PA', 'ALCLA.PA', 'SESL.PA', 'ALERS.PA', 'LR.PA', 'AKE.PA', 'LNA.PA', 'ADP.PA', 'PARRO.PA', 'ALVDM.PA', 'ALMDG.PA', 'CATG.PA', 'VETO.PA', 'BSD.PA', 'DG.PA', 'INEA.PA', 'OLG.PA', 'GET.PA', 'ALFPC.PA', 'ARG.PA', 'METEX.PA', 'BVI.PA', 'RXL.PA', 'ALCLS.PA', 'GDS.PA', 'GNFT.PA', 'VLA.PA', 'BASS.PA', 'IPH.PA', 'IPS.PA', 'ITP.PA', 'BOL.PA', 'COV.PA', 'EC.PA', 'S30.PA', 'WAVE.PA', 'MBWS.PA', 'EDEN.PA', 'JCQ.PA', 'ALCAR.PA', 'AB.PA', 'ALBIO.PA', 'AXW.PA', 'PAT.PA', 'ALMDT.PA', 'ALTA.PA', 'IDIP.PA', 'ALPDX.PA', 'DBV.PA', 'IDL.PA', 'LAT.PA', 'ALGAU.PA', 'ALGEV.PA', 'ALNOV.PA', 'NANO.PA', 'EKI.PA', 'FNAC.PA', 'FGA.PA', 'ALCRB.PA', 'GTT.PA', 'GV.PA', 'AKW.PA', 'ALVIV.PA', 'ALEXA.PA', 'ELIOR.PA', 'ENX.PA', 'COFA.PA', 'WLN.PA', 'TKTT.PA', 'ATEME.PA', 'SEFER.PA', 'ALFOC.PA', 'ALCJ.PA', 'POXEL.PA', 'ALDRV.PA', 'NHOA.PA', 'ELIS.PA', 'ALREA.PA', 'SPIE.PA', 'ALLIX.PA', 'SRP.PA', 'AMUN.PA', 'OSE.PA', 'MDM.PA', 'NOKIA.PA', 'ABVX.PA', 'FDE.PA', 'ABEO.PA', 'ALBFR.PA', 'ALBLD.PA', 'ALESK.PA', 'ALMOU.PA', 'AVT.PA', 'IAM.PA', 'SFPI.PA', 'VLTSA.PA', 'ALCYB.PA', 'SIGHT.PA', 'XFAB.PA', 'TKO.PA', 'IVA.PA', 'ALD.PA', 'SMCP.PA', 'CNV.PA', 'JBOG.PA', 'ALKAL.PA', 'RBO.PA', 'NEOEN.PA', 'ALVU.PA', 'PWG.PA', 'ALDNE.PA', 'VRLA.PA', 'ALHGR.PA', 'FDJ.PA', 'NACON.PA', 'ALINV.PA', 'ALHPI.PA', 'PRC.PA', 'TE.PA', 'HDF.PA', 'ALESE.PA', 'WAGA.PA', 'ANTIN.PA', 'FORSE.PA', 'ALHRS.PA', 'EXN.PA', 'BLV.PA', 'OVH.PA', 'MAAT.PA', 'ALKEM.PA', 'ARAMI.PA', 'ALAFY.PA', 'DEEZR.PA', 'EAPI.PA']\n",
      "list_code_str=\"'BOI.PA','ELEC.PA','CDI.PA','TEP.PA','GFC.PA','LI.PA','RE.PA','SAVE.PA','VIRP.PA','LOUP.PA','BN.PA','TFI.PA','CRI.PA','MF.PA','ERF.PA','BEN.PA','TRI.PA','SOI.PA','GLO.PA','PIG.PA','ALDLT.PA','ALGIL.PA','AM.PA','BIG.PA','BNP.PA','CAT31.PA','CDA.PA','CEN.PA','CMO.PA','CRAP.PA','CRLO.PA','CRSU.PA','DIM.PA','DSY.PA','FGR.PA','IMDA.PA','LSS.PA','PERR.PA','RAL.PA','RCO.PA','RF.PA','RI.PA','SBT.PA','SDG.PA','TFF.PA','THEP.PA','VK.PA','GLE.PA','BUR.PA','AC.PA','BLC.PA','BON.PA','CA.PA','CGG.PA','CIV.PA','CRTO.PA','ES.PA','FII.PA','HO.PA','PVL.PA','RNO.PA','SAN.PA','SCR.PA','SU.PA','SCHP.PA','VCT.PA','ASY.PA','ENGI.PA','CRBP2.PA','MRN.PA','SGO.PA','AI.PA','EL.PA','ALFLE.PA','ML.PA','EXE.PA','FR.PA','PEUG.PA','BAIN.PA','KER.PA','KOF.PA','LPE.PA','VRAP.PA','DKUPL.PA','RUI.PA','STF.PA','ATE.PA','LACR.PA','CAP.PA','ATO.PA','PARP.PA','ERA.PA','LIN.PA','QDT.PA','VIE.PA','VIL.PA','NK.PA','SOP.PA','ALLAN.PA','UBI.PA','VIV.PA','MMB.PA','BB.PA','GBT.PA','ALMRB.PA','DBG.PA','EQS.PA','NRO.PA','LBIRD.PA','CGM.PA','SAMS.PA','CRLA.PA','MMT.PA','NRG.PA','PUB.PA','SAF.PA','GAM.PA','TNG.PA','INF.PA','CCN.PA','MC.PA','ALDEL.PA','DEC.PA','ALHRG.PA','NEX.PA','POM.PA','ABCA.PA','ESI.PA','AIR.PA','DGE.PA','ALLDL.PA','ALDAR.PA','GNE.PA','SWP.PA','ORP.PA','AUB.PA','GUI.PA','XIL.PA','SQI.PA','SESG.PA','BIM.PA','LOCAL.PA','NXI.PA','EIFF.PA','ICAD.PA','EUR.PA','CBOT.PA','COVH.PA','GPE.PA','AF.PA','ALO.PA','MERY.PA','ETL.PA','IPN.PA','TTE.PA','ALCLA.PA','SESL.PA','ALERS.PA','LR.PA','AKE.PA','LNA.PA','ADP.PA','PARRO.PA','ALVDM.PA','ALMDG.PA','CATG.PA','VETO.PA','BSD.PA','DG.PA','INEA.PA','OLG.PA','GET.PA','ALFPC.PA','ARG.PA','METEX.PA','BVI.PA','RXL.PA','ALCLS.PA','GDS.PA','GNFT.PA','VLA.PA','BASS.PA','IPH.PA','IPS.PA','ITP.PA','BOL.PA','COV.PA','EC.PA','S30.PA','WAVE.PA','MBWS.PA','EDEN.PA','JCQ.PA','ALCAR.PA','AB.PA','ALBIO.PA','AXW.PA','PAT.PA','ALMDT.PA','ALTA.PA','IDIP.PA','ALPDX.PA','DBV.PA','IDL.PA','LAT.PA','ALGAU.PA','ALGEV.PA','ALNOV.PA','NANO.PA','EKI.PA','FNAC.PA','FGA.PA','ALCRB.PA','GTT.PA','GV.PA','AKW.PA','ALVIV.PA','ALEXA.PA','ELIOR.PA','ENX.PA','COFA.PA','WLN.PA','TKTT.PA','ATEME.PA','SEFER.PA','ALFOC.PA','ALCJ.PA','POXEL.PA','ALDRV.PA','NHOA.PA','ELIS.PA','ALREA.PA','SPIE.PA','ALLIX.PA','SRP.PA','AMUN.PA','OSE.PA','MDM.PA','NOKIA.PA','ABVX.PA','FDE.PA','ABEO.PA','ALBFR.PA','ALBLD.PA','ALESK.PA','ALMOU.PA','AVT.PA','IAM.PA','SFPI.PA','VLTSA.PA','ALCYB.PA','SIGHT.PA','XFAB.PA','TKO.PA','IVA.PA','ALD.PA','SMCP.PA','CNV.PA','JBOG.PA','ALKAL.PA','RBO.PA','NEOEN.PA','ALVU.PA','PWG.PA','ALDNE.PA','VRLA.PA','ALHGR.PA','FDJ.PA','NACON.PA','ALINV.PA','ALHPI.PA','PRC.PA','TE.PA','HDF.PA','ALESE.PA','WAGA.PA','ANTIN.PA','FORSE.PA','ALHRS.PA','EXN.PA','BLV.PA','OVH.PA','MAAT.PA','ALKEM.PA','ARAMI.PA','ALAFY.PA','DEEZR.PA','EAPI.PA'\"\n"
     ]
    }
   ],
   "source": [
    "# save in a file the liste of code  in the format 'CODE_1','CODE_2',...,'CODE_N'\n",
    "list_code = df_filtered.index.get_level_values('CODE').unique().tolist()\n",
    "print(f\"{list_code=}\")\n",
    "list_code_str = ','.join([f\"'{code}'\" for code in list_code])\n",
    "print(f\"{list_code_str=}\")\n",
    "# save the list_code_str in a file\n",
    "with open(PATH_DATA_DTS+\"PARIS_TREND_1D_20D_V4_filtered_list_code.txt\", \"w\") as f:\n",
    "    f.write(f\"{list_code_str}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
