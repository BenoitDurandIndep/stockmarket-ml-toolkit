{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparation of the dataset for the homemade backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import int64\n",
    "from matplotlib import pyplot as plt\n",
    "import importlib\n",
    "import joblib\n",
    "from typing import List\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# Ensure project root is on sys.path for local imports\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "if not (PROJECT_ROOT / \"dataset_mngr\").exists():\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "if (PROJECT_ROOT / \"dataset_mngr\").exists():\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import backtest_portfolio as port\n",
    "import backtest_preparation as prep\n",
    "from dataset_mngr import db_models\n",
    "from dataset_mngr import sqlite_io as sio\n",
    "from dataset_mngr.db_models import Scenario as ScenarioORM, Campaign as CampaignORM, Strategy as StrategyORM, Model as ModelORM, Indicator as IndicatorORM,CombiModels as CombiModelsORM\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "importlib.reload(port)\n",
    "importlib.reload(prep)\n",
    "importlib.reload(sio)\n",
    "importlib.reload(db_models)\n",
    "\n",
    "\n",
    "PATH_DATA = \"D:\\\\Projets\\\\Data\\\\\"\n",
    "PATH_MODELS = PATH_DATA+\"Models\\\\LGBM\"\n",
    "PATH_DB_FWK=PATH_DATA+\"\\\\sqlite\\\\dataset_market.db\"\n",
    "\n",
    "if \"con_fwk\" in locals():\n",
    "        sio.close_connection(con_fwk)\n",
    "con_fwk = sio.get_connection(str_db_path=PATH_DB_FWK)\n",
    "\n",
    "my_session_maker = sessionmaker(bind=con_fwk)\n",
    "session=my_session_maker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Model objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE_CLASS_5 = \"Class 5\"\n",
    "TYPE_CLASS_10 = \"Class 10\"\n",
    "SK_DATASET = 8\n",
    "SK_SYMBOL = 417\n",
    "\n",
    "list_models_conf = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"name\": \"20D Adj class 5\",\n",
    "        \"type\": TYPE_CLASS_5,\n",
    "        \"label\": \"lab_perf_20d_class_5_adj\",\n",
    "        \"label_base\": \"lab_perf_20d\",\n",
    "        \"predict_col\":\"predict_5_adj\",\n",
    "        \"proba_col\": \"predict_5_proba_adj\",\n",
    "        \"filename\": \"PARIS_TREND_1D_ADJ_V5_class_R3_CLIP_20D_LGBM_MODEL_CLAS5_R3_2503_V1.pkl\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"name\": \"20D Adj class 10\",\n",
    "        \"type\": TYPE_CLASS_10,\n",
    "        \"label\": \"lab_perf_20d_class_10_adj\",\n",
    "        \"label_base\": \"lab_perf_20d\",\n",
    "        \"predict_col\":\"predict_10_adj\",\n",
    "        \"proba_col\": \"predict_10_proba_adj\",\n",
    "        \"filename\": \"PARIS_TREND_1D_ADJ_V5_class_R3_CLIP_20D_LGBM_MODEL_CLAS10_R3_2503_V1.pkl\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"name\": \"20D class 5\",\n",
    "        \"type\": TYPE_CLASS_5,\n",
    "        \"label\": \"lab_perf_20d_class5\",\n",
    "        \"label_base\": \"lab_perf_20d\",\n",
    "        \"predict_col\":\"predict_LGBM_CLASS_5_20D\",\n",
    "        \"proba_col\": \"predict_LGBM_CLASS_5_20D_proba\",\n",
    "        \"filename\": \"PARIS_TREND_1D_V5B_class_R3_CLIP_20D_LGBM_MODEL_CLAS5_R3_2507_V1.pkl\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"name\": \"20D class 10\",\n",
    "        \"type\": TYPE_CLASS_10,\n",
    "        \"label\": \"lab_perf_20d_class10\",\n",
    "        \"label_base\": \"lab_perf_20d\",\n",
    "        \"predict_col\":\"predict_LGBM_CLASS_10_20D\",\n",
    "        \"proba_col\": \"predict_LGBM_CLASS_10_20D_proba\",\n",
    "        \"filename\": \"PARIS_TREND_1D_V5B_class_R3_CLIP_20D_LGBM_MODEL_CLAS10_R3_2507_V1.pkl\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"name\": \"50D class 5\",\n",
    "        \"type\": TYPE_CLASS_5,\n",
    "        \"label\": \"lab_perf_50d_class5\",\n",
    "        \"label_base\": \"lab_perf_50d\",\n",
    "        \"predict_col\":\"predict_LGBM_CLASS_5_50D\",\n",
    "        \"proba_col\": \"predict_LGBM_CLASS_5_50D_proba\",\n",
    "        \"filename\": \"PARIS_TREND_1D_V5B_class_R3_CLIP_50D_LGBM_MODEL_CLAS5_R3_2508_V1.pkl\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 6,\n",
    "        \"name\": \"50D class 10\",\n",
    "        \"type\": TYPE_CLASS_10,\n",
    "        \"label\": \"lab_perf_50d_class10\",\n",
    "        \"label_base\": \"lab_perf_50d\",\n",
    "        \"predict_col\":\"predict_LGBM_CLASS_10_50D\",\n",
    "        \"proba_col\": \"predict_LGBM_CLASS_10_50D_proba\",\n",
    "        \"filename\": \"PARIS_TREND_1D_V5B_class_R3_CLIP_50D_LGBM_MODEL_CLAS10_R3_2507_V1.pkl\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# for each model in list, open the file and add the feature list at the end\n",
    "list_model=[]\n",
    "list_labels=[]\n",
    "list_predict_cols=[]\n",
    "list_proba_cols=[]\n",
    "\n",
    "for model in list_models_conf:\n",
    "    mod_fic = joblib.load(PATH_MODELS + \"\\\\\" + model[\"filename\"])\n",
    "    model[\"features\"] = mod_fic.booster_.feature_name()\n",
    "\n",
    "    my_model=prep.Model(model[\"id\"], model[\"name\"], model[\"type\"], model[\"label\"],model[\"label_base\"],\n",
    "                        model[\"predict_col\"], model[\"proba_col\"], model[\"filename\"], model[\"features\"],\n",
    "                        sk_dataset=SK_DATASET, sk_symbol=SK_SYMBOL)\n",
    "\n",
    "    list_model.append(my_model)\n",
    "    list_labels.append(model[\"label\"])\n",
    "    list_predict_cols.append(model[\"predict_col\"])\n",
    "    list_proba_cols.append(model[\"proba_col\"])\n",
    "\n",
    "    print(f\"Model {my_model.name} loaded\")\n",
    "\n",
    "print(f\"{list_model.__len__()} models loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model in DB if doesn't exist, if exists get id\n",
    "\n",
    "for model in list_model:\n",
    "    # check if model exists\n",
    "    model_orm = session.query(ModelORM).filter(ModelORM.name == model.name).first()\n",
    "    if model_orm is None:\n",
    "        indicator_orm = session.query(IndicatorORM).filter(IndicatorORM.label == model.label_base).first()\n",
    "        if indicator_orm is None:\n",
    "            raise ValueError(f\"No IndicatorORM found with label '{model.label_base}'. Please ensure the indicator exists in the database.\")\n",
    "        model.sk_label = indicator_orm.sk_indicator\n",
    "        sio.insert_object(session, ModelORM, model)\n",
    "        session.commit()\n",
    "        model_orm = session.query(ModelORM).filter(ModelORM.name == model.name).first()\n",
    "        if model_orm is None:\n",
    "            raise ValueError(f\"Model '{model.name}' was not persisted; cannot set model id.\")\n",
    "        print(f\"Model {model.name} added to DB with id {model_orm.sk_model}\")\n",
    "    else:\n",
    "        print(f\"Model {model.name} already exists in DB with id {model_orm.sk_model}\")\n",
    "    model.id = model_orm.sk_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "def _parse_params(value)-> dict:\n",
    "    if value is None:\n",
    "        return {}\n",
    "    if isinstance(value, dict):\n",
    "        return value\n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            return json.loads(value)\n",
    "        except Exception:\n",
    "            try:\n",
    "                return ast.literal_eval(value)\n",
    "            except Exception:\n",
    "                return {}\n",
    "    return {}\n",
    "\n",
    "# Load StrategyType from SQLite (inserted by strategy_type_seed.py)\n",
    "strategy_type_name = \"STRAT_1_MOD_1_TRES_V1\"\n",
    "strategy_type_row = session.query(db_models.StrategyType).filter(db_models.StrategyType.name == strategy_type_name).first()\n",
    "if strategy_type_row is None:\n",
    "    raise ValueError(f\"StrategyType '{strategy_type_name}' not found in DB\")\n",
    "\n",
    "# Build StrategyType instance for runtime use\n",
    "def _build_strategy_type(strategy_type:db_models.StrategyType) -> prep.StrategyType:\n",
    "\n",
    "    return prep.StrategyType(\n",
    "        id=strategy_type.sk_strategy_type,\n",
    "        name=strategy_type.name or strategy_type_name,\n",
    "        description=strategy_type.description or \"\",\n",
    "        code_entry=strategy_type.code_entry or \"\",\n",
    "        code_exit=strategy_type.code_exit or \"\",\n",
    "        param_entry=strategy_type.param_entry or \"\",\n",
    "        param_exit=strategy_type.param_exit or \"\",\n",
    "    )\n",
    "\n",
    "# Load strategies from SQLite (do not define here)\n",
    "list_strat=[]\n",
    "model_map = {m.id: m for m in list_model}\n",
    "\n",
    "strategies_orm = session.query(StrategyORM).filter(StrategyORM.strat_type == strategy_type_row.sk_strategy_type).all()\n",
    "print(f\"Loaded {len(strategies_orm)} strategies from DB for {strategy_type_name}\")\n",
    "\n",
    "for strat_orm in strategies_orm:\n",
    "    combis = session.query(CombiModelsORM).filter(CombiModelsORM.sk_strategy == strat_orm.sk_strategy).all()\n",
    "    models = [model_map[c.sk_model] for c in combis if c.sk_model in model_map]\n",
    "    if not models:\n",
    "        print(f\"Skipping strategy {strat_orm.name} (no models linked)\")\n",
    "        continue\n",
    "    \n",
    "    strat_type = _build_strategy_type(strategy_type_row)\n",
    "    my_strat = prep.Strategy(\n",
    "        id=strat_orm.sk_strategy,\n",
    "        name=strat_orm.name or f\"Strategy_{strat_orm.sk_strategy}\",\n",
    "        type=strat_type,\n",
    "        models=models,\n",
    "        entry_condition=strat_type.get_code_entry(),\n",
    "        exit_condition=strat_type.get_code_exit(),\n",
    "        param_entry=_parse_params(strat_orm.param_entry) or _parse_params(strat_type.param_entry),\n",
    "        param_exit=_parse_params(strat_orm.param_exit) or _parse_params(strat_type.param_exit),\n",
    "    )\n",
    "    list_strat.append(my_strat)\n",
    "    print(f\"Strategy {my_strat.name} loaded from DB\")\n",
    "\n",
    "print(f\"{list_strat.__len__()} strategies loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=joblib.load(PATH_DATA+\"\\\\DTS_FULL\\\\PARIS_TREND_1D_V5_5B_lab_20_adj_20_50_class_5_10_PREDICT_FULL_V2.pkl\")\n",
    "print(df.shape)\n",
    "\n",
    "df = df[df['TRADABLE'] != 0]\n",
    "print(df.shape)\n",
    "\n",
    "default_val=-1\n",
    "# fill na by default_val for cols in list_labels + list_predict_cols \n",
    "df[list_labels + list_predict_cols ] = df[list_labels + list_predict_cols ].fillna(default_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NAME']=df['NAME'].astype(str)\n",
    "df['day'] = df.index.get_level_values(0)\n",
    "df['weekday'] = df['day'].dt.weekday\n",
    "df['week_YYYYWW']=df['day'].dt.strftime('%Y%W')\n",
    "df['is_last_day_week'] = df.groupby('week_YYYYWW')['day'].transform(lambda x: x == x.max())\n",
    "df['next_open'] = df.groupby('CODE')['OPEN'].shift(-1)\n",
    "df['YYMM_int'] = (df['day'].dt.year-2000) * 12 + df['day'].dt.month\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "print(df['YYMM_int'].min(),df['YYMM_int'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each strat add the entry and exit col\n",
    "sort_column='cap_M'\n",
    "sort_group_column='OPEN_DATETIME'\n",
    "\n",
    "for strat in list_strat:\n",
    "    df = strat.add_signals(df=df, sort_column=sort_column, sort_group_column=sort_group_column)\n",
    "\n",
    "print(df.shape)\n",
    "# print list of columns starting with 'entry_' or 'exit_'\n",
    "print([col for col in df.columns if col.startswith('entry_') or col.startswith('exit_')])\n",
    "\n",
    "print(df[df['lab_perf_20d_class_5_adj'].isna()].shape[0])\n",
    "\n",
    "print(df.groupby(['lab_perf_20d_class_5_adj']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the list of CODE where a month is missed between to values of YYMM_int\n",
    "missing_dates_codes = []\n",
    "\n",
    "# Group by CODE and check for gaps in YYMM_int\n",
    "for code, group in df.groupby('CODE'):\n",
    "    group = group.sort_values('YYMM_int')  # Sort by YYMM_int\n",
    "    gaps = group['YYMM_int'].diff()  # Calculate differences between consecutive YYMM_int\n",
    "    if (gaps > 1).any():  # Check if any gap is greater than 1\n",
    "        missing_dates_codes.append(code)\n",
    "\n",
    "# Print the list of codes with missing dates\n",
    "print(\"Codes with missing dates in YYMM_int:\", missing_dates_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario type 1 : fixe quantity scenario type 2 : variable quntity\n",
    "pos_size=1000\n",
    "sl=0.2\n",
    "\n",
    "# def get_sl(df:pd.DataFrame,col:str, SL:float):\n",
    "#     return df[col]*(1-SL)\n",
    "\n",
    "list_scenarii_types=[\n",
    "    {'max_positions': 10, 'position_size': pos_size,'sl':sl, 'scale_up': False, 'sell_all': True, 'fixe_quantity':False},\n",
    "    {'max_positions': 10, 'position_size': pos_size,'sl':sl, 'scale_up': False, 'sell_all': True, 'fixe_quantity':True},\n",
    "    {'max_positions': 5, 'position_size': pos_size*2,'sl':sl, 'scale_up': False, 'sell_all': True, 'fixe_quantity':True}\n",
    "]\n",
    "\n",
    "id_sce=0\n",
    "list_scenarii=[]\n",
    "for strat in list_strat:\n",
    "    for sce_type in list_scenarii_types:\n",
    "        id_sce+=1\n",
    "        my_scenario=prep.Scenario(id=id_sce, strategy=strat, stop_loss='get_sl', params=sce_type)\n",
    "        list_scenarii.append(my_scenario)\n",
    "        # print(f\"Scenario {my_scenario.id} - {my_scenario.strategy.name} - fixe_quantity={my_scenario.params['fixe_quantity']} loaded\")\n",
    "\n",
    "print(f\"{list_scenarii.__len__()} scenarii loaded\")\n",
    "\n",
    "campaign_params={'initial_cash': 10000, 'parts':['TRAIN','VAL'],'commission': 0.003}\n",
    "my_campaign=prep.Campaign(name=\"Campagne Test\", description=\"Campagne test Paris TRAIN VAL\",\n",
    "                           scenarii=list_scenarii, params=campaign_params)\n",
    "\n",
    "df_camp=df[df['PART'].isin(campaign_params['parts'])]#'TRAIN','VAL','CONF'\n",
    "print(df_camp.shape)\n",
    "# add date_start and date_end to my_campaign params\n",
    "my_campaign.params['date_start'] = df_camp.index.get_level_values(0).min()\n",
    "my_campaign.params['date_end'] = df_camp.index.get_level_values(0).max()\n",
    "print(f\"Campaign date range: {my_campaign.params['date_start']} to {my_campaign.params['date_end']}\")\n",
    "\n",
    "# save campaign in DB if not exist\n",
    "existing_camp = session.query(CampaignORM).filter(CampaignORM.code == my_campaign.code).first()\n",
    "if not existing_camp:\n",
    "    sio.insert_object(session, CampaignORM,my_campaign)\n",
    "    camp_orm = session.query(CampaignORM).filter(CampaignORM.code == my_campaign.code).first()\n",
    "    print(f\"Inserted campaign {my_campaign.name} into DB with id {my_campaign.id}\") \n",
    "else:\n",
    "    my_campaign.id = existing_camp.sk_campaign\n",
    "    print(f\"Campaign {my_campaign.name} already exists in DB with id {my_campaign.id}\")\n",
    "\n",
    "#save scenarii in DB if not exist\n",
    "for scenario in list_scenarii:\n",
    "    print(f\"1-{scenario.code=} {scenario.params=}\")\n",
    "    scenario.set_sk_campaign(my_campaign.id)\n",
    "    print(f\" 2 -{scenario.code=} {scenario.params=}\")\n",
    "    existing_sce = session.query(ScenarioORM).filter(ScenarioORM.code == scenario.code).first()\n",
    "    if not existing_sce:\n",
    "        sio.insert_object(session, ScenarioORM,scenario)\n",
    "        sce_orm = session.query(ScenarioORM).filter(ScenarioORM.code == scenario.code).first()\n",
    "        scenario.id = sce_orm.sk_scenario\n",
    "        print(f\"Inserted scenario for strategy {scenario.strategy.name} into DB with id {scenario.id}\")\n",
    "    else:\n",
    "        scenario.id = existing_sce.sk_scenario\n",
    "        print(f\"Scenario for strategy {scenario.strategy.name} already exists in DB with id {scenario.id}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "freq_print=20\n",
    "log_to_file=True\n",
    "\n",
    "dict_portfolio={}\n",
    "for sce in my_campaign.scenarii:\n",
    "    my_suffix=str(sce.strategy.suffix)\n",
    "    entry_col='entry_'+my_suffix\n",
    "    \n",
    "    print(f\"Scenario {sce.id} - {sce.strategy.name} - suffix={my_suffix} - fixe_quantity={sce.params['fixe_quantity']} loaded\")\n",
    "\n",
    "    # filter out rows where 'entry' is 0 and 'exit' is 0\n",
    "    distinct_codes = df_camp[df_camp[entry_col] == 1].index.get_level_values('CODE').unique()\n",
    "    codes_not_in_distinct = df_camp[~df_camp.index.get_level_values('CODE').isin(distinct_codes)].index.get_level_values('CODE').unique().tolist()\n",
    "    print(f\"{len(distinct_codes)=}-{len(codes_not_in_distinct)=}\")\n",
    "\n",
    "    df_clean = df_camp[~df_camp.index.get_level_values('CODE').isin(codes_not_in_distinct)]\n",
    "    print(df_clean.shape)\n",
    "\n",
    "    df_clean=sce.add_sl(df_clean, col='CLOSE', sl=sce.params['sl'])\n",
    "    df_clean.loc[:,'quantity']=np.floor(sce.params['position_size']/df_clean['next_open'])\n",
    "\n",
    "    df_bt=df_clean[['LOW','next_open','exit_'+my_suffix,'sl_'+my_suffix,'rank_'+my_suffix,entry_col,'quantity']]\n",
    "    df_bt = df_bt.rename(columns={entry_col: 'entry','exit_'+my_suffix:'exit', 'next_open': 'price', 'LOW': 'low', 'sl_'+my_suffix: 'sl','rank_'+my_suffix:'priority'})\n",
    "    print(df_bt.columns.tolist())\n",
    "    print(df_bt.index.names)\n",
    "\n",
    "    # backtest\n",
    "    remaining_portfolio = port.backtest_strategy_portfolio(df_in=df_bt, initial_cash=my_campaign.params['initial_cash'],\n",
    "                                                      commission=my_campaign.params['commission'],options=sce.params,\n",
    "                                                      freq_print=freq_print, log_to_file=log_to_file)\n",
    "    print(f'Remaining portfolio: {remaining_portfolio}')\n",
    "    print(f'{remaining_portfolio.nb_trades= } {remaining_portfolio.total_commission= }')\n",
    "    print(remaining_portfolio.metrics)\n",
    "    dict_portfolio[sce.id] = remaining_portfolio\n",
    "\n",
    "    # save result in DB\n",
    "    try:\n",
    "        # insert_bt_result(session: Session, sk_symbol: int, sk_scenario: int,\n",
    "                    #  date_start:str, date_end:str, unit_time:str, log_file: str, extra: Optional[Dict[str, Any]] = None):\n",
    "\n",
    "        bt_result_orm = sio.insert_bt_result(\n",
    "            session=session,\n",
    "            sk_symbol=SK_SYMBOL,\n",
    "            sk_scenario=sce.id,\n",
    "            date_start=str(my_campaign.params['date_start']),\n",
    "            date_end=str(my_campaign.params['date_end']),\n",
    "            unit_time='1D',\n",
    "            log_file=remaining_portfolio.file_path,\n",
    "            extra=remaining_portfolio.metrics\n",
    "        )\n",
    "        print(f\"Inserted BT_RESULT for scenario {sce.id} into DB with id {bt_result_orm.sk_bt_result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting BT_RESULT for scenario {sce.id}: {e}\")\n",
    "\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the risk-reward ratio of every portfolio\n",
    "for sce_id, portfolio in dict_portfolio.items():\n",
    "    print(f\"Scenario ID: {sce_id}, Risk-Reward Win : {portfolio.metrics.get('risk_reward_win', 'N/A')} Risk-Reward Loss : {portfolio.metrics.get('risk_reward_loss', 'N/A')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_portfolio=dict_portfolio[list(dict_portfolio.keys())[0]]\n",
    "# print metrics\n",
    "print(my_portfolio.metrics)\n",
    "# print graphic history of portfolio with matplotlib\n",
    "plt.plot(my_portfolio.history['date'], my_portfolio.history['value'], label='Value')\n",
    "plt.plot(my_portfolio.history['date'], my_portfolio.history['cash'], label='Cash')\n",
    "# plt.plot(my_portfolio.history['date'], my_portfolio.history['value'] - my_portfolio.history['cash'], label='Invested')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenarii generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, hashlib\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "def make_code(strategy_name: str, params: dict) -> str:\n",
    "    s = json.dumps({\"strategy\": strategy_name, \"params\": params}, sort_keys=True, default=str)\n",
    "    return hashlib.md5(s.encode()).hexdigest()[:12]\n",
    "\n",
    "\n",
    "def generate_grid(base_strategy, param_grid: dict, start_id=1):\n",
    "    keys = list(param_grid.keys())\n",
    "    scenarios=[]\n",
    "    id_counter = start_id\n",
    "    for values in product(*[param_grid[k] for k in keys]):\n",
    "        params = dict(zip(keys, values))\n",
    "        code = make_code(base_strategy.name, params)\n",
    "        sce = prep.Scenario(id=id_counter, strategy=base_strategy, stop_loss='get_sl', params=params)\n",
    "        sce.code = code\n",
    "        scenarios.append(sce)\n",
    "        id_counter += 1\n",
    "    return scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid generator + persistence + demo run\n",
    "This section:\n",
    "- Generates a small grid of scenarios for one existing strategy\n",
    "- Persists (campaign + scenarios) to SQLite idempotently using your `sqlite_io` helpers\n",
    "- Runs one scenario end-to-end and writes `BT_RESULT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  list strategies\n",
    "list_strat_type=[]\n",
    "my_strat_type_1 = prep.StrategyType(id=1, name=\"Strat 1\", model_type=\"Class 5\", description=\"1 modèle avec entrée à 4 sortie à 0\")\n",
    "list_strat_type.append(my_strat_type_1)\n",
    "\n",
    "list_strat=[]\n",
    "\n",
    "list_settings_strat = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"type\": TYPE_CLASS_5,\n",
    "        \"settings\": {\n",
    "            'entry_threshold': 4,\n",
    "            'exit_threshold': 0\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"type\": TYPE_CLASS_5,\n",
    "        \"settings\": {\n",
    "            'entry_threshold': 4,\n",
    "            'exit_threshold': 1\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"type\": TYPE_CLASS_10,\n",
    "        \"settings\": {\n",
    "            'entry_threshold': 8,\n",
    "            'exit_threshold': 1\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"type\": TYPE_CLASS_10,\n",
    "        \"settings\": {\n",
    "            'entry_threshold': 8,\n",
    "            'exit_threshold': 2\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "num_strat=1\n",
    "# define entry_condition and exit_condition for the first strat\n",
    "def entry_condition_1(df:pd.DataFrame, models:List[prep.Model], settings: dict ): #threshold:int=4\n",
    "    return df[models[0].predict_col] >= settings.get('entry_threshold', 4)\n",
    "\n",
    "def exit_condition_1(df:pd.DataFrame, models:List[prep.Model], settings: dict ):\n",
    "    return df[models[0].predict_col] <= settings.get('exit_threshold', 0)\n",
    "\n",
    "for n,strat_type in enumerate(list_strat_type):\n",
    "    print(f\"Strategy type {strat_type.name} loaded\")\n",
    "    for m in list_model:\n",
    "       if m.type == strat_type.model_type:\n",
    "           for s in list_settings_strat:\n",
    "               if s[\"type\"] == strat_type.model_type:\n",
    "                   settings = s[\"settings\"]\n",
    "                   name=f\"{strat_type.name}_{m.name}_{s['id']}\".replace(\" \",\"_\")\n",
    "                   my_strat=prep.Strategy(id=strat_type.calculate_id([m], num_strat,s['id']), name=name, type=strat_type,models=[m], \n",
    "                                  entry_condition=entry_condition_1, exit_condition=exit_condition_1, settings=settings)\n",
    "           list_strat.append(my_strat)\n",
    "           print(f\"Strategy {my_strat.name} loaded\")\n",
    "\n",
    "print(f\"{list_strat.__len__()} strategies loaded\")\n",
    "\n",
    "# insert strategies into DB if not exist\n",
    "for strat in list_strat:\n",
    "    existing_strat = session.query(StrategyORM).filter(StrategyORM.name == strat.name).first()\n",
    "    if not existing_strat:\n",
    "        sio.insert_object(session, StrategyORM,strat)\n",
    "        strat_orm = session.query(StrategyORM).filter(StrategyORM.name == strat.name).first()\n",
    "        strat.id = strat_orm.sk_strategy\n",
    "        print(f\"Inserted strategy {strat.name} into DB with id {strat.id}\")\n",
    "    else:\n",
    "        strat.id = existing_strat.sk_strategy\n",
    "        print(f\"Strategy {strat.name} already exists in DB with id {strat.id}\")\n",
    "\n",
    "    list_combi_orm = sio.insert_combi(session, strat)\n",
    "    for combi in list_combi_orm:\n",
    "        print(f\"  - link model to strategy {strat.name} (model {combi.sk_model}) to strategy {combi.sk_strategy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one base strategy to generate scenarios for\n",
    "if not list_strat:\n",
    "    raise ValueError(\"list_strat is empty. Run the strategy creation cells first.\")\n",
    "\n",
    "base_strategy = list_strat[0]\n",
    "print(f\"Using base strategy: {base_strategy.name} (suffix={base_strategy.suffix})\")\n",
    "\n",
    "# Small grid (keep it small for demo)\n",
    "param_grid = {\n",
    "    \"max_positions\": [5, 10],\n",
    "    \"position_size\": [1000, 2000],\n",
    "    \"sl\": [0.15, 0.20],\n",
    "    \"scale_up\": [False],\n",
    "    \"sell_all\": [True],\n",
    "    \"fixe_quantity\": [False, True],\n",
    "}\n",
    "\n",
    "# Generate scenarios (in-memory)\n",
    "grid_scenarios = generate_grid(base_strategy=base_strategy, param_grid=param_grid, start_id=1)\n",
    "print(f\"Generated {len(grid_scenarios)} scenarios\")\n",
    "print(\"First 3 scenario params:\")\n",
    "for s in grid_scenarios[:3]:\n",
    "    print(s.code, s.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Persist campaign + scenarios (idempotent) ---\n",
    "campaign_params = {\"initial_cash\": 10000, \"parts\": [\"TRAIN\", \"VAL\"], \"commission\": 0.003}\n",
    "grid_campaign = prep.Campaign(\n",
    "    name=\"Campagne Grid Demo\",\n",
    "    description=\"Demo grid generation + persistence\",\n",
    "    scenarii=grid_scenarios,\n",
    "    params=campaign_params,\n",
    ")\n",
    "\n",
    "# Ensure date range in campaign params (uses df already loaded in notebook)\n",
    "df_camp = df[df[\"PART\"].isin(grid_campaign.params[\"parts\"])].copy()\n",
    "grid_campaign.params[\"date_start\"] = df_camp.index.get_level_values(0).min()\n",
    "grid_campaign.params[\"date_end\"] = df_camp.index.get_level_values(0).max()\n",
    "print(f\"Grid campaign date range: {grid_campaign.params['date_start']} -> {grid_campaign.params['date_end']}\")\n",
    "\n",
    "# Persist campaign\n",
    "existing_camp = session.query(CampaignORM).filter(CampaignORM.code == grid_campaign.code).first()\n",
    "if not existing_camp:\n",
    "    sio.insert_object(session, CampaignORM, grid_campaign)\n",
    "    existing_camp = session.query(CampaignORM).filter(CampaignORM.code == grid_campaign.code).first()\n",
    "    print(f\"Inserted campaign with id {existing_camp.sk_campaign}\")\n",
    "else:\n",
    "    print(f\"Campaign already exists with id {existing_camp.sk_campaign}\")\n",
    "grid_campaign.id = existing_camp.sk_campaign\n",
    "\n",
    "# Ensure strategy exists + combi links exist\n",
    "existing_strat = session.query(StrategyORM).filter(StrategyORM.name == base_strategy.name).first()\n",
    "if not existing_strat:\n",
    "    sio.insert_object(session, StrategyORM, base_strategy)\n",
    "    existing_strat = session.query(StrategyORM).filter(StrategyORM.name == base_strategy.name).first()\n",
    "base_strategy.id = existing_strat.sk_strategy\n",
    "_ = sio.insert_combi(session, base_strategy)\n",
    "\n",
    "# Persist scenarios (dedupe by code)\n",
    "inserted = 0\n",
    "already = 0\n",
    "for scenario in grid_scenarios:\n",
    "    scenario.set_sk_campaign(grid_campaign.id)\n",
    "    existing_sce = session.query(ScenarioORM).filter(ScenarioORM.code == scenario.code).first()\n",
    "    if existing_sce is None:\n",
    "        sio.insert_object(session, ScenarioORM, scenario)\n",
    "        existing_sce = session.query(ScenarioORM).filter(ScenarioORM.code == scenario.code).first()\n",
    "        inserted += 1\n",
    "    else:\n",
    "        already += 1\n",
    "    scenario.id = existing_sce.sk_scenario\n",
    "\n",
    "print(f\"Scenarios inserted={inserted}, already_present={already}\")\n",
    "print(f\"Example persisted scenario id={grid_scenarios[0].id} code={grid_scenarios[0].code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Demo run: execute 1 scenario and write BT_RESULT ---\n",
    "demo_sce = grid_scenarios[0]\n",
    "suffix = str(demo_sce.strategy.suffix)\n",
    "entry_col = \"entry_\" + suffix\n",
    "exit_col = \"exit_\" + suffix\n",
    "rank_col = \"rank_\" + suffix\n",
    "sl_col = \"sl_\" + suffix\n",
    "\n",
    "# Ensure signal columns exist (only add if missing)\n",
    "if entry_col not in df.columns or exit_col not in df.columns:\n",
    "    df = demo_sce.strategy.add_signals(df=df, sort_column=\"cap_M\", sort_group_column=\"OPEN_DATETIME\")\n",
    "\n",
    "# Restrict to campaign parts\n",
    "df_camp = df[df[\"PART\"].isin(grid_campaign.params[\"parts\"])].copy()\n",
    "\n",
    "# Filter codes with at least 1 entry\n",
    "distinct_codes = df_camp[df_camp[entry_col] == 1].index.get_level_values(\"CODE\").unique()\n",
    "df_clean = df_camp[df_camp.index.get_level_values(\"CODE\").isin(distinct_codes)].copy()\n",
    "print(f\"df_clean shape: {df_clean.shape} (codes={len(distinct_codes)})\")\n",
    "\n",
    "# Add SL + quantity\n",
    "df_clean = demo_sce.add_sl(df_clean, col=\"CLOSE\", sl=demo_sce.params[\"sl\"])\n",
    "df_clean.loc[:, \"quantity\"] = np.floor(demo_sce.params[\"position_size\"] / df_clean[\"next_open\"])\n",
    "\n",
    "df_bt = df_clean[[\"LOW\", \"next_open\", exit_col, sl_col, rank_col, entry_col, \"quantity\"]].copy()\n",
    "df_bt = df_bt.rename(\n",
    "    columns={\n",
    "        entry_col: \"entry\",\n",
    "        exit_col: \"exit\",\n",
    "        \"next_open\": \"price\",\n",
    "        \"LOW\": \"low\",\n",
    "        sl_col: \"sl\",\n",
    "        rank_col: \"priority\",\n",
    "    }\n",
    ")\n",
    "\n",
    "remaining_portfolio = port.backtest_strategy_portfolio(\n",
    "    df_in=df_bt,\n",
    "    initial_cash=grid_campaign.params[\"initial_cash\"],\n",
    "    commission=grid_campaign.params[\"commission\"],\n",
    "    options=demo_sce.params,\n",
    "    freq_print=50,\n",
    "    log_to_file=True,\n",
    ")\n",
    "print(remaining_portfolio.metrics)\n",
    "\n",
    "bt_result_orm = sio.insert_bt_result(\n",
    "    session=session,\n",
    "    sk_symbol=SK_SYMBOL,\n",
    "    sk_scenario=demo_sce.id,  # DB scenario id\n",
    "    date_start=str(grid_campaign.params[\"date_start\"]),\n",
    "    date_end=str(grid_campaign.params[\"date_end\"]),\n",
    "    unit_time=\"1D\",\n",
    "    log_file=remaining_portfolio.file_path,\n",
    "    extra=remaining_portfolio.metrics,\n",
    ")\n",
    "print(f\"Inserted BT_RESULT for demo scenario {demo_sce.id} -> bt_result_id={bt_result_orm.sk_bt_result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
