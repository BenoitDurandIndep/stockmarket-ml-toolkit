{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import importlib\n",
    "import ast\n",
    "from pathlib import Path\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset,RandomSampler\n",
    "from torch.optim import Adam\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "import sqlite_io as sio\n",
    "import add_indicators as indic\n",
    "import split_merge as sm\n",
    "import balance  # wait for new release https://github.com/scikit-learn-contrib/imbalanced-learn/issues/1081\n",
    "import model_mngr as modmgr\n",
    "\n",
    "importlib.reload(sio)\n",
    "importlib.reload(modmgr)\n",
    "importlib.reload(sm)\n",
    "importlib.reload(balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = \"C:\\\\Projets\\\\Data\"\n",
    "PATH_DB_FWK=\"C:\\\\Projets\\\\Data\\\\sqlite\\\\dataset_market.db\"\n",
    "PATH_DB_STOCK=\"C:\\\\Projets\\\\Data\\\\sqlite\\\\dataset_paris_stock_adjusted.db\"\n",
    "PATH_DATA_DTS=PATH_DATA+\"\\\\DTS_FULL\\\\\"\n",
    "\n",
    "SUFFIX_TRAIN=\"_TRAIN.zip\"\n",
    "SUFFIX_VAL=\"_VAL.zip\"\n",
    "SUFFIX_CONF=\"_CONF.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONNECTION TO SQLITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"con_stock\" in locals():\n",
    "        sio.close_connection(con_stock)\n",
    "con_stock = sio.get_connection(str_db_path=PATH_DB_STOCK)\n",
    "\n",
    "if \"con_fwk\" in locals():\n",
    "        sio.close_connection(con_fwk)\n",
    "con_fwk = sio.get_connection(str_db_path=PATH_DB_FWK)\n",
    "\n",
    "my_session_maker = sessionmaker(bind=con_fwk)\n",
    "session=my_session_maker()\n",
    "\n",
    "table_stock=\"DS_PARIS_1D_ADJ_CLEAN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts_name=\"PARIS_TREND_1D_20D_V2\"\n",
    "multi_symbol=\"PARIS_STOCK\"\n",
    "\n",
    "df_base=sio.get_candles_to_df(session=session,con=con_stock, target_table=table_stock,tradable=True)\n",
    "df_work=pd.DataFrame()\n",
    "for code_value in df_base.index.get_level_values('CODE').unique():\n",
    "    sub_df=df_base[df_base.index.get_level_values('CODE') == code_value]\n",
    "    df_work_tmp = indic.add_indicators_to_df(con=con_fwk, df_in=sub_df, dts_name=dts_name,symbol=multi_symbol)\n",
    "    df_work = pd.concat([df_work, df_work_tmp])\n",
    "    \n",
    "df_work.sort_index(inplace=True)\n",
    "df_work.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_work[10000:10010]\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# print(df_work.describe())\n",
    "\n",
    "df_work.round(5).to_csv(\n",
    "    PATH_DATA_DTS+dts_name+\"_BASE.zip\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "START HERE FOR BASE DATASET (all labels included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>sma20</th>\n",
       "      <th>pos_sma20</th>\n",
       "      <th>sma50</th>\n",
       "      <th>sma200</th>\n",
       "      <th>pos_sma50</th>\n",
       "      <th>...</th>\n",
       "      <th>adx14</th>\n",
       "      <th>adx14_neg</th>\n",
       "      <th>adx14_pos</th>\n",
       "      <th>adx14_dif</th>\n",
       "      <th>avg_vol14</th>\n",
       "      <th>pos_avg_vol14</th>\n",
       "      <th>pos_sma20_200</th>\n",
       "      <th>williamsr_14</th>\n",
       "      <th>perf_sma_50_5d</th>\n",
       "      <th>perf_sma_200_5d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPEN_DATETIME</th>\n",
       "      <th>CODE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-04-26</th>\n",
       "      <th>AB.PA</th>\n",
       "      <td>12.98</td>\n",
       "      <td>12.98</td>\n",
       "      <td>12.20</td>\n",
       "      <td>12.68</td>\n",
       "      <td>62866.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.68000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-27</th>\n",
       "      <th>AB.PA</th>\n",
       "      <td>12.74</td>\n",
       "      <td>12.83</td>\n",
       "      <td>12.61</td>\n",
       "      <td>12.70</td>\n",
       "      <td>22370.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.69000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-28</th>\n",
       "      <th>AB.PA</th>\n",
       "      <td>12.70</td>\n",
       "      <td>12.70</td>\n",
       "      <td>12.41</td>\n",
       "      <td>12.50</td>\n",
       "      <td>8211.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.62667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.01003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-29</th>\n",
       "      <th>AB.PA</th>\n",
       "      <td>12.60</td>\n",
       "      <td>12.65</td>\n",
       "      <td>12.46</td>\n",
       "      <td>12.64</td>\n",
       "      <td>4676.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.63000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <th>AB.PA</th>\n",
       "      <td>12.63</td>\n",
       "      <td>12.71</td>\n",
       "      <td>12.55</td>\n",
       "      <td>12.65</td>\n",
       "      <td>4470.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.63400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      OPEN   HIGH    LOW  CLOSE   VOLUME  sma20  pos_sma20  \\\n",
       "OPEN_DATETIME CODE                                                           \n",
       "2010-04-26    AB.PA  12.98  12.98  12.20  12.68  62866.0    NaN        NaN   \n",
       "2010-04-27    AB.PA  12.74  12.83  12.61  12.70  22370.0    NaN        NaN   \n",
       "2010-04-28    AB.PA  12.70  12.70  12.41  12.50   8211.0    NaN        NaN   \n",
       "2010-04-29    AB.PA  12.60  12.65  12.46  12.64   4676.0    NaN        NaN   \n",
       "2010-04-30    AB.PA  12.63  12.71  12.55  12.65   4470.0    NaN        NaN   \n",
       "\n",
       "                        sma50  sma200  pos_sma50  ...  adx14  adx14_neg  \\\n",
       "OPEN_DATETIME CODE                                ...                     \n",
       "2010-04-26    AB.PA  12.68000     NaN    0.00000  ...    0.0        0.0   \n",
       "2010-04-27    AB.PA  12.69000     NaN    0.00079  ...    0.0        0.0   \n",
       "2010-04-28    AB.PA  12.62667     NaN   -0.01003  ...    0.0        0.0   \n",
       "2010-04-29    AB.PA  12.63000     NaN    0.00079  ...    0.0        0.0   \n",
       "2010-04-30    AB.PA  12.63400     NaN    0.00127  ...    0.0        0.0   \n",
       "\n",
       "                     adx14_pos  adx14_dif  avg_vol14  pos_avg_vol14  \\\n",
       "OPEN_DATETIME CODE                                                    \n",
       "2010-04-26    AB.PA        0.0        0.0        NaN            NaN   \n",
       "2010-04-27    AB.PA        0.0        0.0        NaN            NaN   \n",
       "2010-04-28    AB.PA        0.0        0.0        NaN            NaN   \n",
       "2010-04-29    AB.PA        0.0        0.0        NaN            NaN   \n",
       "2010-04-30    AB.PA        0.0        0.0        NaN            NaN   \n",
       "\n",
       "                     pos_sma20_200  williamsr_14  perf_sma_50_5d  \\\n",
       "OPEN_DATETIME CODE                                                 \n",
       "2010-04-26    AB.PA            NaN           NaN             NaN   \n",
       "2010-04-27    AB.PA            NaN           NaN             NaN   \n",
       "2010-04-28    AB.PA            NaN           NaN             NaN   \n",
       "2010-04-29    AB.PA            NaN           NaN             NaN   \n",
       "2010-04-30    AB.PA            NaN           NaN             NaN   \n",
       "\n",
       "                     perf_sma_200_5d  \n",
       "OPEN_DATETIME CODE                    \n",
       "2010-04-26    AB.PA              NaN  \n",
       "2010-04-27    AB.PA              NaN  \n",
       "2010-04-28    AB.PA              NaN  \n",
       "2010-04-29    AB.PA              NaN  \n",
       "2010-04-30    AB.PA              NaN  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dts_name=\"PARIS_TREND_1D_20D_V2\"\n",
    "# dts_name=\"PARIS_TREND_1D_50D_V1\"\n",
    "multi_symbol=\"PARIS_STOCK\"\n",
    "\n",
    "df_work=pd.read_csv(PATH_DATA_DTS+dts_name+\"_BASE.zip\",sep=\",\",index_col=[\"OPEN_DATETIME\",\"CODE\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "df_work.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with no pos_sma200 \n",
    "df_work=df_work.dropna(subset=['pos_sma200'])\n",
    "\n",
    "# if williamsr_14 >0 =0 if williamsr_14<-100 = -100\n",
    "# df_work['williamsr_14']=df_work['williamsr_14'].apply(lambda x: 0 if x>0 else x)\n",
    "# df_work['williamsr_14']=df_work['williamsr_14'].apply(lambda x: -100 if x<-100 else x)\n",
    "\n",
    "# if williamsr_14 >0 =0 if williamsr_14<-100 = -100\n",
    "df_work.loc[df_work['williamsr_14'] > 0, 'williamsr_14'] = 0\n",
    "df_work.loc[df_work['williamsr_14'] < -100, 'williamsr_14'] = -100\n",
    "\n",
    "# print min and max of the columns williamsr_14, perf_sma_50_5d, perf_sma_200_5d\n",
    "# print(f\"{df_work['williamsr_14'].min()=}\")  inf-100\n",
    "# print(f\"{df_work['williamsr_14'].max()=}\") sup 0\n",
    "\n",
    "# df_check=df_work[df_work['perf_sma_50_5d'] > 1]\n",
    "# df_check=df_check[df_check['ret_1d'] <= 2]\n",
    "# print(df_check.index.get_level_values('CODE').unique())\n",
    "# df_check[df_check.index.get_level_values('CODE')=='AI.PA']\n",
    "# df_check.head(5)\n",
    "# df_check=df_work[df_work.index.get_level_values('CODE')=='AI.PA']\n",
    "# CATG\n",
    "# mask = df_work['stdev20_1d'] > 1000\n",
    "# df_work.drop(df_work[mask].index, inplace=True)\n",
    "# df_check[6000:6010]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work[10000:10010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           LABEL\n",
      "0   lab_perf_20d\n",
      "1   lab_perf_50d\n",
      "2  lab_perf_125d\n"
     ]
    }
   ],
   "source": [
    "df_work = indic.drop_indicators_by_type(\n",
    "    con=con_fwk, df_in=df_work, dts_name=dts_name, symbol=multi_symbol, ind_type=0)\n",
    "list_label = indic.get_ind_list_by_type_for_dts(\n",
    "    con=con_fwk, dts_name=dts_name, symbol_code=multi_symbol, ind_type=2)\n",
    "print(list_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>pos_sma20</th>\n",
       "      <th>pos_sma50</th>\n",
       "      <th>pos_sma200</th>\n",
       "      <th>pos_sma50_200</th>\n",
       "      <th>pos_sma20_50</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_donchian20_lo</th>\n",
       "      <th>adx14</th>\n",
       "      <th>adx14_neg</th>\n",
       "      <th>adx14_pos</th>\n",
       "      <th>adx14_dif</th>\n",
       "      <th>pos_avg_vol14</th>\n",
       "      <th>pos_sma20_200</th>\n",
       "      <th>williamsr_14</th>\n",
       "      <th>perf_sma_50_5d</th>\n",
       "      <th>perf_sma_200_5d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPEN_DATETIME</th>\n",
       "      <th>CODE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">1995-11-24</th>\n",
       "      <th>BN.PA</th>\n",
       "      <td>5.3121</td>\n",
       "      <td>5.3292</td>\n",
       "      <td>5.3035</td>\n",
       "      <td>5.3121</td>\n",
       "      <td>1112239.0</td>\n",
       "      <td>0.01177</td>\n",
       "      <td>0.01509</td>\n",
       "      <td>0.03347</td>\n",
       "      <td>0.01811</td>\n",
       "      <td>0.00328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07840</td>\n",
       "      <td>20.28870</td>\n",
       "      <td>17.98263</td>\n",
       "      <td>24.68813</td>\n",
       "      <td>6.70549</td>\n",
       "      <td>0.57971</td>\n",
       "      <td>0.02145</td>\n",
       "      <td>-43.92655</td>\n",
       "      <td>-0.00423</td>\n",
       "      <td>0.00475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOI.PA</th>\n",
       "      <td>2.4317</td>\n",
       "      <td>2.4317</td>\n",
       "      <td>2.3817</td>\n",
       "      <td>2.3817</td>\n",
       "      <td>3392.0</td>\n",
       "      <td>-0.03791</td>\n",
       "      <td>-0.04912</td>\n",
       "      <td>0.10459</td>\n",
       "      <td>0.16165</td>\n",
       "      <td>-0.01165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>40.68240</td>\n",
       "      <td>27.60340</td>\n",
       "      <td>14.71410</td>\n",
       "      <td>-12.88930</td>\n",
       "      <td>0.08447</td>\n",
       "      <td>0.14812</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>-0.00193</td>\n",
       "      <td>0.00800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDI.PA</th>\n",
       "      <td>5.5472</td>\n",
       "      <td>5.5958</td>\n",
       "      <td>5.5472</td>\n",
       "      <td>5.5958</td>\n",
       "      <td>85024.0</td>\n",
       "      <td>0.01444</td>\n",
       "      <td>0.04278</td>\n",
       "      <td>0.15177</td>\n",
       "      <td>0.10453</td>\n",
       "      <td>0.02793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>14.69556</td>\n",
       "      <td>19.13562</td>\n",
       "      <td>20.95757</td>\n",
       "      <td>1.82195</td>\n",
       "      <td>0.11627</td>\n",
       "      <td>0.13538</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.00866</td>\n",
       "      <td>0.00701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELEC.PA</th>\n",
       "      <td>3.9661</td>\n",
       "      <td>3.9661</td>\n",
       "      <td>3.9661</td>\n",
       "      <td>3.9661</td>\n",
       "      <td>162.0</td>\n",
       "      <td>-0.02968</td>\n",
       "      <td>-0.05170</td>\n",
       "      <td>-0.03635</td>\n",
       "      <td>0.01619</td>\n",
       "      <td>-0.02270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02507</td>\n",
       "      <td>14.74654</td>\n",
       "      <td>55.61796</td>\n",
       "      <td>43.88082</td>\n",
       "      <td>-11.73714</td>\n",
       "      <td>0.63943</td>\n",
       "      <td>-0.00688</td>\n",
       "      <td>-71.42857</td>\n",
       "      <td>-0.00965</td>\n",
       "      <td>0.00166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFC.PA</th>\n",
       "      <td>3.3486</td>\n",
       "      <td>3.3486</td>\n",
       "      <td>3.2076</td>\n",
       "      <td>3.2093</td>\n",
       "      <td>32614.0</td>\n",
       "      <td>0.00242</td>\n",
       "      <td>0.03218</td>\n",
       "      <td>0.24682</td>\n",
       "      <td>0.20795</td>\n",
       "      <td>0.02969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06339</td>\n",
       "      <td>33.09500</td>\n",
       "      <td>12.06264</td>\n",
       "      <td>26.76666</td>\n",
       "      <td>14.70403</td>\n",
       "      <td>2.22395</td>\n",
       "      <td>0.24381</td>\n",
       "      <td>-61.60998</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.01102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAT.PA</th>\n",
       "      <td>24.8529</td>\n",
       "      <td>24.8529</td>\n",
       "      <td>24.8529</td>\n",
       "      <td>24.8529</td>\n",
       "      <td>154.0</td>\n",
       "      <td>-0.00517</td>\n",
       "      <td>-0.01589</td>\n",
       "      <td>-0.05827</td>\n",
       "      <td>-0.04307</td>\n",
       "      <td>-0.01078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05672</td>\n",
       "      <td>11.41274</td>\n",
       "      <td>49.78475</td>\n",
       "      <td>43.88114</td>\n",
       "      <td>-5.90361</td>\n",
       "      <td>0.26857</td>\n",
       "      <td>-0.05338</td>\n",
       "      <td>-31.34328</td>\n",
       "      <td>-0.00242</td>\n",
       "      <td>-0.00235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LI.PA</th>\n",
       "      <td>2.0554</td>\n",
       "      <td>2.0554</td>\n",
       "      <td>2.0435</td>\n",
       "      <td>2.0435</td>\n",
       "      <td>143309.0</td>\n",
       "      <td>0.01303</td>\n",
       "      <td>-0.00332</td>\n",
       "      <td>-0.02706</td>\n",
       "      <td>-0.02382</td>\n",
       "      <td>-0.01615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03726</td>\n",
       "      <td>36.83981</td>\n",
       "      <td>9.74307</td>\n",
       "      <td>17.22198</td>\n",
       "      <td>7.47891</td>\n",
       "      <td>2.38002</td>\n",
       "      <td>-0.03958</td>\n",
       "      <td>-41.56051</td>\n",
       "      <td>-0.00162</td>\n",
       "      <td>-0.00054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RE.PA</th>\n",
       "      <td>4.8710</td>\n",
       "      <td>4.8710</td>\n",
       "      <td>4.7188</td>\n",
       "      <td>4.7188</td>\n",
       "      <td>33953.0</td>\n",
       "      <td>0.00203</td>\n",
       "      <td>-0.01415</td>\n",
       "      <td>-0.00043</td>\n",
       "      <td>0.01391</td>\n",
       "      <td>-0.01614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06898</td>\n",
       "      <td>12.87952</td>\n",
       "      <td>19.22271</td>\n",
       "      <td>23.88377</td>\n",
       "      <td>4.66107</td>\n",
       "      <td>0.72411</td>\n",
       "      <td>-0.00245</td>\n",
       "      <td>-44.43796</td>\n",
       "      <td>-0.01148</td>\n",
       "      <td>0.00182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAVE.PA</th>\n",
       "      <td>15.3615</td>\n",
       "      <td>15.6143</td>\n",
       "      <td>15.3615</td>\n",
       "      <td>15.3615</td>\n",
       "      <td>28928.0</td>\n",
       "      <td>0.03593</td>\n",
       "      <td>0.05608</td>\n",
       "      <td>0.05257</td>\n",
       "      <td>-0.00332</td>\n",
       "      <td>0.01945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08714</td>\n",
       "      <td>48.09569</td>\n",
       "      <td>4.50842</td>\n",
       "      <td>30.13034</td>\n",
       "      <td>25.62192</td>\n",
       "      <td>0.41972</td>\n",
       "      <td>0.01606</td>\n",
       "      <td>-36.89894</td>\n",
       "      <td>0.00149</td>\n",
       "      <td>0.00358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEP.PA</th>\n",
       "      <td>1.4524</td>\n",
       "      <td>1.4524</td>\n",
       "      <td>1.3325</td>\n",
       "      <td>1.3325</td>\n",
       "      <td>83775.0</td>\n",
       "      <td>-0.13757</td>\n",
       "      <td>-0.15298</td>\n",
       "      <td>-0.16537</td>\n",
       "      <td>-0.01463</td>\n",
       "      <td>-0.01787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>26.08714</td>\n",
       "      <td>65.25452</td>\n",
       "      <td>17.32163</td>\n",
       "      <td>-47.93289</td>\n",
       "      <td>3.00736</td>\n",
       "      <td>-0.03224</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>-0.00313</td>\n",
       "      <td>-0.00357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          OPEN     HIGH      LOW    CLOSE     VOLUME  \\\n",
       "OPEN_DATETIME CODE                                                     \n",
       "1995-11-24    BN.PA     5.3121   5.3292   5.3035   5.3121  1112239.0   \n",
       "              BOI.PA    2.4317   2.4317   2.3817   2.3817     3392.0   \n",
       "              CDI.PA    5.5472   5.5958   5.5472   5.5958    85024.0   \n",
       "              ELEC.PA   3.9661   3.9661   3.9661   3.9661      162.0   \n",
       "              GFC.PA    3.3486   3.3486   3.2076   3.2093    32614.0   \n",
       "              LAT.PA   24.8529  24.8529  24.8529  24.8529      154.0   \n",
       "              LI.PA     2.0554   2.0554   2.0435   2.0435   143309.0   \n",
       "              RE.PA     4.8710   4.8710   4.7188   4.7188    33953.0   \n",
       "              SAVE.PA  15.3615  15.6143  15.3615  15.3615    28928.0   \n",
       "              TEP.PA    1.4524   1.4524   1.3325   1.3325    83775.0   \n",
       "\n",
       "                       pos_sma20  pos_sma50  pos_sma200  pos_sma50_200  \\\n",
       "OPEN_DATETIME CODE                                                       \n",
       "1995-11-24    BN.PA      0.01177    0.01509     0.03347        0.01811   \n",
       "              BOI.PA    -0.03791   -0.04912     0.10459        0.16165   \n",
       "              CDI.PA     0.01444    0.04278     0.15177        0.10453   \n",
       "              ELEC.PA   -0.02968   -0.05170    -0.03635        0.01619   \n",
       "              GFC.PA     0.00242    0.03218     0.24682        0.20795   \n",
       "              LAT.PA    -0.00517   -0.01589    -0.05827       -0.04307   \n",
       "              LI.PA      0.01303   -0.00332    -0.02706       -0.02382   \n",
       "              RE.PA      0.00203   -0.01415    -0.00043        0.01391   \n",
       "              SAVE.PA    0.03593    0.05608     0.05257       -0.00332   \n",
       "              TEP.PA    -0.13757   -0.15298    -0.16537       -0.01463   \n",
       "\n",
       "                       pos_sma20_50  ...  pos_donchian20_lo     adx14  \\\n",
       "OPEN_DATETIME CODE                   ...                                \n",
       "1995-11-24    BN.PA         0.00328  ...            0.07840  20.28870   \n",
       "              BOI.PA       -0.01165  ...            0.00000  40.68240   \n",
       "              CDI.PA        0.02793  ...            0.04362  14.69556   \n",
       "              ELEC.PA      -0.02270  ...            0.02507  14.74654   \n",
       "              GFC.PA        0.02969  ...            0.06339  33.09500   \n",
       "              LAT.PA       -0.01078  ...            0.05672  11.41274   \n",
       "              LI.PA        -0.01615  ...            0.03726  36.83981   \n",
       "              RE.PA        -0.01614  ...            0.06898  12.87952   \n",
       "              SAVE.PA       0.01945  ...            0.08714  48.09569   \n",
       "              TEP.PA       -0.01787  ...            0.00000  26.08714   \n",
       "\n",
       "                       adx14_neg  adx14_pos  adx14_dif  pos_avg_vol14  \\\n",
       "OPEN_DATETIME CODE                                                      \n",
       "1995-11-24    BN.PA     17.98263   24.68813    6.70549        0.57971   \n",
       "              BOI.PA    27.60340   14.71410  -12.88930        0.08447   \n",
       "              CDI.PA    19.13562   20.95757    1.82195        0.11627   \n",
       "              ELEC.PA   55.61796   43.88082  -11.73714        0.63943   \n",
       "              GFC.PA    12.06264   26.76666   14.70403        2.22395   \n",
       "              LAT.PA    49.78475   43.88114   -5.90361        0.26857   \n",
       "              LI.PA      9.74307   17.22198    7.47891        2.38002   \n",
       "              RE.PA     19.22271   23.88377    4.66107        0.72411   \n",
       "              SAVE.PA    4.50842   30.13034   25.62192        0.41972   \n",
       "              TEP.PA    65.25452   17.32163  -47.93289        3.00736   \n",
       "\n",
       "                       pos_sma20_200  williamsr_14  perf_sma_50_5d  \\\n",
       "OPEN_DATETIME CODE                                                   \n",
       "1995-11-24    BN.PA          0.02145     -43.92655        -0.00423   \n",
       "              BOI.PA         0.14812    -100.00000        -0.00193   \n",
       "              CDI.PA         0.13538      -0.00000         0.00866   \n",
       "              ELEC.PA       -0.00688     -71.42857        -0.00965   \n",
       "              GFC.PA         0.24381     -61.60998         0.00240   \n",
       "              LAT.PA        -0.05338     -31.34328        -0.00242   \n",
       "              LI.PA         -0.03958     -41.56051        -0.00162   \n",
       "              RE.PA         -0.00245     -44.43796        -0.01148   \n",
       "              SAVE.PA        0.01606     -36.89894         0.00149   \n",
       "              TEP.PA        -0.03224    -100.00000        -0.00313   \n",
       "\n",
       "                       perf_sma_200_5d  \n",
       "OPEN_DATETIME CODE                      \n",
       "1995-11-24    BN.PA            0.00475  \n",
       "              BOI.PA           0.00800  \n",
       "              CDI.PA           0.00701  \n",
       "              ELEC.PA          0.00166  \n",
       "              GFC.PA           0.01102  \n",
       "              LAT.PA          -0.00235  \n",
       "              LI.PA           -0.00054  \n",
       "              RE.PA            0.00182  \n",
       "              SAVE.PA          0.00358  \n",
       "              TEP.PA          -0.00357  \n",
       "\n",
       "[10 rows x 53 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_work=df_work.droplevel('CODE') !!!!!!\n",
    "df_work.sort_index(inplace=True)\n",
    "df_work[10000:10010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected: df_selected.shape=(838987, 29) valid: df_valid.shape=(231843, 29) confirm: df_confirm.shape=(244596, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_sma20</th>\n",
       "      <th>pos_sma50</th>\n",
       "      <th>pos_sma200</th>\n",
       "      <th>rsi14</th>\n",
       "      <th>sma20_rsi14</th>\n",
       "      <th>ret_5d</th>\n",
       "      <th>pos_top20</th>\n",
       "      <th>pos_top50</th>\n",
       "      <th>pos_bot20</th>\n",
       "      <th>pos_bot50</th>\n",
       "      <th>...</th>\n",
       "      <th>cmf_20</th>\n",
       "      <th>adx14</th>\n",
       "      <th>adx14_neg</th>\n",
       "      <th>adx14_pos</th>\n",
       "      <th>adx14_dif</th>\n",
       "      <th>pos_avg_vol14</th>\n",
       "      <th>pos_sma20_200</th>\n",
       "      <th>perf_sma_50_5d</th>\n",
       "      <th>perf_sma_200_5d</th>\n",
       "      <th>TICKER</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPEN_DATETIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996-01-04</th>\n",
       "      <td>0.03032</td>\n",
       "      <td>0.04450</td>\n",
       "      <td>0.04734</td>\n",
       "      <td>68.61368</td>\n",
       "      <td>57.45887</td>\n",
       "      <td>0.02203</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.06381</td>\n",
       "      <td>0.10456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.68106</td>\n",
       "      <td>34.55900</td>\n",
       "      <td>16.30154</td>\n",
       "      <td>32.80825</td>\n",
       "      <td>16.50671</td>\n",
       "      <td>1.43364</td>\n",
       "      <td>0.01652</td>\n",
       "      <td>0.01085</td>\n",
       "      <td>0.00350</td>\n",
       "      <td>SAVE.PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-04</th>\n",
       "      <td>0.00911</td>\n",
       "      <td>-0.01411</td>\n",
       "      <td>-0.06019</td>\n",
       "      <td>51.10742</td>\n",
       "      <td>48.38847</td>\n",
       "      <td>0.01840</td>\n",
       "      <td>-0.03493</td>\n",
       "      <td>-0.11954</td>\n",
       "      <td>0.05738</td>\n",
       "      <td>0.10499</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00654</td>\n",
       "      <td>21.08814</td>\n",
       "      <td>30.49097</td>\n",
       "      <td>26.14443</td>\n",
       "      <td>-4.34654</td>\n",
       "      <td>0.10186</td>\n",
       "      <td>-0.06867</td>\n",
       "      <td>-0.01641</td>\n",
       "      <td>-0.00343</td>\n",
       "      <td>TEP.PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-04</th>\n",
       "      <td>0.05060</td>\n",
       "      <td>0.03251</td>\n",
       "      <td>0.16970</td>\n",
       "      <td>58.77622</td>\n",
       "      <td>45.64184</td>\n",
       "      <td>0.03184</td>\n",
       "      <td>-0.02624</td>\n",
       "      <td>-0.02624</td>\n",
       "      <td>0.10498</td>\n",
       "      <td>0.10498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11007</td>\n",
       "      <td>19.47531</td>\n",
       "      <td>27.82168</td>\n",
       "      <td>32.68546</td>\n",
       "      <td>4.86378</td>\n",
       "      <td>1.73709</td>\n",
       "      <td>0.11336</td>\n",
       "      <td>0.00850</td>\n",
       "      <td>0.01067</td>\n",
       "      <td>TFI.PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-04</th>\n",
       "      <td>0.01749</td>\n",
       "      <td>-0.03933</td>\n",
       "      <td>0.04489</td>\n",
       "      <td>49.29749</td>\n",
       "      <td>38.37917</td>\n",
       "      <td>0.04334</td>\n",
       "      <td>-0.04469</td>\n",
       "      <td>-0.10454</td>\n",
       "      <td>0.06570</td>\n",
       "      <td>0.06570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.24571</td>\n",
       "      <td>22.52874</td>\n",
       "      <td>21.82438</td>\n",
       "      <td>25.90113</td>\n",
       "      <td>4.07675</td>\n",
       "      <td>1.35506</td>\n",
       "      <td>0.02694</td>\n",
       "      <td>-0.00896</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>VIRP.PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-05</th>\n",
       "      <td>0.01285</td>\n",
       "      <td>0.00631</td>\n",
       "      <td>-0.00376</td>\n",
       "      <td>52.83213</td>\n",
       "      <td>49.86578</td>\n",
       "      <td>-0.00893</td>\n",
       "      <td>-0.02243</td>\n",
       "      <td>-0.03173</td>\n",
       "      <td>0.04537</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14429</td>\n",
       "      <td>14.92596</td>\n",
       "      <td>28.76524</td>\n",
       "      <td>30.40562</td>\n",
       "      <td>1.64038</td>\n",
       "      <td>0.50658</td>\n",
       "      <td>-0.01641</td>\n",
       "      <td>0.00690</td>\n",
       "      <td>0.00293</td>\n",
       "      <td>BN.PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-05</th>\n",
       "      <td>0.03801</td>\n",
       "      <td>0.02653</td>\n",
       "      <td>0.10581</td>\n",
       "      <td>61.28371</td>\n",
       "      <td>49.09160</td>\n",
       "      <td>0.03733</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.03275</td>\n",
       "      <td>0.05942</td>\n",
       "      <td>0.07388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50814</td>\n",
       "      <td>29.47521</td>\n",
       "      <td>17.54691</td>\n",
       "      <td>16.77613</td>\n",
       "      <td>-0.77078</td>\n",
       "      <td>0.12624</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>-0.00504</td>\n",
       "      <td>0.00746</td>\n",
       "      <td>BOI.PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-05</th>\n",
       "      <td>0.03567</td>\n",
       "      <td>0.12029</td>\n",
       "      <td>0.28952</td>\n",
       "      <td>66.79495</td>\n",
       "      <td>71.57781</td>\n",
       "      <td>0.00596</td>\n",
       "      <td>-0.01651</td>\n",
       "      <td>-0.01651</td>\n",
       "      <td>0.11823</td>\n",
       "      <td>0.22153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.42051</td>\n",
       "      <td>41.67504</td>\n",
       "      <td>14.69324</td>\n",
       "      <td>43.10116</td>\n",
       "      <td>28.40792</td>\n",
       "      <td>0.71424</td>\n",
       "      <td>0.24511</td>\n",
       "      <td>0.02108</td>\n",
       "      <td>0.01041</td>\n",
       "      <td>CDI.PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-05</th>\n",
       "      <td>-0.00497</td>\n",
       "      <td>-0.04962</td>\n",
       "      <td>-0.10276</td>\n",
       "      <td>44.68482</td>\n",
       "      <td>41.48714</td>\n",
       "      <td>0.00438</td>\n",
       "      <td>-0.04037</td>\n",
       "      <td>-0.11778</td>\n",
       "      <td>0.00438</td>\n",
       "      <td>0.00438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05534</td>\n",
       "      <td>10.20240</td>\n",
       "      <td>38.68822</td>\n",
       "      <td>47.13757</td>\n",
       "      <td>8.44935</td>\n",
       "      <td>1.14001</td>\n",
       "      <td>-0.09827</td>\n",
       "      <td>-0.00897</td>\n",
       "      <td>0.00085</td>\n",
       "      <td>ELEC.PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-05</th>\n",
       "      <td>0.01013</td>\n",
       "      <td>0.02410</td>\n",
       "      <td>0.19591</td>\n",
       "      <td>57.52017</td>\n",
       "      <td>55.21953</td>\n",
       "      <td>0.01443</td>\n",
       "      <td>-0.01506</td>\n",
       "      <td>-0.05496</td>\n",
       "      <td>0.04269</td>\n",
       "      <td>0.07580</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01669</td>\n",
       "      <td>26.80769</td>\n",
       "      <td>14.80556</td>\n",
       "      <td>34.98566</td>\n",
       "      <td>20.18010</td>\n",
       "      <td>0.10965</td>\n",
       "      <td>0.18391</td>\n",
       "      <td>0.00753</td>\n",
       "      <td>0.01116</td>\n",
       "      <td>GFC.PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-05</th>\n",
       "      <td>0.06142</td>\n",
       "      <td>0.06319</td>\n",
       "      <td>0.01671</td>\n",
       "      <td>63.83981</td>\n",
       "      <td>49.25421</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.17008</td>\n",
       "      <td>0.17008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>15.60680</td>\n",
       "      <td>35.58655</td>\n",
       "      <td>52.39946</td>\n",
       "      <td>16.81291</td>\n",
       "      <td>0.95004</td>\n",
       "      <td>-0.04213</td>\n",
       "      <td>0.00509</td>\n",
       "      <td>-0.00040</td>\n",
       "      <td>LAT.PA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               pos_sma20  pos_sma50  pos_sma200     rsi14  sma20_rsi14  \\\n",
       "OPEN_DATETIME                                                            \n",
       "1996-01-04       0.03032    0.04450     0.04734  68.61368     57.45887   \n",
       "1996-01-04       0.00911   -0.01411    -0.06019  51.10742     48.38847   \n",
       "1996-01-04       0.05060    0.03251     0.16970  58.77622     45.64184   \n",
       "1996-01-04       0.01749   -0.03933     0.04489  49.29749     38.37917   \n",
       "1996-01-05       0.01285    0.00631    -0.00376  52.83213     49.86578   \n",
       "1996-01-05       0.03801    0.02653     0.10581  61.28371     49.09160   \n",
       "1996-01-05       0.03567    0.12029     0.28952  66.79495     71.57781   \n",
       "1996-01-05      -0.00497   -0.04962    -0.10276  44.68482     41.48714   \n",
       "1996-01-05       0.01013    0.02410     0.19591  57.52017     55.21953   \n",
       "1996-01-05       0.06142    0.06319     0.01671  63.83981     49.25421   \n",
       "\n",
       "                ret_5d  pos_top20  pos_top50  pos_bot20  pos_bot50  ...  \\\n",
       "OPEN_DATETIME                                                       ...   \n",
       "1996-01-04     0.02203    0.00000    0.00000    0.06381    0.10456  ...   \n",
       "1996-01-04     0.01840   -0.03493   -0.11954    0.05738    0.10499  ...   \n",
       "1996-01-04     0.03184   -0.02624   -0.02624    0.10498    0.10498  ...   \n",
       "1996-01-04     0.04334   -0.04469   -0.10454    0.06570    0.06570  ...   \n",
       "1996-01-05    -0.00893   -0.02243   -0.03173    0.04537    0.05623  ...   \n",
       "1996-01-05     0.03733    0.00000   -0.03275    0.05942    0.07388  ...   \n",
       "1996-01-05     0.00596   -0.01651   -0.01651    0.11823    0.22153  ...   \n",
       "1996-01-05     0.00438   -0.04037   -0.11778    0.00438    0.00438  ...   \n",
       "1996-01-05     0.01443   -0.01506   -0.05496    0.04269    0.07580  ...   \n",
       "1996-01-05     0.00000    0.00000    0.00000    0.17008    0.17008  ...   \n",
       "\n",
       "                cmf_20     adx14  adx14_neg  adx14_pos  adx14_dif  \\\n",
       "OPEN_DATETIME                                                       \n",
       "1996-01-04     0.68106  34.55900   16.30154   32.80825   16.50671   \n",
       "1996-01-04    -0.00654  21.08814   30.49097   26.14443   -4.34654   \n",
       "1996-01-04     0.11007  19.47531   27.82168   32.68546    4.86378   \n",
       "1996-01-04     0.24571  22.52874   21.82438   25.90113    4.07675   \n",
       "1996-01-05     0.14429  14.92596   28.76524   30.40562    1.64038   \n",
       "1996-01-05     0.50814  29.47521   17.54691   16.77613   -0.77078   \n",
       "1996-01-05     0.42051  41.67504   14.69324   43.10116   28.40792   \n",
       "1996-01-05     0.05534  10.20240   38.68822   47.13757    8.44935   \n",
       "1996-01-05    -0.01669  26.80769   14.80556   34.98566   20.18010   \n",
       "1996-01-05     0.08836  15.60680   35.58655   52.39946   16.81291   \n",
       "\n",
       "               pos_avg_vol14  pos_sma20_200  perf_sma_50_5d  perf_sma_200_5d  \\\n",
       "OPEN_DATETIME                                                                  \n",
       "1996-01-04           1.43364        0.01652         0.01085          0.00350   \n",
       "1996-01-04           0.10186       -0.06867        -0.01641         -0.00343   \n",
       "1996-01-04           1.73709        0.11336         0.00850          0.01067   \n",
       "1996-01-04           1.35506        0.02694        -0.00896          0.00673   \n",
       "1996-01-05           0.50658       -0.01641         0.00690          0.00293   \n",
       "1996-01-05           0.12624        0.06531        -0.00504          0.00746   \n",
       "1996-01-05           0.71424        0.24511         0.02108          0.01041   \n",
       "1996-01-05           1.14001       -0.09827        -0.00897          0.00085   \n",
       "1996-01-05           0.10965        0.18391         0.00753          0.01116   \n",
       "1996-01-05           0.95004       -0.04213         0.00509         -0.00040   \n",
       "\n",
       "                TICKER  \n",
       "OPEN_DATETIME           \n",
       "1996-01-04     SAVE.PA  \n",
       "1996-01-04      TEP.PA  \n",
       "1996-01-04      TFI.PA  \n",
       "1996-01-04     VIRP.PA  \n",
       "1996-01-05       BN.PA  \n",
       "1996-01-05      BOI.PA  \n",
       "1996-01-05      CDI.PA  \n",
       "1996-01-05     ELEC.PA  \n",
       "1996-01-05      GFC.PA  \n",
       "1996-01-05      LAT.PA  \n",
       "\n",
       "[10 rows x 29 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_studied = \"lab_perf_50d\"\n",
    "algo_studied = \"LSTM_CLASS\"\n",
    "dts_name=\"PARIS_TREND_1D_20D_V2\"\n",
    "\n",
    "df_work_lab = indic.drop_indicators_not_selected(con=con_fwk, df_in=df_work, dts_name=dts_name, symbol=multi_symbol,label=lab_studied,algo=algo_studied)\n",
    "# print(df_work_lab.head(5))\n",
    "\n",
    "# move CODE to column to be able to slit the dataset\n",
    "df_work_lab['TICKER'] = df_work_lab.index.get_level_values('CODE')\n",
    "df_work_lab=df_work_lab.droplevel('CODE')\n",
    "\n",
    "df_split=sm.split_df_by_label_strat(\n",
    "    df_in=df_work_lab, list_label=[lab_studied], split_timeframe=\"M\",random_split=False,split_strat=(80,10,10))\n",
    "df_selected = df_split['df_'+lab_studied+'_train']\n",
    "df_valid = df_split['df_'+lab_studied+'_valid']\n",
    "df_confirm = df_split['df_'+lab_studied+'_confirm']\n",
    "df_selected.sort_index(inplace=True)\n",
    "df_valid.sort_index(inplace=True)\n",
    "df_confirm.sort_index(inplace=True)\n",
    "\n",
    "print(f\"selected: {df_selected.shape=} valid: {df_valid.shape=} confirm: {df_confirm.shape=}\")\n",
    "df_selected[10000:10010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        min      max\n",
      "lab_perf_50d_class                  \n",
      "0                  -0.83200 -0.07920\n",
      "1                  -0.07919 -0.00751\n",
      "2                  -0.00750  0.04948\n",
      "3                   0.04949  0.12576\n",
      "4                   0.12577  4.92040\n"
     ]
    }
   ],
   "source": [
    "label=lab_studied\n",
    "df_class=balance.add_class_by_lab_nb_lines(df_in=df_selected,str_label=lab_studied,nb_class=5,bool_replace_label=False)\n",
    "min_max_lab_by_class = df_class.groupby(label+'_class')[label].agg(['min', 'max'])\n",
    "print(min_max_lab_by_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPEN_DATETIME\n",
      "1989-10-27    4\n",
      "2017-01-31    4\n",
      "Name: lab_perf_50d, dtype: int64\n",
      "OPEN_DATETIME\n",
      "2017-02-01    3.0\n",
      "2020-06-30    4.0\n",
      "Name: lab_perf_50d, dtype: float64\n",
      "OPEN_DATETIME\n",
      "2020-07-01    4.0\n",
      "2023-11-01    1.0\n",
      "Name: lab_perf_50d, dtype: float64\n",
      "lab_perf_50d\n",
      "0    167804\n",
      "1    167794\n",
      "2    167818\n",
      "3    167779\n",
      "4    167792\n",
      "Name: count, dtype: int64\n",
      "lab_perf_50d\n",
      "0.0    56691\n",
      "1.0    48735\n",
      "2.0    45584\n",
      "3.0    41231\n",
      "4.0    39552\n",
      "Name: count, dtype: int64\n",
      "lab_perf_50d\n",
      "0.0    61105\n",
      "1.0    51970\n",
      "2.0    43750\n",
      "3.0    41295\n",
      "4.0    46476\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_sma20</th>\n",
       "      <th>pos_sma50</th>\n",
       "      <th>pos_sma200</th>\n",
       "      <th>rsi14</th>\n",
       "      <th>sma20_rsi14</th>\n",
       "      <th>ret_5d</th>\n",
       "      <th>pos_top20</th>\n",
       "      <th>pos_top50</th>\n",
       "      <th>pos_bot20</th>\n",
       "      <th>pos_bot50</th>\n",
       "      <th>...</th>\n",
       "      <th>adx14</th>\n",
       "      <th>adx14_neg</th>\n",
       "      <th>adx14_pos</th>\n",
       "      <th>adx14_dif</th>\n",
       "      <th>pos_avg_vol14</th>\n",
       "      <th>pos_sma20_200</th>\n",
       "      <th>perf_sma_50_5d</th>\n",
       "      <th>perf_sma_200_5d</th>\n",
       "      <th>TICKER</th>\n",
       "      <th>lab_perf_50d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPEN_DATETIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996-01-04</th>\n",
       "      <td>0.03032</td>\n",
       "      <td>0.04450</td>\n",
       "      <td>0.04734</td>\n",
       "      <td>68.61368</td>\n",
       "      <td>57.45887</td>\n",
       "      <td>0.02203</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.06381</td>\n",
       "      <td>0.10456</td>\n",
       "      <td>...</td>\n",
       "      <td>34.55900</td>\n",
       "      <td>16.30154</td>\n",
       "      <td>32.80825</td>\n",
       "      <td>16.50671</td>\n",
       "      <td>1.43364</td>\n",
       "      <td>0.01652</td>\n",
       "      <td>0.01085</td>\n",
       "      <td>0.00350</td>\n",
       "      <td>SAVE.PA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-04</th>\n",
       "      <td>0.00911</td>\n",
       "      <td>-0.01411</td>\n",
       "      <td>-0.06019</td>\n",
       "      <td>51.10742</td>\n",
       "      <td>48.38847</td>\n",
       "      <td>0.01840</td>\n",
       "      <td>-0.03493</td>\n",
       "      <td>-0.11954</td>\n",
       "      <td>0.05738</td>\n",
       "      <td>0.10499</td>\n",
       "      <td>...</td>\n",
       "      <td>21.08814</td>\n",
       "      <td>30.49097</td>\n",
       "      <td>26.14443</td>\n",
       "      <td>-4.34654</td>\n",
       "      <td>0.10186</td>\n",
       "      <td>-0.06867</td>\n",
       "      <td>-0.01641</td>\n",
       "      <td>-0.00343</td>\n",
       "      <td>TEP.PA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-04</th>\n",
       "      <td>0.05060</td>\n",
       "      <td>0.03251</td>\n",
       "      <td>0.16970</td>\n",
       "      <td>58.77622</td>\n",
       "      <td>45.64184</td>\n",
       "      <td>0.03184</td>\n",
       "      <td>-0.02624</td>\n",
       "      <td>-0.02624</td>\n",
       "      <td>0.10498</td>\n",
       "      <td>0.10498</td>\n",
       "      <td>...</td>\n",
       "      <td>19.47531</td>\n",
       "      <td>27.82168</td>\n",
       "      <td>32.68546</td>\n",
       "      <td>4.86378</td>\n",
       "      <td>1.73709</td>\n",
       "      <td>0.11336</td>\n",
       "      <td>0.00850</td>\n",
       "      <td>0.01067</td>\n",
       "      <td>TFI.PA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-04</th>\n",
       "      <td>0.01749</td>\n",
       "      <td>-0.03933</td>\n",
       "      <td>0.04489</td>\n",
       "      <td>49.29749</td>\n",
       "      <td>38.37917</td>\n",
       "      <td>0.04334</td>\n",
       "      <td>-0.04469</td>\n",
       "      <td>-0.10454</td>\n",
       "      <td>0.06570</td>\n",
       "      <td>0.06570</td>\n",
       "      <td>...</td>\n",
       "      <td>22.52874</td>\n",
       "      <td>21.82438</td>\n",
       "      <td>25.90113</td>\n",
       "      <td>4.07675</td>\n",
       "      <td>1.35506</td>\n",
       "      <td>0.02694</td>\n",
       "      <td>-0.00896</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>VIRP.PA</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-05</th>\n",
       "      <td>0.01285</td>\n",
       "      <td>0.00631</td>\n",
       "      <td>-0.00376</td>\n",
       "      <td>52.83213</td>\n",
       "      <td>49.86578</td>\n",
       "      <td>-0.00893</td>\n",
       "      <td>-0.02243</td>\n",
       "      <td>-0.03173</td>\n",
       "      <td>0.04537</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>14.92596</td>\n",
       "      <td>28.76524</td>\n",
       "      <td>30.40562</td>\n",
       "      <td>1.64038</td>\n",
       "      <td>0.50658</td>\n",
       "      <td>-0.01641</td>\n",
       "      <td>0.00690</td>\n",
       "      <td>0.00293</td>\n",
       "      <td>BN.PA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-05</th>\n",
       "      <td>0.03801</td>\n",
       "      <td>0.02653</td>\n",
       "      <td>0.10581</td>\n",
       "      <td>61.28371</td>\n",
       "      <td>49.09160</td>\n",
       "      <td>0.03733</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.03275</td>\n",
       "      <td>0.05942</td>\n",
       "      <td>0.07388</td>\n",
       "      <td>...</td>\n",
       "      <td>29.47521</td>\n",
       "      <td>17.54691</td>\n",
       "      <td>16.77613</td>\n",
       "      <td>-0.77078</td>\n",
       "      <td>0.12624</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>-0.00504</td>\n",
       "      <td>0.00746</td>\n",
       "      <td>BOI.PA</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-05</th>\n",
       "      <td>0.03567</td>\n",
       "      <td>0.12029</td>\n",
       "      <td>0.28952</td>\n",
       "      <td>66.79495</td>\n",
       "      <td>71.57781</td>\n",
       "      <td>0.00596</td>\n",
       "      <td>-0.01651</td>\n",
       "      <td>-0.01651</td>\n",
       "      <td>0.11823</td>\n",
       "      <td>0.22153</td>\n",
       "      <td>...</td>\n",
       "      <td>41.67504</td>\n",
       "      <td>14.69324</td>\n",
       "      <td>43.10116</td>\n",
       "      <td>28.40792</td>\n",
       "      <td>0.71424</td>\n",
       "      <td>0.24511</td>\n",
       "      <td>0.02108</td>\n",
       "      <td>0.01041</td>\n",
       "      <td>CDI.PA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-05</th>\n",
       "      <td>-0.00497</td>\n",
       "      <td>-0.04962</td>\n",
       "      <td>-0.10276</td>\n",
       "      <td>44.68482</td>\n",
       "      <td>41.48714</td>\n",
       "      <td>0.00438</td>\n",
       "      <td>-0.04037</td>\n",
       "      <td>-0.11778</td>\n",
       "      <td>0.00438</td>\n",
       "      <td>0.00438</td>\n",
       "      <td>...</td>\n",
       "      <td>10.20240</td>\n",
       "      <td>38.68822</td>\n",
       "      <td>47.13757</td>\n",
       "      <td>8.44935</td>\n",
       "      <td>1.14001</td>\n",
       "      <td>-0.09827</td>\n",
       "      <td>-0.00897</td>\n",
       "      <td>0.00085</td>\n",
       "      <td>ELEC.PA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-05</th>\n",
       "      <td>0.01013</td>\n",
       "      <td>0.02410</td>\n",
       "      <td>0.19591</td>\n",
       "      <td>57.52017</td>\n",
       "      <td>55.21953</td>\n",
       "      <td>0.01443</td>\n",
       "      <td>-0.01506</td>\n",
       "      <td>-0.05496</td>\n",
       "      <td>0.04269</td>\n",
       "      <td>0.07580</td>\n",
       "      <td>...</td>\n",
       "      <td>26.80769</td>\n",
       "      <td>14.80556</td>\n",
       "      <td>34.98566</td>\n",
       "      <td>20.18010</td>\n",
       "      <td>0.10965</td>\n",
       "      <td>0.18391</td>\n",
       "      <td>0.00753</td>\n",
       "      <td>0.01116</td>\n",
       "      <td>GFC.PA</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-05</th>\n",
       "      <td>0.06142</td>\n",
       "      <td>0.06319</td>\n",
       "      <td>0.01671</td>\n",
       "      <td>63.83981</td>\n",
       "      <td>49.25421</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.17008</td>\n",
       "      <td>0.17008</td>\n",
       "      <td>...</td>\n",
       "      <td>15.60680</td>\n",
       "      <td>35.58655</td>\n",
       "      <td>52.39946</td>\n",
       "      <td>16.81291</td>\n",
       "      <td>0.95004</td>\n",
       "      <td>-0.04213</td>\n",
       "      <td>0.00509</td>\n",
       "      <td>-0.00040</td>\n",
       "      <td>LAT.PA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               pos_sma20  pos_sma50  pos_sma200     rsi14  sma20_rsi14  \\\n",
       "OPEN_DATETIME                                                            \n",
       "1996-01-04       0.03032    0.04450     0.04734  68.61368     57.45887   \n",
       "1996-01-04       0.00911   -0.01411    -0.06019  51.10742     48.38847   \n",
       "1996-01-04       0.05060    0.03251     0.16970  58.77622     45.64184   \n",
       "1996-01-04       0.01749   -0.03933     0.04489  49.29749     38.37917   \n",
       "1996-01-05       0.01285    0.00631    -0.00376  52.83213     49.86578   \n",
       "1996-01-05       0.03801    0.02653     0.10581  61.28371     49.09160   \n",
       "1996-01-05       0.03567    0.12029     0.28952  66.79495     71.57781   \n",
       "1996-01-05      -0.00497   -0.04962    -0.10276  44.68482     41.48714   \n",
       "1996-01-05       0.01013    0.02410     0.19591  57.52017     55.21953   \n",
       "1996-01-05       0.06142    0.06319     0.01671  63.83981     49.25421   \n",
       "\n",
       "                ret_5d  pos_top20  pos_top50  pos_bot20  pos_bot50  ...  \\\n",
       "OPEN_DATETIME                                                       ...   \n",
       "1996-01-04     0.02203    0.00000    0.00000    0.06381    0.10456  ...   \n",
       "1996-01-04     0.01840   -0.03493   -0.11954    0.05738    0.10499  ...   \n",
       "1996-01-04     0.03184   -0.02624   -0.02624    0.10498    0.10498  ...   \n",
       "1996-01-04     0.04334   -0.04469   -0.10454    0.06570    0.06570  ...   \n",
       "1996-01-05    -0.00893   -0.02243   -0.03173    0.04537    0.05623  ...   \n",
       "1996-01-05     0.03733    0.00000   -0.03275    0.05942    0.07388  ...   \n",
       "1996-01-05     0.00596   -0.01651   -0.01651    0.11823    0.22153  ...   \n",
       "1996-01-05     0.00438   -0.04037   -0.11778    0.00438    0.00438  ...   \n",
       "1996-01-05     0.01443   -0.01506   -0.05496    0.04269    0.07580  ...   \n",
       "1996-01-05     0.00000    0.00000    0.00000    0.17008    0.17008  ...   \n",
       "\n",
       "                  adx14  adx14_neg  adx14_pos  adx14_dif  pos_avg_vol14  \\\n",
       "OPEN_DATETIME                                                             \n",
       "1996-01-04     34.55900   16.30154   32.80825   16.50671        1.43364   \n",
       "1996-01-04     21.08814   30.49097   26.14443   -4.34654        0.10186   \n",
       "1996-01-04     19.47531   27.82168   32.68546    4.86378        1.73709   \n",
       "1996-01-04     22.52874   21.82438   25.90113    4.07675        1.35506   \n",
       "1996-01-05     14.92596   28.76524   30.40562    1.64038        0.50658   \n",
       "1996-01-05     29.47521   17.54691   16.77613   -0.77078        0.12624   \n",
       "1996-01-05     41.67504   14.69324   43.10116   28.40792        0.71424   \n",
       "1996-01-05     10.20240   38.68822   47.13757    8.44935        1.14001   \n",
       "1996-01-05     26.80769   14.80556   34.98566   20.18010        0.10965   \n",
       "1996-01-05     15.60680   35.58655   52.39946   16.81291        0.95004   \n",
       "\n",
       "               pos_sma20_200  perf_sma_50_5d  perf_sma_200_5d   TICKER  \\\n",
       "OPEN_DATETIME                                                            \n",
       "1996-01-04           0.01652         0.01085          0.00350  SAVE.PA   \n",
       "1996-01-04          -0.06867        -0.01641         -0.00343   TEP.PA   \n",
       "1996-01-04           0.11336         0.00850          0.01067   TFI.PA   \n",
       "1996-01-04           0.02694        -0.00896          0.00673  VIRP.PA   \n",
       "1996-01-05          -0.01641         0.00690          0.00293    BN.PA   \n",
       "1996-01-05           0.06531        -0.00504          0.00746   BOI.PA   \n",
       "1996-01-05           0.24511         0.02108          0.01041   CDI.PA   \n",
       "1996-01-05          -0.09827        -0.00897          0.00085  ELEC.PA   \n",
       "1996-01-05           0.18391         0.00753          0.01116   GFC.PA   \n",
       "1996-01-05          -0.04213         0.00509         -0.00040   LAT.PA   \n",
       "\n",
       "               lab_perf_50d  \n",
       "OPEN_DATETIME                \n",
       "1996-01-04                1  \n",
       "1996-01-04                4  \n",
       "1996-01-04                2  \n",
       "1996-01-04                3  \n",
       "1996-01-05                1  \n",
       "1996-01-05                3  \n",
       "1996-01-05                4  \n",
       "1996-01-05                2  \n",
       "1996-01-05                3  \n",
       "1996-01-05                4  \n",
       "\n",
       "[10 rows x 29 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label=lab_studied\n",
    "df_class=balance.add_class_by_lab_nb_lines(df_in=df_selected,str_label=lab_studied,nb_class=5,bool_replace_label=True)\n",
    "df_class.sort_index(inplace=True)\n",
    "categ_50={0:[-1,-0.0792],1:[-0.0792,-0.0075],2:[-0.0075,0.04948],3:[0.04948,0.12576],4:[0.12576,5]}\n",
    "# categ_20={0:[-1,-0.0520],1:[-0.0520,-0.0089],2:[-0.0089,0.0235],3:[0.0235,0.0713],4:[0.0713,4]}\n",
    "df_class_val=balance.add_lab_by_class(df_in=df_valid,str_label=lab_studied, categ=categ_50,bool_replace_label=True) # categ\n",
    "df_class_val.sort_index(inplace=True)\n",
    "df_class_conf=balance.add_lab_by_class(df_in=df_confirm,str_label=lab_studied, categ=categ_50,bool_replace_label=True) # categ\n",
    "df_class_conf.sort_index(inplace=True)\n",
    "print(df_class.loc[:, label].dropna().iloc[[0, -1]])\n",
    "print(df_class_val.loc[:, label].dropna().iloc[[0, -1]])\n",
    "print(df_class_conf.loc[:, label].dropna().iloc[[0, -1]])\n",
    "# df_class_clean=df_class.drop(['OPEN','HIGH','LOW','CLOSE','VOLUME','lab_perf_125d','lab_perf_20d','lab_perf_50d'],axis=1)\n",
    "data = df_class[label]\n",
    "print(data.value_counts().sort_index())\n",
    "data_val = df_class_val[label]\n",
    "print(data_val.value_counts().sort_index())\n",
    "data_conf = df_class_conf[label]\n",
    "print(data_conf.value_counts().sort_index())\n",
    "df_class[10000:10010]\n",
    "# min_max_lab_by_class = df_class.groupby(label+'_class')[label].agg(['min', 'max'])\n",
    "# print(min_max_lab_by_class)\n",
    "\n",
    "# lab_perf_20d : train min nb rows 211000 validation 53000 confirm 55000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  SAVE DATASETS\n",
    "file_name=\"PARIS_TREND_1D_50D_V2\"\n",
    "df_class.round(5).to_csv(\n",
    "    PATH_DATA_DTS+file_name+SUFFIX_TRAIN, sep=\",\")\n",
    "df_class_val.round(5).to_csv(\n",
    "    PATH_DATA_DTS+file_name+SUFFIX_VAL, sep=\",\")\n",
    "df_class_conf.round(5).to_csv(\n",
    "    PATH_DATA_DTS+file_name+SUFFIX_CONF, sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate and save scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Projets\\\\Data\\\\DTS_FULL\\\\PARIS_TREND_1D_50D_V2_train_colab_lstm_norm_2405_scaler.save']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dts_name=\"PARIS_TREND_1D_50D_V2\"\n",
    "multi_symbol=\"PARIS_STOCK\"\n",
    "label = \"lab_perf_50d\"\n",
    "\n",
    "df_class=pd.read_csv(PATH_DATA_DTS+dts_name+SUFFIX_TRAIN,sep=\",\",index_col=[\"OPEN_DATETIME\",\"TICKER\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "df_class=df_class.dropna(subset=[label])\n",
    "df_class=df_class.sort_index()\n",
    "\n",
    "df_norm,norm_scaler= balance.normalize_df(df_in=df_class,str_label=label,tuple_ft_range=(-1,1))\n",
    "\n",
    "file_name=dts_name+\"_train_colab_lstm_norm_2405\"\n",
    "scaler_name=file_name+\"_scaler.save\"\n",
    "joblib.dump(norm_scaler,filename=PATH_DATA_DTS+scaler_name)\n",
    "\n",
    "# df_class_val=pd.read_csv(PATH_DATA_DTS+dts_name+SUFFIX_VAL,sep=\",\",index_col=[\"OPEN_DATETIME\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "# df_class_val.dropna(subset=[label], inplace=True)\n",
    "# df_class_val.sort_index(inplace=True)\n",
    "\n",
    "# list_feat = df_class.columns.values.tolist()\n",
    "# list_feat.remove(label)\n",
    "# X, y = sm.split_df_x_y(\n",
    "#     df_in=df_class, list_features=list_feat, str_label=label, drop_na=True)\n",
    "# nb_val=211000\n",
    "# method = RandomUnderSampler(sampling_strategy={0:nb_val,1:nb_val,2:nb_val,3:nb_val}) \n",
    "# df_x_train, col_y_train=  method.fit_resample(X, y)\n",
    "# print(col_y_train.value_counts().sort_index())\n",
    "\n",
    "# X, y = sm.split_df_x_y(\n",
    "#     df_in=df_class_val, list_features=list_feat, str_label=label, drop_na=True)\n",
    "# nb_val=53000\n",
    "# method = RandomUnderSampler(sampling_strategy={0:nb_val,1:nb_val,2:nb_val,3:nb_val}) # 53000 pour lab 20 et nn pour lab 50\n",
    "# df_x_val, col_y_val=  method.fit_resample(X, y)\n",
    "# print(col_y_val.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train et val df, normalize,  undersample  and preparation for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_class_train_norm.shape=(831990, 28) df_class_val_norm.shape=(231793, 28)\n",
      "                       pos_sma20  pos_sma50  pos_sma200     rsi14  \\\n",
      "OPEN_DATETIME TICKER                                                \n",
      "1998-01-20    RE.PA    -0.401871  -0.530231   -0.504369  0.387174   \n",
      "              SAVE.PA  -0.429049  -0.551279   -0.530901  0.333374   \n",
      "              TEP.PA   -0.379269  -0.510884   -0.525588  0.509715   \n",
      "              TFI.PA   -0.396483  -0.499134   -0.470829  0.504751   \n",
      "              VIRP.PA  -0.414437  -0.515018   -0.598517  0.253438   \n",
      "\n",
      "                       sma20_rsi14    ret_5d  pos_top20  pos_top50  pos_bot20  \\\n",
      "OPEN_DATETIME TICKER                                                            \n",
      "1998-01-20    RE.PA       0.182813 -0.503245   0.983320   0.983966  -0.918870   \n",
      "              SAVE.PA     0.195811 -0.515616   0.980994   0.981731  -0.967591   \n",
      "              TEP.PA      0.198386 -0.495371   0.984695   0.985288  -0.902783   \n",
      "              TFI.PA      0.370092 -0.505919   1.000000   1.000000  -0.917227   \n",
      "              VIRP.PA     0.222042 -0.520613   0.919375   0.922500  -0.900381   \n",
      "\n",
      "                       pos_bot50  ...   cmf_20     adx14  adx14_neg  \\\n",
      "OPEN_DATETIME TICKER              ...                                 \n",
      "1998-01-20    RE.PA    -0.928958  ...  0.35220 -0.385375  -0.698540   \n",
      "              SAVE.PA  -0.917901  ...  0.05869 -0.586076  -0.813125   \n",
      "              TEP.PA   -0.905425  ...  0.28968 -0.469373  -0.726042   \n",
      "              TFI.PA   -0.858916  ...  0.16207 -0.148957  -0.779130   \n",
      "              VIRP.PA  -0.899170  ...  0.46392 -0.387973  -0.813607   \n",
      "\n",
      "                       adx14_pos  adx14_dif  pos_avg_vol14  pos_sma20_200  \\\n",
      "OPEN_DATETIME TICKER                                                        \n",
      "1998-01-20    RE.PA    -0.278402   0.210069      -0.924964      -0.332989   \n",
      "              SAVE.PA  -0.421942   0.195591      -0.911933      -0.343584   \n",
      "              TEP.PA   -0.260655   0.232694      -0.953953      -0.384536   \n",
      "              TFI.PA   -0.141195   0.318968      -0.855588      -0.291030   \n",
      "              VIRP.PA  -0.461689   0.175959      -0.954981      -0.456234   \n",
      "\n",
      "                       perf_sma_50_5d  perf_sma_200_5d  lab_perf_50d  \n",
      "OPEN_DATETIME TICKER                                                  \n",
      "1998-01-20    RE.PA          0.056033        -0.048995             3  \n",
      "              SAVE.PA        0.064044        -0.059569             4  \n",
      "              TEP.PA         0.058978        -0.082391             4  \n",
      "              TFI.PA         0.098127        -0.050670             3  \n",
      "              VIRP.PA        0.061845        -0.163107             3  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "dts_name=\"PARIS_TREND_1D_50D_V2\"\n",
    "multi_symbol=\"PARIS_STOCK\"\n",
    "label = \"lab_perf_50d\"\n",
    "file_name=dts_name+\"_train_colab_lstm_norm_2405\"\n",
    "scaler_name=file_name+\"_scaler.save\"\n",
    "scaler=joblib.load(PATH_DATA_DTS+scaler_name)\n",
    "\n",
    "\n",
    "df_class=pd.read_csv(PATH_DATA_DTS+dts_name+SUFFIX_TRAIN,sep=\",\",index_col=[\"OPEN_DATETIME\",\"TICKER\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "df_class=df_class.dropna(subset=[label])\n",
    "df_class=df_class.loc['1995-01-01':] # drop rows < 1995-01-01\n",
    "df_class=df_class.sort_index()\n",
    "df_class_val=pd.read_csv(PATH_DATA_DTS+dts_name+SUFFIX_VAL,sep=\",\",index_col=[\"OPEN_DATETIME\",\"TICKER\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "df_class_val=df_class_val.dropna(subset=[label])\n",
    "df_class_val=df_class_val.sort_index()\n",
    "\n",
    "# normalize df_class and df_class_val\n",
    "df_class_train_norm=balance.normalize_df_scaler(df_in=df_class, str_label=label,scaler=scaler)\n",
    "df_class_val_norm=balance.normalize_df_scaler(df_in=df_class_val, str_label=label,scaler=scaler)\n",
    "\n",
    "print(f\"{df_class_train_norm.shape=} {df_class_val_norm.shape=}\")\n",
    "print(df_class_train_norm[10000:10005])\n",
    "# print type of index of df_class_train_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{type(df_class_train_norm.index[0])= } {type(df_class_train_norm.index[1])= }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 2024-07-25 16:25:42 cnt=20 ticker='ALDEL.PA'\n",
      "time 2024-07-25 16:30:23 cnt=40 ticker='ALNOV.PA'\n",
      "time 2024-07-25 16:34:46 cnt=60 ticker='BEN.PA'\n",
      "time 2024-07-25 16:39:52 cnt=80 ticker='CDI.PA'\n",
      "time 2024-07-25 16:44:16 cnt=100 ticker='DG.PA'\n",
      "time 2024-07-25 16:48:28 cnt=120 ticker='ETL.PA'\n",
      "time 2024-07-25 16:52:56 cnt=140 ticker='GTT.PA'\n",
      "time 2024-07-25 16:57:20 cnt=160 ticker='LBIRD.PA'\n",
      "time 2024-07-25 17:02:48 cnt=180 ticker='MRN.PA'\n",
      "time 2024-07-25 17:08:16 cnt=200 ticker='POXEL.PA'\n",
      "time 2024-07-25 17:15:57 cnt=220 ticker='SCR.PA'\n",
      "time 2024-07-25 17:23:48 cnt=240 ticker='TRI.PA'\n",
      "2024-07-25 17:29:42 train seq ok\n",
      "time 2024-07-25 17:31:24 cnt=20 ticker='ALCYB.PA'\n",
      "time 2024-07-25 17:33:11 cnt=40 ticker='ALLDL.PA'\n",
      "time 2024-07-25 17:34:58 cnt=60 ticker='ATO.PA'\n",
      "time 2024-07-25 17:37:02 cnt=80 ticker='CAP.PA'\n",
      "time 2024-07-25 17:39:13 cnt=100 ticker='CRLA.PA'\n",
      "time 2024-07-25 17:41:11 cnt=120 ticker='ENGI.PA'\n",
      "time 2024-07-25 17:43:20 cnt=140 ticker='GDS.PA'\n",
      "time 2024-07-25 17:45:15 cnt=160 ticker='IPN.PA'\n",
      "time 2024-07-25 17:47:10 cnt=180 ticker='MC.PA'\n",
      "time 2024-07-25 17:48:57 cnt=200 ticker='NXI.PA'\n",
      "time 2024-07-25 17:50:47 cnt=220 ticker='RCO.PA'\n",
      "time 2024-07-25 17:52:55 cnt=240 ticker='SGO.PA'\n",
      "time 2024-07-25 17:54:46 cnt=260 ticker='UBI.PA'\n",
      "df_class_train_seq.shape=(831990, 29) df_class_val_seq.shape=(231793, 29)\n",
      "                      pos_sma20  pos_sma50  pos_sma200     rsi14  sma20_rsi14  \\\n",
      "OPEN_DATETIME TICKER                                                            \n",
      "2016-10-17    AC.PA   -0.501521  -0.630326   -0.658272 -0.460224    -0.127326   \n",
      "2016-10-18    AC.PA   -0.482841  -0.616831   -0.648421 -0.238727    -0.139778   \n",
      "2016-10-19    AC.PA   -0.448301  -0.590277   -0.628386  0.073411    -0.135167   \n",
      "2016-10-20    AC.PA   -0.448632  -0.590855   -0.628973  0.062996    -0.135018   \n",
      "2016-10-21    AC.PA   -0.448294  -0.591361   -0.629508  0.052895    -0.140102   \n",
      "\n",
      "                        ret_5d  pos_top20  pos_top50  pos_bot20  pos_bot50  \\\n",
      "OPEN_DATETIME TICKER                                                         \n",
      "2016-10-17    AC.PA  -0.560996   0.738418   0.739639  -1.000000  -1.000000   \n",
      "2016-10-18    AC.PA  -0.547479   0.794361   0.793173  -0.986927  -0.989755   \n",
      "2016-10-19    AC.PA  -0.513909   0.909672   0.903558  -0.959977  -0.968633   \n",
      "2016-10-20    AC.PA  -0.509966   0.905520   0.899567  -0.960950  -0.969396   \n",
      "2016-10-21    AC.PA  -0.511684   0.913423   0.895913  -0.961845  -0.970098   \n",
      "\n",
      "                      ...     adx14  adx14_neg  adx14_pos  adx14_dif  \\\n",
      "OPEN_DATETIME TICKER  ...                                              \n",
      "2016-10-17    AC.PA   ... -0.581407  -0.343171  -0.764754  -0.210792   \n",
      "2016-10-18    AC.PA   ... -0.566156  -0.410425  -0.707837  -0.148706   \n",
      "2016-10-19    AC.PA   ... -0.601214  -0.501340  -0.497559   0.001890   \n",
      "2016-10-20    AC.PA   ... -0.633768  -0.521011  -0.517377   0.001817   \n",
      "2016-10-21    AC.PA   ... -0.658038  -0.550293  -0.508726   0.020783   \n",
      "\n",
      "                      pos_avg_vol14  pos_sma20_200  perf_sma_50_5d  \\\n",
      "OPEN_DATETIME TICKER                                                 \n",
      "2016-10-17    AC.PA       -0.848053      -0.468827       -0.036007   \n",
      "2016-10-18    AC.PA       -0.893781      -0.470573       -0.035929   \n",
      "2016-10-19    AC.PA       -0.806314      -0.470820       -0.032356   \n",
      "2016-10-20    AC.PA       -0.921291      -0.471413       -0.029371   \n",
      "2016-10-21    AC.PA       -0.942267      -0.472519       -0.025720   \n",
      "\n",
      "                      perf_sma_200_5d  lab_perf_50d  \\\n",
      "OPEN_DATETIME TICKER                                  \n",
      "2016-10-17    AC.PA         -0.190013             3   \n",
      "2016-10-18    AC.PA         -0.186034             3   \n",
      "2016-10-19    AC.PA         -0.181114             2   \n",
      "2016-10-20    AC.PA         -0.177031             2   \n",
      "2016-10-21    AC.PA         -0.175461             2   \n",
      "\n",
      "                                                               SEQUENCE  \n",
      "OPEN_DATETIME TICKER                                                     \n",
      "2016-10-17    AC.PA   [[-0.44677, -0.58218, -0.61794, 0.1237, 0.0259...  \n",
      "2016-10-18    AC.PA   [[-0.4725, -0.60259, -0.63393, -0.16102, 0.009...  \n",
      "2016-10-19    AC.PA   [[-0.48115, -0.61003, -0.64006, -0.24276, -0.0...  \n",
      "2016-10-20    AC.PA   [[-0.48553, -0.61396, -0.64362, -0.28775, -0.0...  \n",
      "2016-10-21    AC.PA   [[-0.48807, -0.61596, -0.6456, -0.31407, -0.04...  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "list_feat = df_class.columns.values.tolist()\n",
    "list_feat.remove(label)\n",
    "\n",
    "sequence_length = 10\n",
    "col_sequence = \"SEQUENCE\"\n",
    "\n",
    "# for each TICKER in index of df_class_train_norm, sort data with index and prepare sequences\n",
    "df_class_train_norm_sorted = df_class_train_norm.sort_index(level=['TICKER', 'OPEN_DATETIME'])\n",
    "df_class_val_norm_sorted = df_class_val_norm.sort_index(level=['TICKER', 'OPEN_DATETIME'])\n",
    "\n",
    "# Prepare sequences for each TICKER\n",
    "df_class_train_seq = pd.DataFrame()\n",
    "cnt=0\n",
    "for ticker in df_class_train_norm_sorted.index.get_level_values('TICKER').unique():\n",
    "    sub_df=df_class_train_norm_sorted[df_class_train_norm_sorted.index.get_level_values('TICKER') == ticker]\n",
    "    sub_df = sm.prepare_sequences_df(\n",
    "        df_in=sub_df, list_features=list_feat, sequence_length=sequence_length, str_new_col=col_sequence)\n",
    "    cnt+=1\n",
    "    if cnt%20==0:\n",
    "        print(f\"time {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} {cnt=} {ticker=}\")\n",
    "        gc.collect()\n",
    "    # if cnt==3:\n",
    "    #     break\n",
    "    \n",
    "# concatenate all TICKER data in the same df\n",
    "    df_class_train_seq = pd.concat([df_class_train_seq, sub_df])\n",
    "\n",
    "print((f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} train seq ok\"))\n",
    "\n",
    "df_class_val_seq = pd.DataFrame()\n",
    "cnt=0\n",
    "for ticker in df_class_val_norm_sorted.index.get_level_values('TICKER').unique():\n",
    "    sub_df=df_class_val_norm_sorted[df_class_val_norm_sorted.index.get_level_values('TICKER') == ticker]\n",
    "    sub_df = sm.prepare_sequences_df(\n",
    "        df_in=sub_df, list_features=list_feat, sequence_length=sequence_length, str_new_col=col_sequence)\n",
    "    cnt+=1\n",
    "    if cnt%20==0:\n",
    "        print(f\"time {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} {cnt=} {ticker=}\")\n",
    "        gc.collect()\n",
    "    # if cnt==3:\n",
    "    #     break\n",
    "    \n",
    "# concatenate all TICKER data in the same df\n",
    "    df_class_val_seq = pd.concat([df_class_val_seq, sub_df])\n",
    "\n",
    "print(f\"{df_class_train_seq.shape=} {df_class_val_seq.shape=}\")\n",
    "print(df_class_train_seq[10000:10005])\n",
    "\n",
    "# df_class_train_norm=sm.prepare_sequences_df(df_in=df_class_train_norm,list_features=list_feat,sequence_length=sequence_length,str_new_col=col_sequence)\n",
    "# df_class_val_norm=sm.prepare_sequences_df(df_in=df_class_val_norm,list_features=list_feat,sequence_length=sequence_length,str_new_col=col_sequence)\n",
    "\n",
    "# df_x_train, col_y_train = sm.split_df_x_y(\n",
    "#     df_in=df_class_train_norm, list_features=list_feat, str_label=label, drop_na=True)\n",
    "\n",
    "# df_x_val, col_y_val = sm.split_df_x_y(\n",
    "#     df_in=df_class_val_norm, list_features=list_feat, str_label=label, drop_na=True)\n",
    "\n",
    "\n",
    "\n",
    "# x_train=df_x_train.values\n",
    "# y_train=col_y_train.values\n",
    "# x_val=df_x_val.values\n",
    "# y_val=col_y_val.values\n",
    "# x_train_lstm,y_train_lstm=sm.prepare_sequences(x_train,y_train,sequence_length)\n",
    "# x_val_lstm,y_val_lstm=sm.prepare_sequences(x_val,y_val,sequence_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO put this in a function ??\n",
    "gc.collect()\n",
    "def format_float(x):\n",
    "    return '{:.5f}'.format(x) if x is not None else None\n",
    "\n",
    "def array_to_string(x):\n",
    "    return np.array2string(x,separator='_') if x is not None else None\n",
    "\n",
    "\n",
    "vfunc = np.vectorize(format_float) \n",
    "\n",
    "df_class_train_seq2=df_class_train_seq.copy()\n",
    "df_class_val_seq2=df_class_val_seq.copy()\n",
    "\n",
    "df_class_train_seq2[col_sequence] = df_class_train_seq2[col_sequence].apply(vfunc)\n",
    "df_class_val_seq2[col_sequence] = df_class_val_seq2[col_sequence].apply(vfunc)\n",
    "\n",
    "df_class_train_seq2[col_sequence] = df_class_train_seq2[col_sequence].apply(array_to_string)\n",
    "df_class_val_seq2[col_sequence] = df_class_val_seq2[col_sequence].apply(array_to_string)\n",
    "\n",
    "df_class_train_seq2.round(5).to_csv(\n",
    "    PATH_DATA_DTS+dts_name+\"_TRAIN_seq_6\", sep=\",\", float_format='%.5f')\n",
    "df_class_val_seq2.round(5).to_csv(\n",
    "    PATH_DATA_DTS+dts_name+\"_VAL_seq_6\", sep=\",\", float_format='%.5f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "START HERE TO LOAD DATASETS WITH SEQUENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_class_train_csv.shape=(829695, 2)\n",
      "                      lab_perf_50d  \\\n",
      "TICKER OPEN_DATETIME                 \n",
      "AB.PA  2015-02-11                1   \n",
      "       2015-02-12                0   \n",
      "       2015-02-13                0   \n",
      "       2015-02-16                0   \n",
      "       2015-02-17                0   \n",
      "\n",
      "                                                               SEQUENCE  \n",
      "TICKER OPEN_DATETIME                                                     \n",
      "AB.PA  2015-02-11     [[-0.39987, -0.49388, -0.45321, 0.33119, 0.245...  \n",
      "       2015-02-12     [[-0.40479, -0.49565, -0.45233, 0.33764, 0.256...  \n",
      "       2015-02-13     [[-0.39282, -0.4837, -0.43821, 0.39571, 0.2664...  \n",
      "       2015-02-16     [[-0.35487, -0.4481, -0.40128, 0.51362, 0.2836...  \n",
      "       2015-02-17     [[-0.35342, -0.4441, -0.39371, 0.5362, 0.29874...  \n",
      "df_class_val_csv.shape=(229327, 2)\n",
      "                       lab_perf_50d  \\\n",
      "TICKER  OPEN_DATETIME                 \n",
      "ABCA.PA 2017-09-21              3.0   \n",
      "        2017-09-22              3.0   \n",
      "        2017-09-25              3.0   \n",
      "        2017-09-26              3.0   \n",
      "        2017-09-27              3.0   \n",
      "\n",
      "                                                                SEQUENCE  \n",
      "TICKER  OPEN_DATETIME                                                     \n",
      "ABCA.PA 2017-09-21     [[-0.46348, -0.60691, -0.64682, -0.25331, -0.2...  \n",
      "        2017-09-22     [[-0.46059, -0.60448, -0.64507, -0.18567, -0.2...  \n",
      "        2017-09-25     [[-0.46006, -0.60384, -0.64462, -0.18567, -0.2...  \n",
      "        2017-09-26     [[-0.46187, -0.60494, -0.64553, -0.23363, -0.2...  \n",
      "        2017-09-27     [[-0.4624, -0.60526, -0.6458, -0.25719, -0.239...  \n",
      "                      lab_perf_50d  \\\n",
      "TICKER OPEN_DATETIME                 \n",
      "AB.PA  2015-02-11              0.0   \n",
      "       2015-02-12              1.0   \n",
      "       2015-02-13              0.0   \n",
      "       2015-02-16              0.0   \n",
      "       2015-02-17              0.0   \n",
      "\n",
      "                                                               SEQUENCE  \n",
      "TICKER OPEN_DATETIME                                                     \n",
      "AB.PA  2015-02-11     [[-0.39987, -0.49388, -0.45321, 0.33119, 0.245...  \n",
      "       2015-02-12     [[-0.40479, -0.49565, -0.45233, 0.33764, 0.256...  \n",
      "       2015-02-13     [[-0.39282, -0.4837, -0.43821, 0.39571, 0.2664...  \n",
      "       2015-02-16     [[-0.35487, -0.4481, -0.40128, 0.51362, 0.2836...  \n",
      "       2015-02-17     [[-0.35342, -0.4441, -0.39371, 0.5362, 0.29874...  \n",
      "                       lab_perf_50d  \\\n",
      "TICKER  OPEN_DATETIME                 \n",
      "ABCA.PA 2017-09-22              3.0   \n",
      "        2017-09-25              3.0   \n",
      "        2017-09-26              3.0   \n",
      "        2017-09-27              3.0   \n",
      "        2017-09-28              3.0   \n",
      "\n",
      "                                                                SEQUENCE  \n",
      "TICKER  OPEN_DATETIME                                                     \n",
      "ABCA.PA 2017-09-22     [[-0.46059, -0.60448, -0.64507, -0.18567, -0.2...  \n",
      "        2017-09-25     [[-0.46006, -0.60384, -0.64462, -0.18567, -0.2...  \n",
      "        2017-09-26     [[-0.46187, -0.60494, -0.64553, -0.23363, -0.2...  \n",
      "        2017-09-27     [[-0.4624, -0.60526, -0.6458, -0.25719, -0.239...  \n",
      "        2017-09-28     [[-0.46188, -0.6047, -0.64538, -0.25719, -0.24...  \n"
     ]
    }
   ],
   "source": [
    "dts_name=\"PARIS_TREND_1D_50D_V2\"\n",
    "multi_symbol=\"PARIS_STOCK\"\n",
    "label = \"lab_perf_50d\"\n",
    "file_name=dts_name+\"_train_colab_lstm_norm_2405\"\n",
    "col_sequence = \"SEQUENCE\"\n",
    "df_class_train_csv=pd.read_csv(PATH_DATA_DTS+dts_name+\"_TRAIN_seq_6.zip\",sep=\",\",index_col=[\"TICKER\",\"OPEN_DATETIME\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "df_class_train_csv=df_class_train_csv.dropna(subset=[col_sequence])\n",
    "df_class_train_csv=df_class_train_csv.sort_index()\n",
    "df_class_val_csv=pd.read_csv(PATH_DATA_DTS+dts_name+\"_VAL_seq_6.zip\",sep=\",\",index_col=[\"TICKER\",\"OPEN_DATETIME\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "df_class_val_csv=df_class_val_csv.dropna(subset=[col_sequence])\n",
    "df_class_val_csv=df_class_val_csv.sort_index()\n",
    "gc.collect()\n",
    "# keep only index, label and sequence\n",
    "df_class_train_csv=df_class_train_csv[[label,col_sequence]]\n",
    "df_class_val_csv=df_class_val_csv[[label,col_sequence]]\n",
    "\n",
    "df_class_train_csv[col_sequence] = df_class_train_csv[col_sequence].str.replace(\"_\", \",\").apply(ast.literal_eval)\n",
    "df_class_train_csv[col_sequence]  = df_class_train_csv[col_sequence] .apply(lambda x: np.array(x, dtype=np.float32))\n",
    "\n",
    "df_class_val_csv[col_sequence] = df_class_val_csv[col_sequence].str.replace(\"_\", \",\").apply(ast.literal_eval)\n",
    "df_class_val_csv[col_sequence]  = df_class_val_csv[col_sequence] .apply(lambda x: np.array(x, dtype=np.float32))\n",
    "\n",
    "\n",
    "print(f\"{df_class_train_csv.shape=}\")\n",
    "print(df_class_train_csv[1015:1020])\n",
    "print(f\"{df_class_val_csv.shape=}\")\n",
    "print(df_class_val_csv[1015:1020])\n",
    "\n",
    "# decision is made between market sessions so we have shift the label of 1 day for each ticker\n",
    "df_class_train_csv[label] = df_class_train_csv.groupby(level='TICKER')[label].shift(1)\n",
    "df_class_train_csv=df_class_train_csv.dropna(subset=[label])\n",
    "df_class_val_csv[label] = df_class_val_csv.groupby(level='TICKER')[label].shift(1)\n",
    "df_class_val_csv=df_class_val_csv.dropna(subset=[label])\n",
    "print(df_class_train_csv[1014:1019])\n",
    "print(df_class_val_csv[1014:1019])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_train_csv.to_pickle(PATH_DATA_DTS+dts_name+\"_TRAIN_seq_6.pckl\")\n",
    "df_class_val_csv.to_pickle(PATH_DATA_DTS+dts_name+\"_VAL_seq_6.pckl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "START HERE TO DIRECTLY LOAD THE PICKLE FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts_name=\"PARIS_TREND_1D_20D_V2\"\n",
    "multi_symbol=\"PARIS_STOCK\"\n",
    "label = \"lab_perf_20d\"\n",
    "file_name=dts_name+\"_train_colab_lstm_norm_2405\"\n",
    "col_sequence = \"SEQUENCE\"\n",
    "\n",
    "df_class_train_csv=pd.read_pickle(PATH_DATA_DTS+dts_name+\"_TRAIN_seq_6.pckl\")  #the train will be split in train + val\n",
    "df_class_test_csv=pd.read_pickle(PATH_DATA_DTS+dts_name+\"_VAL_seq_6.pckl\") #the val is finally used as a test dataset\n",
    "print(df_class_train_csv[1014:1019])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_class_train_csv split into train and val with 0.75/0.25 by open datetime using sm.split_df_by_label_strat\n",
    "df_class_train_csv.reset_index(level='TICKER',inplace=True)\n",
    "\n",
    "df_split=sm.split_df_by_label_strat(\n",
    "    df_in=df_class_train_csv, list_label=[label], split_timeframe=\"D\",random_split=False,split_strat=(80,20,0))\n",
    "df_train_split=df_split['df_'+label+'_train']\n",
    "df_val_split=df_split['df_'+label+'_valid']\n",
    "\n",
    "df_train_split.set_index('TICKER',append=True,inplace=True)\n",
    "df_val_split.set_index('TICKER',append=True,inplace=True)\n",
    "df_train_split.sort_index(inplace=True)\n",
    "df_val_split.sort_index(inplace=True)\n",
    "print(df_train_split[1014:1019])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"{df_class_train_csv.shape=} {df_class_val_csv.shape=}\")\n",
    "print(df_train_split[label].value_counts().sort_index()) # undersampling at 109200\n",
    "print(df_val_split[label].value_counts().sort_index()) # undersampling at 43900\n",
    "print(df_class_test_csv[label].value_counts().sort_index()) # undersampling at 41500\n",
    "\n",
    "nb_val=30000 #109200\n",
    "df_class_train_under=balance.class_custom_undersampler(df_train_split,label,nb_val) # undersampling todo\n",
    "\n",
    "nb_val=5000 #41500\n",
    "df_class_val_under=balance.class_custom_undersampler(df_val_split,label,nb_val)\n",
    "df_class_test_under=balance.class_custom_undersampler(df_class_test_csv,label,nb_val)\n",
    "\n",
    "print(df_class_train_under[label].value_counts().sort_index()) \n",
    "print(df_class_val_under[label].value_counts().sort_index()) \n",
    "print(df_class_test_under[label].value_counts().sort_index()) \n",
    "\n",
    "\n",
    "x_train_tensor = torch.as_tensor(df_class_train_under[col_sequence], dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(df_class_train_under[label], dtype=torch.int64)\n",
    "\n",
    "# x_val_tensor = torch.tensor(df_class_val_under['col_sequence_3'], dtype=torch.float)\n",
    "x_val_tensor = torch.as_tensor(df_class_val_under[col_sequence], dtype=torch.float)\n",
    "y_val_tensor = torch.tensor(df_class_val_under[label], dtype=torch.int64)\n",
    "\n",
    "x_test_tensor = torch.as_tensor(df_class_test_under[col_sequence], dtype=torch.float)\n",
    "y_test_tensor = torch.tensor(df_class_test_under[label], dtype=torch.int64)\n",
    "\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "# initiate a pytorch randomsampler for train data\n",
    "# train_sampler = RandomSampler(train_dataset,num_samples=100000,replacement=True)\n",
    "\n",
    "batch_size=512\n",
    "num_workers=7\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False,drop_last=True,num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,drop_last=True,num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size,drop_last=True,num_workers=num_workers)\n",
    " \n",
    "print(f\"{train_loader.dataset.tensors[0].shape=} {val_loader.dataset.tensors[0].shape=} {test_loader.dataset.tensors[0].shape=}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{train_loader.dataset.tensors[0].shape=} {val_loader.dataset.tensors[0].shape=} {test_loader.dataset.tensors[0].shape=}\")\n",
    "#print next(iter(train_loader))\n",
    "pprint(next(iter(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation (Copy from the Tensorflow notebook), not tested here !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_train = df_x_train.corr()\n",
    "plt.clf()\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "corr_train.replace(1,0,inplace=True)\n",
    "corr_train=corr_train.applymap(lambda x : None if x< 0.7 and x>-0.7 else x)\n",
    "corr_train.dropna(axis=0,how='all',inplace=True)\n",
    "corr_train.dropna(axis=1,how='all',inplace=True)\n",
    "\n",
    "# corr_train_check=corr_train[corr_train >0.8]\n",
    "corr_train_check=corr_train\n",
    "sns.heatmap(corr_train_check, annot=False, cmap='coolwarm', vmin=-1, vmax=1, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df_class, x='pos_sma200', y='pos_top50', hue='lab_perf_20d', palette='Set1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "###### REFACTO USING PYTORCH LIGHTNING ########\n",
    "###############################################\n",
    "\n",
    "# Define LSTM model\n",
    "class DynamicLSTMModel(pl.LightningModule):\n",
    "    def __init__(self, layer_configs, lr, criterion):\n",
    "        super(DynamicLSTMModel, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        for config in layer_configs:\n",
    "            # print(f\"{config=}\")\n",
    "            if config['type'] == 'LSTM':\n",
    "                layer = nn.LSTM(input_size=config['input_dim'], hidden_size=config['hidden_dim'], num_layers=config['num_layers'],\n",
    "                                batch_first=True, dropout=config['dropout'], bidirectional=config['bidirectional'])\n",
    "            elif config['type'] == 'Linear':\n",
    "                layer = nn.Linear(config['input_dim'], config['output_dim'])\n",
    "            elif config['type'] == 'Softmax':\n",
    "                layer = nn.Softmax(dim=config['dim'])\n",
    "            elif config['type'] == 'ReLU':\n",
    "                layer = nn.ReLU()\n",
    "            elif config['type'] == 'Sigmoid':\n",
    "                layer = nn.Sigmoid()\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported layer type: {config['type']}\")\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        self.lr = lr\n",
    "        self.criterion = criterion\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, nn.LSTM):\n",
    "                # LSTM layers require special handling for initial states\n",
    "                batch_size = x.size(0)\n",
    "                hidden_dim = layer.hidden_size\n",
    "                num_layers = layer.num_layers * 2 if layer.bidirectional else layer.num_layers\n",
    "                h0 = torch.zeros(num_layers, batch_size,\n",
    "                                 hidden_dim).to(x.device)\n",
    "                c0 = torch.zeros(num_layers, batch_size,\n",
    "                                 hidden_dim).to(x.device)\n",
    "                x, _ = layer(x, (h0, c0))\n",
    "                x = x[:, -1, :]\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        _, predicted = torch.max(y_hat.data, 1)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        correct = (predicted == y).sum().item()\n",
    "        total = len(y)\n",
    "        self.log(\"train_loss\", loss, on_step=True,\n",
    "                 on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"train_acc\", correct/total, on_step=True,\n",
    "                 on_epoch=True, prog_bar=True, logger=True)\n",
    "        output = {\"loss\": loss, \"train_loss\": loss,\n",
    "                  \"train_correct\": correct, \"train_total\": total}\n",
    "        return output\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        _, predicted = torch.max(y_hat.data, 1)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        correct = (predicted == y).sum().item()\n",
    "        total = len(y)\n",
    "        # output=f\"val_loss: {loss}, val_correct: {correct}, val_total: {y.size(0)}\"\n",
    "        output = {\"loss\": loss, \"val_loss\": loss,\n",
    "                  \"val_correct\": correct, \"val_total\": total}\n",
    "        # self.log(output)\n",
    "        self.log(\"val_loss\", loss, on_step=True,\n",
    "                 on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc\", correct/total, on_step=True,\n",
    "                 on_epoch=True, prog_bar=True, logger=True)\n",
    "        return output\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        _, predicted = torch.max(y_hat.data, 1)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        correct = (predicted == y).sum().item()\n",
    "        total = len(y)\n",
    "        # output=f\"val_loss: {loss}, val_correct: {correct}, val_total: {y.size(0)}\"\n",
    "        output = {\"loss\": loss, \"test_loss\": loss, \"test_correct\": correct,\n",
    "                  \"test_total\": total, \"test_acc\": correct/total}\n",
    "        # self.log(output)\n",
    "        self.log(\"test_loss\", loss, on_step=True,\n",
    "                 on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"test_acc\", correct/total, on_step=True,\n",
    "                 on_epoch=True, prog_bar=True, logger=True)\n",
    "        return output\n",
    "\n",
    "    # def test_epoch_end(self, outputs):\n",
    "    #     avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "    #     self.log('test_loss_epoch', avg_loss)\n",
    "\n",
    "    # def on_validation_epoch_end(self, outputs):\n",
    "    #     avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "    #     total_correct = sum(x['val_correct'] for x in outputs)\n",
    "    #     total = sum(x['val_total'] for x in outputs)\n",
    "    #     tensorboard_logs = {'val_loss': avg_loss}\n",
    "    #     return {'val_loss': avg_loss, 'progress_bar': tensorboard_logs, 'val_acc': total_correct / total}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "\n",
    "input_dim = x_train_tensor.shape[2]\n",
    "num_classes = 5\n",
    "epochs = 10  # 350\n",
    "suffix = \"lstm_pytorch_v1\"\n",
    "tb_directory = \"tb_logs\"\n",
    "debug = False\n",
    "patience = 5\n",
    "\n",
    "obj_acc = 0.25\n",
    "cpt_param = 0\n",
    "try_limit = 3\n",
    "pct_check_class = 0.3  # check if at least n% of the validation set per class\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "len_val = x_val_tensor.shape[0]\n",
    "check_class_limit = (len_val/num_classes)*pct_check_class\n",
    "check_class = False  # check if at least obj_acc accuracy per class\n",
    "\n",
    "list_param_valid = [\n",
    "    {'layer_configs': [\n",
    "        {'type': 'Linear', 'input_dim': input_dim, 'output_dim': input_dim},\n",
    "        {'type': 'LSTM', 'input_dim': input_dim, 'hidden_dim': 64,         'num_layers': 1, 'dropout': 0.0, 'bidirectional': True},\n",
    "        # Note: LSTM bidirectional output is doubled\n",
    "        {'type': 'Linear', 'input_dim': 64 * 2, 'output_dim': num_classes},\n",
    "        {'type': 'Softmax', 'dim': 1}\n",
    "    ], 'optimizer__lr': 0.01},\n",
    "    {'layer_configs': [\n",
    "        {'type': 'Linear', 'input_dim': input_dim, 'output_dim': input_dim},\n",
    "        {'type': 'LSTM', 'input_dim': input_dim, 'hidden_dim': 32,\n",
    "         'num_layers': 2, 'dropout': 0.2, 'bidirectional': False},\n",
    "        # Note: LSTM bidirectional output is doubled\n",
    "        {'type': 'Linear', 'input_dim': 32, 'output_dim': num_classes},\n",
    "        {'type': 'Softmax', 'dim': 1}\n",
    "    ], 'optimizer__lr': 0.01},\n",
    "    # {'fit__batch_size': 256, 'model__dropout': 0.05, 'model__layers': [64, 10], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.9},\n",
    "    # {'fit__batch_size': 32, 'fit__epochs': 350, 'model__dropout': 0.05, 'model__layers': [128, 20], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.7},\n",
    "    # {'fit__batch_size': 32, 'fit__epochs': 350, 'model__dropout': 0.05, 'model__layers': [128, 20], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.5},\n",
    "    # {'fit__batch_size': 64, 'fit__epochs': 350, 'model__dropout': 0.05, 'model__layers': [128, 20], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.9},\n",
    "    # {'fit__batch_size': 64, 'fit__epochs': 350, 'model__dropout': 0.05, 'model__layers': [128, 20], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.7},\n",
    "    # {'fit__batch_size': 64, 'fit__epochs': 350, 'model__dropout': 0.05, 'model__layers': [128, 20], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.5},\n",
    "]\n",
    "\n",
    "while (cpt_param < len(list_param_valid) and check_class == False):  # loop for parameters\n",
    "    gc.collect()\n",
    "    param_valid = list_param_valid[cpt_param]  # select the current param line\n",
    "    print(f\"{param_valid=}\")\n",
    "    cpt = 0\n",
    "    filename_tmp_model = dts_name+\"_\"+suffix+\".pckl\"\n",
    "\n",
    "    while (cpt < try_limit and check_class == False):  # loop for train models until good results\n",
    "        cpt += 1\n",
    "\n",
    "        model = DynamicLSTMModel(layer_configs=param_valid['layer_configs'], lr=param_valid['optimizer__lr'], criterion=criterion)\n",
    "\n",
    "        if cpt == 1 and debug:\n",
    "            print(model)\n",
    "            print(len(list(model.parameters())))\n",
    "            for i in range(len(list(model.parameters()))):\n",
    "                print(list(model.parameters())[i].size())\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=PATH_DATA+\"\\\\Models\\\\\",  # Specify the directory to save the model\n",
    "            # Specify the filename format\n",
    "            filename=f\"{dts_name}_{suffix}_{datetime.now().strftime('%Y%m%d')}_{cpt_param}_{cpt}\",\n",
    "            save_top_k=1,  # Save only the top k models according to the monitored quantity\n",
    "            verbose=True,\n",
    "            monitor='val_loss',  # Specify the metric to monitor\n",
    "            mode='min',  # Mode can be either 'min', 'max', or 'auto'\n",
    "            save_last=False  # Optionally, you can choose to save the last model\n",
    "        )\n",
    "\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\", min_delta=0.001, patience=patience, verbose=True, mode=\"min\")\n",
    "        logger = TensorBoardLogger(tb_directory, name=\"my_model\")\n",
    "        trainer = pl.Trainer(max_epochs=epochs, callbacks=[\n",
    "                             early_stop_callback, checkpoint_callback], logger=logger)\n",
    "\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "        writer = SummaryWriter(log_dir=tb_directory+\"/model_summary\")\n",
    "        model_summary = str(model).replace(\n",
    "            '\\n', '<br/>').replace(' ', '&nbsp;')\n",
    "        writer.add_text(\"model_v\"+str(logger.version), model_summary)\n",
    "        writer.close()\n",
    "\n",
    "        # trainer.test(dataloaders=test_loader)\n",
    "        print(f\"{checkpoint_callback.best_model_path=}\")\n",
    "        best_model = DynamicLSTMModel.load_from_checkpoint(\n",
    "            checkpoint_callback.best_model_path)\n",
    "        result = trainer.test(best_model, dataloaders=test_loader)\n",
    "        # print(f\"{result[0]=}\")\n",
    "        # print(\n",
    "        #     f\"Optim {cpt=} {checkpoint_callback.best_model_path=} {result[0]['test_acc_epoch']=}\")\n",
    "\n",
    "        if result[0]['test_acc_epoch'] > obj_acc:\n",
    "            # calculate the confusion matrix\n",
    "            y_pred = best_model(x_val_tensor)\n",
    "            _, y_pred_classes = torch.max(y_pred, 1)\n",
    "            confusion = metrics.confusion_matrix(y_val_tensor, y_pred_classes)\n",
    "\n",
    "            print(confusion)\n",
    "\n",
    "            check_class = True\n",
    "\n",
    "            for i in range(num_classes):\n",
    "                nb_lab = sum(y_pred_classes == i)\n",
    "                if nb_lab < check_class_limit:\n",
    "                    check_class = False\n",
    "                    print(\n",
    "                        f\"Check class {i=} {nb_lab=} {check_class=} {check_class_limit=}\")\n",
    "\n",
    "            # check saved model, load to check it's OK\n",
    "            if check_class:\n",
    "                torch.save(model, filename_tmp_model)\n",
    "                saved_model = torch.load(filename_tmp_model)\n",
    "                saved_model.eval()\n",
    "                y_pred = saved_model(x_val_tensor)\n",
    "                _, y_pred_classes = torch.max(y_pred, 1)\n",
    "                confusion = metrics.confusion_matrix(\n",
    "                    y_val_tensor, y_pred_classes)\n",
    "                print(confusion)\n",
    "\n",
    "    if cpt >= try_limit:\n",
    "        cpt_param += 1\n",
    "        print(f\"Optim fail {cpt=} param suivant {cpt_param=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir tb_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "###### SAVE CODE FOR BASIC PYTORCH #####\n",
    "###### BEFORE PYTORCH LIGHTNING ########\n",
    "\n",
    "list_param_valid = [\n",
    "                    {'model__dropout': 0.05, 'model__hidden_dim': 16, 'model__num_layers': 2, 'optimizer__lr': 0.1},\n",
    "                    # {'fit__batch_size': 256, 'model__dropout': 0.05, 'model__layers': [64, 10], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.9},\n",
    "                    # {'fit__batch_size': 32, 'fit__epochs': 350, 'model__dropout': 0.05, 'model__layers': [128, 20], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.7},\n",
    "                    # {'fit__batch_size': 32, 'fit__epochs': 350, 'model__dropout': 0.05, 'model__layers': [128, 20], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.5},\n",
    "                    # {'fit__batch_size': 64, 'fit__epochs': 350, 'model__dropout': 0.05, 'model__layers': [128, 20], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.9},\n",
    "                    # {'fit__batch_size': 64, 'fit__epochs': 350, 'model__dropout': 0.05, 'model__layers': [128, 20], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.7},\n",
    "                    # {'fit__batch_size': 64, 'fit__epochs': 350, 'model__dropout': 0.05, 'model__layers': [128, 20], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.5},\n",
    "]\n",
    "\n",
    "# Define LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes, dropout):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "input_dim = x_train_tensor.shape[2]\n",
    "num_classes = 5\n",
    "epochs = 6#350\n",
    "suffix=\"lstm_pytorch_v1\"\n",
    "filename_tmp_model = dts_name+\"_\"+suffix+\".pckl\"\n",
    "patience = 3\n",
    "\n",
    "val_accuracy=0.0\n",
    "obj_acc=0.25\n",
    "cpt_param=0 \n",
    "try_limit=5\n",
    "pct_check_class=0.4 # check if at least n% of the validation set per class\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "len_val=x_val_tensor.shape[0]\n",
    "check_class_limit=(len_val/num_classes)*pct_check_class\n",
    "check_class=False # check if at least obj_acc accuracy per class\n",
    "\n",
    "while(cpt_param<len(list_param_valid) and check_class==False):\n",
    "    param_valid=list_param_valid[cpt_param] #select the current param line\n",
    "    print(param_valid)\n",
    "    cpt=0\n",
    "\n",
    "    while(cpt<try_limit and check_class==False):\n",
    "        cpt+=1\n",
    "        \n",
    "        model = LSTMModel(input_dim=input_dim, hidden_dim=param_valid['model__hidden_dim'], num_layers=param_valid['model__num_layers'], num_classes=num_classes, dropout=param_valid['model__dropout'])\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = Adam(model.parameters(), lr=param_valid['optimizer__lr'])\n",
    "\n",
    "        if cpt==1:\n",
    "            print(model)\n",
    "            print(len(list(model.parameters())))\n",
    "            for i in range(len(list(model.parameters()))):\n",
    "                print(list(model.parameters())[i].size())\n",
    "\n",
    "        # Training loop\n",
    "        hist = np.zeros(epochs)\n",
    "        for epoch in range(epochs):\n",
    "            for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(x_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            if epoch % 1 == 0 :   #change % \n",
    "                print(f\"Epoch {epoch+1} CrossEntropyLoss: {loss.item()}\")\n",
    "            hist[epoch] = loss.item()\n",
    "\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for x_batch, y_batch in val_loader:\n",
    "                outputs = model(x_batch)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += y_batch.size(0)\n",
    "                correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "        val_accuracy = correct / total\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}, Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "        if val_accuracy>obj_acc:\n",
    "            print(f\"Optim success {cpt=} {val_accuracy=}\")\n",
    "            check_class=True #exit directly\n",
    "\n",
    "            # calculate the confusion matrix\n",
    "            y_pred = model(x_val_tensor)\n",
    "            _, y_pred_classes = torch.max(y_pred, 1)\n",
    "            confusion = metrics.confusion_matrix(y_val_tensor, y_pred_classes)\n",
    "            print(confusion)\n",
    "\n",
    "            for i in range(num_classes):\n",
    "                nb_lab=sum(y_pred_classes == i)\n",
    "                if nb_lab<check_class_limit  :\n",
    "                    check_class=False\n",
    "                    print(f\"Check class {i=} {nb_lab=} {check_class=} {check_class_limit=}\")\n",
    "                # print(f\"Categ {i}: real {sum(y_val_tensor == i)} predict {sum(y_pred_classes == i)}\")\n",
    "\n",
    "\n",
    "            #check saved model, load to check it's OK\n",
    "            if check_class:\n",
    "                torch.save(model, filename_tmp_model)\n",
    "                saved_model = torch.load(filename_tmp_model)\n",
    "                saved_model.eval()\n",
    "                y_pred = saved_model(x_val_tensor)\n",
    "                _, y_pred_classes = torch.max(y_pred, 1)\n",
    "                confusion = metrics.confusion_matrix(y_val_tensor, y_pred_classes)\n",
    "                print(confusion)\n",
    "\n",
    "    if cpt>=try_limit :\n",
    "        cpt_param+=1\n",
    "        print(f\"Optim fail {cpt=} param suivant {cpt_param=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist, label=\"Training loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_train.shape[-1]\n",
    "window_size = sequence_length\n",
    "dropout = 0.2\n",
    "num_classes = 4\n",
    "\n",
    "# cat_y_train = keras.utils.to_categorical(col_y_train, num_classes)\n",
    "# cat_y_valid = keras.utils.to_categorical(col_y_valid, num_classes)\n",
    "\n",
    "# df_x_train_exp = np.expand_dims(df_x_train, axis=2)\n",
    "# df_x_valid_exp = np.expand_dims(df_x_valid, axis=2)\n",
    "\n",
    "\n",
    "model_LSTM = Sequential()\n",
    "model_LSTM.add(LSTM(units=20, return_sequences=False,#True\n",
    "               input_shape=(window_size, input_dim)))\n",
    "#,kernel_regularizer=l2(0.1), recurrent_regularizer=l2(0.1), bias_regularizer=l2(0.1)\n",
    "model_LSTM.add(Dropout(rate=dropout))   \n",
    "# model_LSTM.add(Dropout(rate=dropout))\n",
    "# model_LSTM.add(Bidirectional(LSTM((window_size * 2), return_sequences=True)))\n",
    "# model_LSTM.add(Dropout(rate=dropout))\n",
    "# model_LSTM.add(Bidirectional(LSTM(window_size, return_sequences=False)))\n",
    "model_LSTM.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "model_LSTM.compile(loss='categorical_crossentropy',\n",
    "                   optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model_LSTM.fit(x_train_lstm, y_train_lstm, batch_size=1024,\n",
    "                         shuffle=False, epochs=20, validation_data=(x_val_lstm, y_val_lstm))#,verbose=0\n",
    "\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Plot loss\n",
    "epochs = range(1, len(train_accuracy) + 1)\n",
    "plt.plot(epochs, train_accuracy, 'bo-', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'ro-', label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print if keras can use the gpu to train the model\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
