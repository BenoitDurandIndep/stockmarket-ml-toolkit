{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_get_column_indices' from 'sklearn.utils' (c:\\Projets\\MarketDataEnrichment\\.env\\lib\\site-packages\\sklearn\\utils\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01madd_indicators\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mindic\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msplit_merge\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbalance\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmodel_mngr\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmodmgr\u001b[39;00m\n\u001b[0;32m     28\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(sio)\n",
      "File \u001b[1;32mC:\\Projets\\MarketDataEnrichment\\dataset_mngr\\balance.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PowerTransformer, StandardScaler, MinMaxScaler\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munder_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomUnderSampler, TomekLinks, NearMiss\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler, SMOTE\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_transform_label\u001b[39m(df_in: pd\u001b[38;5;241m.\u001b[39mDataFrame, str_label: \u001b[38;5;28mstr\u001b[39m, fl_fix: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-6\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n",
      "File \u001b[1;32mc:\\Projets\\MarketDataEnrichment\\.env\\lib\\site-packages\\imblearn\\__init__.py:52\u001b[0m\n\u001b[0;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     53\u001b[0m         combine,\n\u001b[0;32m     54\u001b[0m         ensemble,\n\u001b[0;32m     55\u001b[0m         exceptions,\n\u001b[0;32m     56\u001b[0m         metrics,\n\u001b[0;32m     57\u001b[0m         over_sampling,\n\u001b[0;32m     58\u001b[0m         pipeline,\n\u001b[0;32m     59\u001b[0m         tensorflow,\n\u001b[0;32m     60\u001b[0m         under_sampling,\n\u001b[0;32m     61\u001b[0m         utils,\n\u001b[0;32m     62\u001b[0m     )\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[1;32mc:\\Projets\\MarketDataEnrichment\\.env\\lib\\site-packages\\imblearn\\combine\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Projets\\MarketDataEnrichment\\.env\\lib\\site-packages\\imblearn\\combine\\_smote_enn.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munder_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EditedNearestNeighbours\n",
      "File \u001b[1;32mc:\\Projets\\MarketDataEnrichment\\.env\\lib\\site-packages\\imblearn\\over_sampling\\__init__.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_adasyn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ADASYN\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_random_over_sampler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE, SMOTEN, SMOTENC, SVMSMOTE, BorderlineSMOTE, KMeansSMOTE\n\u001b[0;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADASYN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomOverSampler\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Projets\\MarketDataEnrichment\\.env\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE, SMOTEN, SMOTENC\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeansSMOTE\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVMSMOTE, BorderlineSMOTE\n",
      "File \u001b[1;32mc:\\Projets\\MarketDataEnrichment\\.env\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder, OrdinalEncoder\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     _get_column_indices,\n\u001b[0;32m     20\u001b[0m     _safe_indexing,\n\u001b[0;32m     21\u001b[0m     check_array,\n\u001b[0;32m     22\u001b[0m     check_random_state,\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparsefuncs_fast\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     25\u001b[0m     csr_mean_variance_axis0,\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _num_features\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_get_column_indices' from 'sklearn.utils' (c:\\Projets\\MarketDataEnrichment\\.env\\lib\\site-packages\\sklearn\\utils\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Bidirectional, Dropout, Activation, Dense, LSTM\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier as scikit_KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier as scikeras_KerasClassifier\n",
    "# from imblearn.under_sampling import RandomUnderSampler # wait for new release https://github.com/scikit-learn-contrib/imbalanced-learn/issues/1081\n",
    "\n",
    "import sqlite_io as sio\n",
    "import add_indicators as indic\n",
    "import split_merge as sm\n",
    "# import balance  # wait for new release https://github.com/scikit-learn-contrib/imbalanced-learn/issues/1081\n",
    "import model_mngr as modmgr\n",
    "\n",
    "importlib.reload(sio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = \"C:\\\\Projets\\\\Data\"\n",
    "PATH_DB_FWK=\"C:\\\\Projets\\\\Data\\\\sqlite\\\\dataset_market.db\"\n",
    "PATH_DB_STOCK=\"C:\\\\Projets\\\\Data\\\\sqlite\\\\dataset_paris_stock_adjusted.db\"\n",
    "PATH_DATA_DTS=PATH_DATA+\"\\\\DTS_FULL\\\\\"\n",
    "\n",
    "SUFFIX_TRAIN=\"_TRAIN.zip\"\n",
    "SUFFIX_VAL=\"_VAL.zip\"\n",
    "SUFFIX_CONF=\"_CONF.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONNECTION TO SQLITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"con_stock\" in locals():\n",
    "        sio.close_connection(con_stock)\n",
    "con_stock = sio.get_connection(str_db_path=PATH_DB_STOCK)\n",
    "\n",
    "if \"con_fwk\" in locals():\n",
    "        sio.close_connection(con_fwk)\n",
    "con_fwk = sio.get_connection(str_db_path=PATH_DB_FWK)\n",
    "\n",
    "my_session_maker = sessionmaker(bind=con_fwk)\n",
    "session=my_session_maker()\n",
    "\n",
    "table_stock=\"DS_PARIS_1D_ADJ_CLEAN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: SELECT CODE,OPEN_DATETIME, OPEN,HIGH,LOW,CLOSE,VOLUME FROM DS_PARIS_1D_ADJ_CLEAN can \n",
      "    WHERE can.TIMEFRAME=1440 AND can.SK_SYMBOL IN (SELECT SK_SYMBOL FROM SYMBOL WHERE TRADABLE=1)      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:1: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "<string>:1: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "<string>:1: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "<string>:1: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "<string>:1: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "<string>:1: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "<string>:1: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "<string>:1: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 1409355 entries, ('AB.PA', '2010-04-26') to ('XIL.PA', '2024-01-15')\n",
      "Data columns (total 68 columns):\n",
      " #   Column             Non-Null Count    Dtype  \n",
      "---  ------             --------------    -----  \n",
      " 0   OPEN               1403182 non-null  float64\n",
      " 1   HIGH               1403182 non-null  float64\n",
      " 2   LOW                1403182 non-null  float64\n",
      " 3   CLOSE              1403182 non-null  float64\n",
      " 4   VOLUME             1403182 non-null  float64\n",
      " 5   sma20              1397520 non-null  float64\n",
      " 6   pos_sma20          1397520 non-null  float64\n",
      " 7   sma50              1403182 non-null  float64\n",
      " 8   sma200             1343880 non-null  float64\n",
      " 9   pos_sma50          1403182 non-null  float64\n",
      " 10  pos_sma200         1343880 non-null  float64\n",
      " 11  pos_sma50_200      1343880 non-null  float64\n",
      " 12  pos_sma20_50       1397520 non-null  float64\n",
      " 13  rsi14              1405468 non-null  float64\n",
      " 14  sma5_rsi14         1404272 non-null  float64\n",
      " 15  sma20_rsi14        1399787 non-null  float64\n",
      " 16  bb20_hi            1397520 non-null  float64\n",
      " 17  bb20_lo            1397520 non-null  float64\n",
      " 18  pos_bb20_hi        1397520 non-null  float64\n",
      " 19  pos_bb20_lo        1397520 non-null  float64\n",
      " 20  ret_1d             1402884 non-null  float64\n",
      " 21  ret_5d             1401692 non-null  float64\n",
      " 22  top20              1397520 non-null  float64\n",
      " 23  top50              1388580 non-null  float64\n",
      " 24  bot20              1397520 non-null  float64\n",
      " 25  bot50              1388580 non-null  float64\n",
      " 26  pos_top20          1397520 non-null  float64\n",
      " 27  pos_top50          1388580 non-null  float64\n",
      " 28  pos_bot20          1397520 non-null  float64\n",
      " 29  pos_bot50          1388580 non-null  float64\n",
      " 30  top200             1343880 non-null  float64\n",
      " 31  bot200             1343880 non-null  float64\n",
      " 32  aroon14_up         1399010 non-null  float64\n",
      " 33  aroon14_down       1399010 non-null  float64\n",
      " 34  aroon14_dif        1399010 non-null  float64\n",
      " 35  macd_dif           1393348 non-null  float64\n",
      " 36  pos_top_200        1343880 non-null  float64\n",
      " 37  pos_bot_200        1343880 non-null  float64\n",
      " 38  stdev20            1397520 non-null  float64\n",
      " 39  stdev20_1d         1392394 non-null  float64\n",
      " 40  stdev20_sma5       1396328 non-null  float64\n",
      " 41  pos_stdev20_sma5   1392263 non-null  float64\n",
      " 42  stdev20_sma20      1391858 non-null  float64\n",
      " 43  pos_stdev20_sma20  1389761 non-null  float64\n",
      " 44  pos_rsi14_sma5     1404272 non-null  float64\n",
      " 45  pos_rsi14_sma20    1399787 non-null  float64\n",
      " 46  pos_rsi14_sma5_20  1399787 non-null  float64\n",
      " 47  lab_perf_125d      1365932 non-null  float64\n",
      " 48  lab_perf_20d       1397222 non-null  float64\n",
      " 49  lab_perf_50d       1388282 non-null  float64\n",
      " 50  stoch14            1391797 non-null  float64\n",
      " 51  stoch14_signal     1390101 non-null  float64\n",
      " 52  stoch14_dif        1390101 non-null  float64\n",
      " 53  cmf_20             1388467 non-null  float64\n",
      " 54  donchian20_hi      1397520 non-null  float64\n",
      " 55  donchian20_lo      1397520 non-null  float64\n",
      " 56  pos_donchian20_hi  1397520 non-null  float64\n",
      " 57  pos_donchian20_lo  1397520 non-null  float64\n",
      " 58  adx14              1403209 non-null  float64\n",
      " 59  adx14_neg          1403197 non-null  float64\n",
      " 60  adx14_pos          1403197 non-null  float64\n",
      " 61  adx14_dif          1403197 non-null  float64\n",
      " 62  avg_vol14          1397520 non-null  float64\n",
      " 63  pos_avg_vol14      1388467 non-null  float64\n",
      " 64  pos_sma20_200      1343880 non-null  float64\n",
      " 65  williamsr_14       1391797 non-null  float64\n",
      " 66  perf_sma_50_5d     1401692 non-null  float64\n",
      " 67  perf_sma_200_5d    1342390 non-null  float64\n",
      "dtypes: float64(68)\n",
      "memory usage: 736.9+ MB\n"
     ]
    }
   ],
   "source": [
    "dts_name=\"PARIS_TREND_1D_20D_V2\"\n",
    "multi_symbol=\"PARIS_STOCK\"\n",
    "\n",
    "df_base=sio.get_candles_to_df(session=session,con=con_stock, target_table=table_stock,tradable=True)\n",
    "df_work=pd.DataFrame()\n",
    "for code_value in df_base.index.get_level_values('CODE').unique():\n",
    "    sub_df=df_base[df_base.index.get_level_values('CODE') == code_value]\n",
    "    df_work_tmp = indic.add_indicators_to_df(con=con_fwk, df_in=sub_df, dts_name=dts_name,symbol=multi_symbol)\n",
    "    df_work = pd.concat([df_work, df_work_tmp])\n",
    "    \n",
    "df_work.sort_index(inplace=True)\n",
    "df_work.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_work[10000:10010]\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# print(df_work.describe())\n",
    "\n",
    "df_work.round(5).to_csv(\n",
    "    PATH_DATA_DTS+dts_name+\"_BASE.zip\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>sma20</th>\n",
       "      <th>pos_sma20</th>\n",
       "      <th>sma50</th>\n",
       "      <th>sma200</th>\n",
       "      <th>pos_sma50</th>\n",
       "      <th>...</th>\n",
       "      <th>adx14</th>\n",
       "      <th>adx14_neg</th>\n",
       "      <th>adx14_pos</th>\n",
       "      <th>adx14_dif</th>\n",
       "      <th>avg_vol14</th>\n",
       "      <th>pos_avg_vol14</th>\n",
       "      <th>pos_sma20_200</th>\n",
       "      <th>williamsr_14</th>\n",
       "      <th>perf_sma_50_5d</th>\n",
       "      <th>perf_sma_200_5d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPEN_DATETIME</th>\n",
       "      <th>CODE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-04-26</th>\n",
       "      <th>AB.PA</th>\n",
       "      <td>12.98</td>\n",
       "      <td>12.98</td>\n",
       "      <td>12.20</td>\n",
       "      <td>12.68</td>\n",
       "      <td>62866.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.68000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-27</th>\n",
       "      <th>AB.PA</th>\n",
       "      <td>12.74</td>\n",
       "      <td>12.83</td>\n",
       "      <td>12.61</td>\n",
       "      <td>12.70</td>\n",
       "      <td>22370.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.69000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-28</th>\n",
       "      <th>AB.PA</th>\n",
       "      <td>12.70</td>\n",
       "      <td>12.70</td>\n",
       "      <td>12.41</td>\n",
       "      <td>12.50</td>\n",
       "      <td>8211.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.62667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.01003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-29</th>\n",
       "      <th>AB.PA</th>\n",
       "      <td>12.60</td>\n",
       "      <td>12.65</td>\n",
       "      <td>12.46</td>\n",
       "      <td>12.64</td>\n",
       "      <td>4676.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.63000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <th>AB.PA</th>\n",
       "      <td>12.63</td>\n",
       "      <td>12.71</td>\n",
       "      <td>12.55</td>\n",
       "      <td>12.65</td>\n",
       "      <td>4470.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.63400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      OPEN   HIGH    LOW  CLOSE   VOLUME  sma20  pos_sma20  \\\n",
       "OPEN_DATETIME CODE                                                           \n",
       "2010-04-26    AB.PA  12.98  12.98  12.20  12.68  62866.0    NaN        NaN   \n",
       "2010-04-27    AB.PA  12.74  12.83  12.61  12.70  22370.0    NaN        NaN   \n",
       "2010-04-28    AB.PA  12.70  12.70  12.41  12.50   8211.0    NaN        NaN   \n",
       "2010-04-29    AB.PA  12.60  12.65  12.46  12.64   4676.0    NaN        NaN   \n",
       "2010-04-30    AB.PA  12.63  12.71  12.55  12.65   4470.0    NaN        NaN   \n",
       "\n",
       "                        sma50  sma200  pos_sma50  ...  adx14  adx14_neg  \\\n",
       "OPEN_DATETIME CODE                                ...                     \n",
       "2010-04-26    AB.PA  12.68000     NaN    0.00000  ...    0.0        0.0   \n",
       "2010-04-27    AB.PA  12.69000     NaN    0.00079  ...    0.0        0.0   \n",
       "2010-04-28    AB.PA  12.62667     NaN   -0.01003  ...    0.0        0.0   \n",
       "2010-04-29    AB.PA  12.63000     NaN    0.00079  ...    0.0        0.0   \n",
       "2010-04-30    AB.PA  12.63400     NaN    0.00127  ...    0.0        0.0   \n",
       "\n",
       "                     adx14_pos  adx14_dif  avg_vol14  pos_avg_vol14  \\\n",
       "OPEN_DATETIME CODE                                                    \n",
       "2010-04-26    AB.PA        0.0        0.0        NaN            NaN   \n",
       "2010-04-27    AB.PA        0.0        0.0        NaN            NaN   \n",
       "2010-04-28    AB.PA        0.0        0.0        NaN            NaN   \n",
       "2010-04-29    AB.PA        0.0        0.0        NaN            NaN   \n",
       "2010-04-30    AB.PA        0.0        0.0        NaN            NaN   \n",
       "\n",
       "                     pos_sma20_200  williamsr_14  perf_sma_50_5d  \\\n",
       "OPEN_DATETIME CODE                                                 \n",
       "2010-04-26    AB.PA            NaN           NaN             NaN   \n",
       "2010-04-27    AB.PA            NaN           NaN             NaN   \n",
       "2010-04-28    AB.PA            NaN           NaN             NaN   \n",
       "2010-04-29    AB.PA            NaN           NaN             NaN   \n",
       "2010-04-30    AB.PA            NaN           NaN             NaN   \n",
       "\n",
       "                     perf_sma_200_5d  \n",
       "OPEN_DATETIME CODE                    \n",
       "2010-04-26    AB.PA              NaN  \n",
       "2010-04-27    AB.PA              NaN  \n",
       "2010-04-28    AB.PA              NaN  \n",
       "2010-04-29    AB.PA              NaN  \n",
       "2010-04-30    AB.PA              NaN  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dts_name=\"PARIS_TREND_1D_20D_V2\"\n",
    "# dts_name=\"PARIS_TREND_1D_50D_V1\"\n",
    "multi_symbol=\"PARIS_STOCK\"\n",
    "\n",
    "df_work=pd.read_csv(PATH_DATA_DTS+dts_name+\"_BASE.zip\",sep=\",\",index_col=[\"OPEN_DATETIME\",\"CODE\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "df_work.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with no pos_sma200 \n",
    "df_work=df_work.dropna(subset=['pos_sma200'])\n",
    "\n",
    "# if williamsr_14 >0 =0 if williamsr_14<-100 = -100\n",
    "# df_work['williamsr_14']=df_work['williamsr_14'].apply(lambda x: 0 if x>0 else x)\n",
    "# df_work['williamsr_14']=df_work['williamsr_14'].apply(lambda x: -100 if x<-100 else x)\n",
    "\n",
    "# if williamsr_14 >0 =0 if williamsr_14<-100 = -100\n",
    "df_work.loc[df_work['williamsr_14'] > 0, 'williamsr_14'] = 0\n",
    "df_work.loc[df_work['williamsr_14'] < -100, 'williamsr_14'] = -100\n",
    "\n",
    "# print min and max of the columns williamsr_14, perf_sma_50_5d, perf_sma_200_5d\n",
    "# print(f\"{df_work['williamsr_14'].min()=}\")  inf-100\n",
    "# print(f\"{df_work['williamsr_14'].max()=}\") sup 0\n",
    "\n",
    "# df_check=df_work[df_work['perf_sma_50_5d'] > 1]\n",
    "# df_check=df_check[df_check['ret_1d'] <= 2]\n",
    "# print(df_check.index.get_level_values('CODE').unique())\n",
    "# df_check[df_check.index.get_level_values('CODE')=='AI.PA']\n",
    "# df_check.head(5)\n",
    "# df_check=df_work[df_work.index.get_level_values('CODE')=='AI.PA']\n",
    "# CATG\n",
    "# mask = df_work['stdev20_1d'] > 1000\n",
    "# df_work.drop(df_work[mask].index, inplace=True)\n",
    "# df_check[6000:6010]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>sma20</th>\n",
       "      <th>pos_sma20</th>\n",
       "      <th>sma50</th>\n",
       "      <th>sma200</th>\n",
       "      <th>pos_sma50</th>\n",
       "      <th>...</th>\n",
       "      <th>adx14</th>\n",
       "      <th>adx14_neg</th>\n",
       "      <th>adx14_pos</th>\n",
       "      <th>adx14_dif</th>\n",
       "      <th>avg_vol14</th>\n",
       "      <th>pos_avg_vol14</th>\n",
       "      <th>pos_sma20_200</th>\n",
       "      <th>williamsr_14</th>\n",
       "      <th>perf_sma_50_5d</th>\n",
       "      <th>perf_sma_200_5d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPEN_DATETIME</th>\n",
       "      <th>CODE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-02</th>\n",
       "      <th>ABEO.PA</th>\n",
       "      <td>7.6136</td>\n",
       "      <td>7.9789</td>\n",
       "      <td>7.6136</td>\n",
       "      <td>7.9789</td>\n",
       "      <td>6332.0</td>\n",
       "      <td>7.31078</td>\n",
       "      <td>0.09139</td>\n",
       "      <td>8.27304</td>\n",
       "      <td>17.04669</td>\n",
       "      <td>-0.03555</td>\n",
       "      <td>...</td>\n",
       "      <td>26.15567</td>\n",
       "      <td>22.77986</td>\n",
       "      <td>24.12433</td>\n",
       "      <td>1.34447</td>\n",
       "      <td>6752.40</td>\n",
       "      <td>0.93774</td>\n",
       "      <td>-0.57113</td>\n",
       "      <td>-31.81630</td>\n",
       "      <td>-0.03229</td>\n",
       "      <td>-0.02455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-03</th>\n",
       "      <th>ABEO.PA</th>\n",
       "      <td>8.1711</td>\n",
       "      <td>8.6710</td>\n",
       "      <td>8.1519</td>\n",
       "      <td>8.4595</td>\n",
       "      <td>8982.0</td>\n",
       "      <td>7.39729</td>\n",
       "      <td>0.14359</td>\n",
       "      <td>8.21825</td>\n",
       "      <td>16.96353</td>\n",
       "      <td>0.02936</td>\n",
       "      <td>...</td>\n",
       "      <td>25.89215</td>\n",
       "      <td>20.36515</td>\n",
       "      <td>32.16729</td>\n",
       "      <td>11.80214</td>\n",
       "      <td>5972.80</td>\n",
       "      <td>1.50382</td>\n",
       "      <td>-0.56393</td>\n",
       "      <td>-11.45907</td>\n",
       "      <td>-0.03301</td>\n",
       "      <td>-0.02453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-04</th>\n",
       "      <th>ABEO.PA</th>\n",
       "      <td>8.5557</td>\n",
       "      <td>8.5557</td>\n",
       "      <td>7.7866</td>\n",
       "      <td>8.4019</td>\n",
       "      <td>7735.0</td>\n",
       "      <td>7.48285</td>\n",
       "      <td>0.12282</td>\n",
       "      <td>8.18441</td>\n",
       "      <td>16.87961</td>\n",
       "      <td>0.02657</td>\n",
       "      <td>...</td>\n",
       "      <td>24.74737</td>\n",
       "      <td>23.41954</td>\n",
       "      <td>28.54604</td>\n",
       "      <td>5.12651</td>\n",
       "      <td>5537.15</td>\n",
       "      <td>1.39693</td>\n",
       "      <td>-0.55669</td>\n",
       "      <td>-16.46677</td>\n",
       "      <td>-0.03314</td>\n",
       "      <td>-0.02459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-05</th>\n",
       "      <th>ABEO.PA</th>\n",
       "      <td>8.4211</td>\n",
       "      <td>8.7864</td>\n",
       "      <td>8.2480</td>\n",
       "      <td>8.5749</td>\n",
       "      <td>6423.0</td>\n",
       "      <td>7.57514</td>\n",
       "      <td>0.13198</td>\n",
       "      <td>8.15596</td>\n",
       "      <td>16.79463</td>\n",
       "      <td>0.05137</td>\n",
       "      <td>...</td>\n",
       "      <td>24.10544</td>\n",
       "      <td>21.58743</td>\n",
       "      <td>29.66498</td>\n",
       "      <td>8.07755</td>\n",
       "      <td>5570.60</td>\n",
       "      <td>1.15302</td>\n",
       "      <td>-0.54895</td>\n",
       "      <td>-12.08848</td>\n",
       "      <td>-0.03011</td>\n",
       "      <td>-0.02463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-08</th>\n",
       "      <th>ABEO.PA</th>\n",
       "      <td>8.7672</td>\n",
       "      <td>9.0363</td>\n",
       "      <td>8.5941</td>\n",
       "      <td>8.7479</td>\n",
       "      <td>19545.0</td>\n",
       "      <td>7.65877</td>\n",
       "      <td>0.14221</td>\n",
       "      <td>8.12712</td>\n",
       "      <td>16.71052</td>\n",
       "      <td>0.07638</td>\n",
       "      <td>...</td>\n",
       "      <td>23.93590</td>\n",
       "      <td>20.13379</td>\n",
       "      <td>31.31449</td>\n",
       "      <td>11.18069</td>\n",
       "      <td>6324.85</td>\n",
       "      <td>3.09019</td>\n",
       "      <td>-0.54168</td>\n",
       "      <td>-14.42361</td>\n",
       "      <td>-0.02444</td>\n",
       "      <td>-0.02464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-09</th>\n",
       "      <th>ABEO.PA</th>\n",
       "      <td>8.7479</td>\n",
       "      <td>9.0363</td>\n",
       "      <td>8.3826</td>\n",
       "      <td>8.8056</td>\n",
       "      <td>8807.0</td>\n",
       "      <td>7.73568</td>\n",
       "      <td>0.13831</td>\n",
       "      <td>8.10039</td>\n",
       "      <td>16.62717</td>\n",
       "      <td>0.08706</td>\n",
       "      <td>...</td>\n",
       "      <td>23.25077</td>\n",
       "      <td>21.27235</td>\n",
       "      <td>28.39698</td>\n",
       "      <td>7.12462</td>\n",
       "      <td>6409.80</td>\n",
       "      <td>1.37399</td>\n",
       "      <td>-0.53476</td>\n",
       "      <td>-11.53788</td>\n",
       "      <td>-0.02087</td>\n",
       "      <td>-0.02461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-10</th>\n",
       "      <th>ABEO.PA</th>\n",
       "      <td>9.0363</td>\n",
       "      <td>9.0363</td>\n",
       "      <td>8.2673</td>\n",
       "      <td>8.6518</td>\n",
       "      <td>6484.0</td>\n",
       "      <td>7.81738</td>\n",
       "      <td>0.10674</td>\n",
       "      <td>8.09462</td>\n",
       "      <td>16.54402</td>\n",
       "      <td>0.06883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.33359</td>\n",
       "      <td>20.60949</td>\n",
       "      <td>25.39907</td>\n",
       "      <td>4.78959</td>\n",
       "      <td>6102.05</td>\n",
       "      <td>1.06259</td>\n",
       "      <td>-0.52748</td>\n",
       "      <td>-19.22981</td>\n",
       "      <td>-0.01504</td>\n",
       "      <td>-0.02473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-11</th>\n",
       "      <th>ABEO.PA</th>\n",
       "      <td>8.5557</td>\n",
       "      <td>8.5557</td>\n",
       "      <td>8.0173</td>\n",
       "      <td>8.1711</td>\n",
       "      <td>5301.0</td>\n",
       "      <td>7.88372</td>\n",
       "      <td>0.03645</td>\n",
       "      <td>8.07194</td>\n",
       "      <td>16.45990</td>\n",
       "      <td>0.01229</td>\n",
       "      <td>...</td>\n",
       "      <td>20.89547</td>\n",
       "      <td>22.22109</td>\n",
       "      <td>23.22080</td>\n",
       "      <td>0.99971</td>\n",
       "      <td>6320.40</td>\n",
       "      <td>0.83871</td>\n",
       "      <td>-0.52104</td>\n",
       "      <td>-50.00289</td>\n",
       "      <td>-0.01374</td>\n",
       "      <td>-0.02486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-12</th>\n",
       "      <th>ABEO.PA</th>\n",
       "      <td>7.9981</td>\n",
       "      <td>8.0750</td>\n",
       "      <td>7.5175</td>\n",
       "      <td>7.6328</td>\n",
       "      <td>11060.0</td>\n",
       "      <td>7.91351</td>\n",
       "      <td>-0.03547</td>\n",
       "      <td>8.04233</td>\n",
       "      <td>16.37550</td>\n",
       "      <td>-0.05092</td>\n",
       "      <td>...</td>\n",
       "      <td>20.25323</td>\n",
       "      <td>26.93381</td>\n",
       "      <td>21.20351</td>\n",
       "      <td>-5.73030</td>\n",
       "      <td>6756.90</td>\n",
       "      <td>1.63685</td>\n",
       "      <td>-0.51675</td>\n",
       "      <td>-81.11310</td>\n",
       "      <td>-0.01393</td>\n",
       "      <td>-0.02496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-15</th>\n",
       "      <th>ABEO.PA</th>\n",
       "      <td>7.9789</td>\n",
       "      <td>7.9789</td>\n",
       "      <td>7.5944</td>\n",
       "      <td>7.5944</td>\n",
       "      <td>5996.0</td>\n",
       "      <td>7.92409</td>\n",
       "      <td>-0.04161</td>\n",
       "      <td>8.01618</td>\n",
       "      <td>16.29523</td>\n",
       "      <td>-0.05262</td>\n",
       "      <td>...</td>\n",
       "      <td>19.65686</td>\n",
       "      <td>25.52877</td>\n",
       "      <td>20.09740</td>\n",
       "      <td>-5.43137</td>\n",
       "      <td>6837.20</td>\n",
       "      <td>0.87697</td>\n",
       "      <td>-0.51372</td>\n",
       "      <td>-91.46210</td>\n",
       "      <td>-0.01365</td>\n",
       "      <td>-0.02485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         OPEN    HIGH     LOW   CLOSE   VOLUME    sma20  \\\n",
       "OPEN_DATETIME CODE                                                        \n",
       "2020-06-02    ABEO.PA  7.6136  7.9789  7.6136  7.9789   6332.0  7.31078   \n",
       "2020-06-03    ABEO.PA  8.1711  8.6710  8.1519  8.4595   8982.0  7.39729   \n",
       "2020-06-04    ABEO.PA  8.5557  8.5557  7.7866  8.4019   7735.0  7.48285   \n",
       "2020-06-05    ABEO.PA  8.4211  8.7864  8.2480  8.5749   6423.0  7.57514   \n",
       "2020-06-08    ABEO.PA  8.7672  9.0363  8.5941  8.7479  19545.0  7.65877   \n",
       "2020-06-09    ABEO.PA  8.7479  9.0363  8.3826  8.8056   8807.0  7.73568   \n",
       "2020-06-10    ABEO.PA  9.0363  9.0363  8.2673  8.6518   6484.0  7.81738   \n",
       "2020-06-11    ABEO.PA  8.5557  8.5557  8.0173  8.1711   5301.0  7.88372   \n",
       "2020-06-12    ABEO.PA  7.9981  8.0750  7.5175  7.6328  11060.0  7.91351   \n",
       "2020-06-15    ABEO.PA  7.9789  7.9789  7.5944  7.5944   5996.0  7.92409   \n",
       "\n",
       "                       pos_sma20    sma50    sma200  pos_sma50  ...     adx14  \\\n",
       "OPEN_DATETIME CODE                                              ...             \n",
       "2020-06-02    ABEO.PA    0.09139  8.27304  17.04669   -0.03555  ...  26.15567   \n",
       "2020-06-03    ABEO.PA    0.14359  8.21825  16.96353    0.02936  ...  25.89215   \n",
       "2020-06-04    ABEO.PA    0.12282  8.18441  16.87961    0.02657  ...  24.74737   \n",
       "2020-06-05    ABEO.PA    0.13198  8.15596  16.79463    0.05137  ...  24.10544   \n",
       "2020-06-08    ABEO.PA    0.14221  8.12712  16.71052    0.07638  ...  23.93590   \n",
       "2020-06-09    ABEO.PA    0.13831  8.10039  16.62717    0.08706  ...  23.25077   \n",
       "2020-06-10    ABEO.PA    0.10674  8.09462  16.54402    0.06883  ...  22.33359   \n",
       "2020-06-11    ABEO.PA    0.03645  8.07194  16.45990    0.01229  ...  20.89547   \n",
       "2020-06-12    ABEO.PA   -0.03547  8.04233  16.37550   -0.05092  ...  20.25323   \n",
       "2020-06-15    ABEO.PA   -0.04161  8.01618  16.29523   -0.05262  ...  19.65686   \n",
       "\n",
       "                       adx14_neg  adx14_pos  adx14_dif  avg_vol14  \\\n",
       "OPEN_DATETIME CODE                                                  \n",
       "2020-06-02    ABEO.PA   22.77986   24.12433    1.34447    6752.40   \n",
       "2020-06-03    ABEO.PA   20.36515   32.16729   11.80214    5972.80   \n",
       "2020-06-04    ABEO.PA   23.41954   28.54604    5.12651    5537.15   \n",
       "2020-06-05    ABEO.PA   21.58743   29.66498    8.07755    5570.60   \n",
       "2020-06-08    ABEO.PA   20.13379   31.31449   11.18069    6324.85   \n",
       "2020-06-09    ABEO.PA   21.27235   28.39698    7.12462    6409.80   \n",
       "2020-06-10    ABEO.PA   20.60949   25.39907    4.78959    6102.05   \n",
       "2020-06-11    ABEO.PA   22.22109   23.22080    0.99971    6320.40   \n",
       "2020-06-12    ABEO.PA   26.93381   21.20351   -5.73030    6756.90   \n",
       "2020-06-15    ABEO.PA   25.52877   20.09740   -5.43137    6837.20   \n",
       "\n",
       "                       pos_avg_vol14  pos_sma20_200  williamsr_14  \\\n",
       "OPEN_DATETIME CODE                                                  \n",
       "2020-06-02    ABEO.PA        0.93774       -0.57113     -31.81630   \n",
       "2020-06-03    ABEO.PA        1.50382       -0.56393     -11.45907   \n",
       "2020-06-04    ABEO.PA        1.39693       -0.55669     -16.46677   \n",
       "2020-06-05    ABEO.PA        1.15302       -0.54895     -12.08848   \n",
       "2020-06-08    ABEO.PA        3.09019       -0.54168     -14.42361   \n",
       "2020-06-09    ABEO.PA        1.37399       -0.53476     -11.53788   \n",
       "2020-06-10    ABEO.PA        1.06259       -0.52748     -19.22981   \n",
       "2020-06-11    ABEO.PA        0.83871       -0.52104     -50.00289   \n",
       "2020-06-12    ABEO.PA        1.63685       -0.51675     -81.11310   \n",
       "2020-06-15    ABEO.PA        0.87697       -0.51372     -91.46210   \n",
       "\n",
       "                       perf_sma_50_5d  perf_sma_200_5d  \n",
       "OPEN_DATETIME CODE                                      \n",
       "2020-06-02    ABEO.PA        -0.03229         -0.02455  \n",
       "2020-06-03    ABEO.PA        -0.03301         -0.02453  \n",
       "2020-06-04    ABEO.PA        -0.03314         -0.02459  \n",
       "2020-06-05    ABEO.PA        -0.03011         -0.02463  \n",
       "2020-06-08    ABEO.PA        -0.02444         -0.02464  \n",
       "2020-06-09    ABEO.PA        -0.02087         -0.02461  \n",
       "2020-06-10    ABEO.PA        -0.01504         -0.02473  \n",
       "2020-06-11    ABEO.PA        -0.01374         -0.02486  \n",
       "2020-06-12    ABEO.PA        -0.01393         -0.02496  \n",
       "2020-06-15    ABEO.PA        -0.01365         -0.02485  \n",
       "\n",
       "[10 rows x 68 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_work[10000:10010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           LABEL\n",
      "0   lab_perf_20d\n",
      "1   lab_perf_50d\n",
      "2  lab_perf_125d\n"
     ]
    }
   ],
   "source": [
    "df_work = indic.drop_indicators_by_type(\n",
    "    con=con_fwk, df_in=df_work, dts_name=dts_name, symbol=multi_symbol, ind_type=0)\n",
    "list_label = indic.get_ind_list_by_type_for_dts(\n",
    "    con=con_fwk, dts_name=dts_name, symbol_code=multi_symbol, ind_type=2)\n",
    "print(list_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>pos_sma20</th>\n",
       "      <th>pos_sma50</th>\n",
       "      <th>pos_sma200</th>\n",
       "      <th>pos_sma50_200</th>\n",
       "      <th>pos_sma20_50</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_donchian20_lo</th>\n",
       "      <th>adx14</th>\n",
       "      <th>adx14_neg</th>\n",
       "      <th>adx14_pos</th>\n",
       "      <th>adx14_dif</th>\n",
       "      <th>pos_avg_vol14</th>\n",
       "      <th>pos_sma20_200</th>\n",
       "      <th>williamsr_14</th>\n",
       "      <th>perf_sma_50_5d</th>\n",
       "      <th>perf_sma_200_5d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPEN_DATETIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1989-10-20</th>\n",
       "      <td>2.1507</td>\n",
       "      <td>2.1913</td>\n",
       "      <td>2.1406</td>\n",
       "      <td>2.1507</td>\n",
       "      <td>209645.0</td>\n",
       "      <td>-0.04857</td>\n",
       "      <td>-0.07186</td>\n",
       "      <td>0.02924</td>\n",
       "      <td>0.10893</td>\n",
       "      <td>-0.02448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00853</td>\n",
       "      <td>21.40482</td>\n",
       "      <td>44.89673</td>\n",
       "      <td>17.73996</td>\n",
       "      <td>-27.15677</td>\n",
       "      <td>0.27907</td>\n",
       "      <td>0.08178</td>\n",
       "      <td>-92.52260</td>\n",
       "      <td>-0.01153</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-10-23</th>\n",
       "      <td>2.1467</td>\n",
       "      <td>2.1649</td>\n",
       "      <td>2.1325</td>\n",
       "      <td>2.1467</td>\n",
       "      <td>1342573.0</td>\n",
       "      <td>-0.04748</td>\n",
       "      <td>-0.07069</td>\n",
       "      <td>0.02695</td>\n",
       "      <td>0.10507</td>\n",
       "      <td>-0.02437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00666</td>\n",
       "      <td>23.06701</td>\n",
       "      <td>43.77485</td>\n",
       "      <td>16.73968</td>\n",
       "      <td>-27.03516</td>\n",
       "      <td>1.68277</td>\n",
       "      <td>0.07814</td>\n",
       "      <td>-94.16598</td>\n",
       "      <td>-0.01256</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-10-24</th>\n",
       "      <td>2.0919</td>\n",
       "      <td>2.1568</td>\n",
       "      <td>2.0716</td>\n",
       "      <td>2.0919</td>\n",
       "      <td>1785758.0</td>\n",
       "      <td>-0.06722</td>\n",
       "      <td>-0.09114</td>\n",
       "      <td>0.00051</td>\n",
       "      <td>0.10084</td>\n",
       "      <td>-0.02565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00980</td>\n",
       "      <td>25.23754</td>\n",
       "      <td>47.58947</td>\n",
       "      <td>14.43476</td>\n",
       "      <td>-33.15471</td>\n",
       "      <td>2.13044</td>\n",
       "      <td>0.07260</td>\n",
       "      <td>-93.32895</td>\n",
       "      <td>-0.01421</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-10-25</th>\n",
       "      <td>2.0817</td>\n",
       "      <td>2.0959</td>\n",
       "      <td>2.0716</td>\n",
       "      <td>2.0817</td>\n",
       "      <td>1091222.0</td>\n",
       "      <td>-0.06742</td>\n",
       "      <td>-0.09234</td>\n",
       "      <td>-0.00458</td>\n",
       "      <td>0.09669</td>\n",
       "      <td>-0.02672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00488</td>\n",
       "      <td>27.25303</td>\n",
       "      <td>45.65847</td>\n",
       "      <td>13.84906</td>\n",
       "      <td>-31.80942</td>\n",
       "      <td>1.27752</td>\n",
       "      <td>0.06739</td>\n",
       "      <td>-96.68091</td>\n",
       "      <td>-0.01586</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-10-26</th>\n",
       "      <td>2.0899</td>\n",
       "      <td>2.1101</td>\n",
       "      <td>2.0899</td>\n",
       "      <td>2.0899</td>\n",
       "      <td>581543.0</td>\n",
       "      <td>-0.06020</td>\n",
       "      <td>-0.08556</td>\n",
       "      <td>-0.00100</td>\n",
       "      <td>0.09247</td>\n",
       "      <td>-0.02699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00883</td>\n",
       "      <td>28.67357</td>\n",
       "      <td>43.43999</td>\n",
       "      <td>15.60559</td>\n",
       "      <td>-27.83440</td>\n",
       "      <td>0.70232</td>\n",
       "      <td>0.06299</td>\n",
       "      <td>-93.98620</td>\n",
       "      <td>-0.01674</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 OPEN    HIGH     LOW   CLOSE     VOLUME  pos_sma20  \\\n",
       "OPEN_DATETIME                                                         \n",
       "1989-10-20     2.1507  2.1913  2.1406  2.1507   209645.0   -0.04857   \n",
       "1989-10-23     2.1467  2.1649  2.1325  2.1467  1342573.0   -0.04748   \n",
       "1989-10-24     2.0919  2.1568  2.0716  2.0919  1785758.0   -0.06722   \n",
       "1989-10-25     2.0817  2.0959  2.0716  2.0817  1091222.0   -0.06742   \n",
       "1989-10-26     2.0899  2.1101  2.0899  2.0899   581543.0   -0.06020   \n",
       "\n",
       "               pos_sma50  pos_sma200  pos_sma50_200  pos_sma20_50  ...  \\\n",
       "OPEN_DATETIME                                                      ...   \n",
       "1989-10-20      -0.07186     0.02924        0.10893      -0.02448  ...   \n",
       "1989-10-23      -0.07069     0.02695        0.10507      -0.02437  ...   \n",
       "1989-10-24      -0.09114     0.00051        0.10084      -0.02565  ...   \n",
       "1989-10-25      -0.09234    -0.00458        0.09669      -0.02672  ...   \n",
       "1989-10-26      -0.08556    -0.00100        0.09247      -0.02699  ...   \n",
       "\n",
       "               pos_donchian20_lo     adx14  adx14_neg  adx14_pos  adx14_dif  \\\n",
       "OPEN_DATETIME                                                                 \n",
       "1989-10-20               0.00853  21.40482   44.89673   17.73996  -27.15677   \n",
       "1989-10-23               0.00666  23.06701   43.77485   16.73968  -27.03516   \n",
       "1989-10-24               0.00980  25.23754   47.58947   14.43476  -33.15471   \n",
       "1989-10-25               0.00488  27.25303   45.65847   13.84906  -31.80942   \n",
       "1989-10-26               0.00883  28.67357   43.43999   15.60559  -27.83440   \n",
       "\n",
       "               pos_avg_vol14  pos_sma20_200  williamsr_14  perf_sma_50_5d  \\\n",
       "OPEN_DATETIME                                                               \n",
       "1989-10-20           0.27907        0.08178     -92.52260        -0.01153   \n",
       "1989-10-23           1.68277        0.07814     -94.16598        -0.01256   \n",
       "1989-10-24           2.13044        0.07260     -93.32895        -0.01421   \n",
       "1989-10-25           1.27752        0.06739     -96.68091        -0.01586   \n",
       "1989-10-26           0.70232        0.06299     -93.98620        -0.01674   \n",
       "\n",
       "               perf_sma_200_5d  \n",
       "OPEN_DATETIME                   \n",
       "1989-10-20                 NaN  \n",
       "1989-10-23                 NaN  \n",
       "1989-10-24                 NaN  \n",
       "1989-10-25                 NaN  \n",
       "1989-10-26                 NaN  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_work=df_work.droplevel('CODE')\n",
    "df_work.sort_index(inplace=True)\n",
    "df_work.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected: df_selected.shape=(844051, 28) valid: df_valid.shape=(233081, 28) confirm: df_confirm.shape=(247146, 28)\n"
     ]
    }
   ],
   "source": [
    "lab_studied = \"lab_perf_20d\"\n",
    "algo_studied = \"LSTM_CLASS\"\n",
    "dts_name=\"PARIS_TREND_1D_20D_V2\"\n",
    "\n",
    "df_work_lab = indic.drop_indicators_not_selected(con=con_fwk, df_in=df_work, dts_name=dts_name, symbol=multi_symbol,label=lab_studied,algo=algo_studied)\n",
    "# print(df_work_lab.head(5))\n",
    "\n",
    "df_split=sm.split_df_by_label_strat(\n",
    "    df_in=df_work_lab, list_label=[lab_studied], split_timeframe=\"M\",random_split=False,split_strat=(80,10,10))\n",
    "df_selected = df_split['df_'+lab_studied+'_train']\n",
    "df_valid = df_split['df_'+lab_studied+'_valid']\n",
    "df_confirm = df_split['df_'+lab_studied+'_confirm']\n",
    "df_selected.sort_index(inplace=True)\n",
    "df_valid.sort_index(inplace=True)\n",
    "df_confirm.sort_index(inplace=True)\n",
    "\n",
    "print(f\"selected: {df_selected.shape=} valid: {df_valid.shape=} confirm: {df_confirm.shape=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        min      max\n",
      "lab_perf_20d_class                  \n",
      "0                  -0.80165 -0.03860\n",
      "1                  -0.03859  0.00610\n",
      "2                   0.00611  0.05654\n",
      "3                   0.05655  3.82176\n"
     ]
    }
   ],
   "source": [
    "label=lab_studied\n",
    "df_class=balance.add_class_by_lab_nb_lines(df_in=df_selected,str_label=lab_studied,nb_class=4,bool_replace_label=False)\n",
    "min_max_lab_by_class = df_class.groupby(label+'_class')[label].agg(['min', 'max'])\n",
    "print(min_max_lab_by_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPEN_DATETIME\n",
      "1989-10-27    3\n",
      "2017-02-28    2\n",
      "Name: lab_perf_20d, dtype: int64\n",
      "OPEN_DATETIME\n",
      "2017-03-01    2.0\n",
      "2020-07-31    2.0\n",
      "Name: lab_perf_20d, dtype: float64\n",
      "OPEN_DATETIME\n",
      "2020-08-03    2.0\n",
      "2023-12-13    1.0\n",
      "Name: lab_perf_20d, dtype: float64\n",
      "lab_perf_20d\n",
      "0    211018\n",
      "1    211018\n",
      "2    211014\n",
      "3    211001\n",
      "Name: count, dtype: int64\n",
      "lab_perf_20d\n",
      "0.0    64761\n",
      "1.0    58466\n",
      "2.0    56807\n",
      "3.0    53038\n",
      "Name: count, dtype: int64\n",
      "lab_perf_20d\n",
      "0.0    73920\n",
      "1.0    56794\n",
      "2.0    55138\n",
      "3.0    61292\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label=lab_studied\n",
    "df_class=balance.add_class_by_lab_nb_lines(df_in=df_selected,str_label=lab_studied,nb_class=4,bool_replace_label=True)\n",
    "df_class.sort_index(inplace=True)\n",
    "# categ_50={0:[-1,-0.05456],1:[-0.07876,-0.00783],2:[-0.00783,0.04790],3:[0.04790,0.12406],4:[0.12406,6]}\n",
    "categ_20={0:[-1,-0.0386],1:[-0.0386,0.0061],2:[0.0061,0.05654],3:[0.05654,5]}\n",
    "df_class_val=balance.add_lab_by_class(df_in=df_valid,str_label=lab_studied, categ=categ_20,bool_replace_label=True) # categ\n",
    "df_class_val.sort_index(inplace=True)\n",
    "df_class_conf=balance.add_lab_by_class(df_in=df_confirm,str_label=lab_studied, categ=categ_20,bool_replace_label=True) # categ\n",
    "df_class_conf.sort_index(inplace=True)\n",
    "print(df_class.loc[:, label].dropna().iloc[[0, -1]])\n",
    "print(df_class_val.loc[:, label].dropna().iloc[[0, -1]])\n",
    "print(df_class_conf.loc[:, label].dropna().iloc[[0, -1]])\n",
    "# df_class_clean=df_class.drop(['OPEN','HIGH','LOW','CLOSE','VOLUME','lab_perf_125d','lab_perf_20d','lab_perf_50d'],axis=1)\n",
    "data = df_class[label]\n",
    "print(data.value_counts().sort_index())\n",
    "data_val = df_class_val[label]\n",
    "print(data_val.value_counts().sort_index())\n",
    "data_conf = df_class_conf[label]\n",
    "print(data_conf.value_counts().sort_index())\n",
    "# min_max_lab_by_class = df_class.groupby(label+'_class')[label].agg(['min', 'max'])\n",
    "# print(min_max_lab_by_class)\n",
    "\n",
    "# lab_perf_20d : train min nb rows 211000 validation 53000 confirm 55000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feat = df_class.columns.values.tolist()\n",
    "list_feat.remove(label)\n",
    "df_x_train, col_y_train = sm.split_df_x_y(\n",
    "    df_in=df_class, list_features=list_feat, str_label=label, drop_na=True)\n",
    "df_x_val, col_y_val = sm.split_df_x_y(\n",
    "    df_in=df_class_val, list_features=list_feat, str_label=label, drop_na=True)\n",
    "df_x_conf, col_y_conf = sm.split_df_x_y(\n",
    "    df_in=df_class_conf, list_features=list_feat, str_label=label, drop_na=True)\n",
    "\n",
    "df_class.round(5).to_csv(\n",
    "    PATH_DATA_DTS+dts_name+SUFFIX_TRAIN, sep=\",\")\n",
    "df_class_val.round(5).to_csv(\n",
    "    PATH_DATA_DTS+dts_name+SUFFIX_VAL, sep=\",\")\n",
    "df_class_conf.round(5).to_csv(\n",
    "    PATH_DATA_DTS+dts_name+SUFFIX_CONF, sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate and save scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Projets\\\\Data\\\\DTS_FULL\\\\PARIS_TREND_1D_20D_V2_train_colab_lstm_norm_2405_scaler.save']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dts_name=\"PARIS_TREND_1D_20D_V2\"\n",
    "multi_symbol=\"PARIS_STOCK\"\n",
    "label = \"lab_perf_20d\"\n",
    "\n",
    "df_class=pd.read_csv(PATH_DATA_DTS+dts_name+SUFFIX_TRAIN,sep=\",\",index_col=[\"OPEN_DATETIME\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "df_class=df_class.dropna(subset=[label])\n",
    "df_class=df_class.sort_index()\n",
    "\n",
    "df_norm,norm_scaler= balance.normalize_df(df_in=df_class,str_label=label,tuple_ft_range=(-1,1))\n",
    "\n",
    "file_name=dts_name+\"_train_colab_lstm_norm_2405\"\n",
    "scaler_name=file_name+\"_scaler.save\"\n",
    "joblib.dump(norm_scaler,filename=PATH_DATA_DTS+scaler_name)\n",
    "\n",
    "# df_class_val=pd.read_csv(PATH_DATA_DTS+dts_name+SUFFIX_VAL,sep=\",\",index_col=[\"OPEN_DATETIME\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "# df_class_val.dropna(subset=[label], inplace=True)\n",
    "# df_class_val.sort_index(inplace=True)\n",
    "\n",
    "# list_feat = df_class.columns.values.tolist()\n",
    "# list_feat.remove(label)\n",
    "# X, y = sm.split_df_x_y(\n",
    "#     df_in=df_class, list_features=list_feat, str_label=label, drop_na=True)\n",
    "# nb_val=211000\n",
    "# method = RandomUnderSampler(sampling_strategy={0:nb_val,1:nb_val,2:nb_val,3:nb_val}) \n",
    "# df_x_train, col_y_train=  method.fit_resample(X, y)\n",
    "# print(col_y_train.value_counts().sort_index())\n",
    "\n",
    "# X, y = sm.split_df_x_y(\n",
    "#     df_in=df_class_val, list_features=list_feat, str_label=label, drop_na=True)\n",
    "# nb_val=53000\n",
    "# method = RandomUnderSampler(sampling_strategy={0:nb_val,1:nb_val,2:nb_val,3:nb_val}) # 53000 pour lab 20 et nn pour lab 50\n",
    "# df_x_val, col_y_val=  method.fit_resample(X, y)\n",
    "# print(col_y_val.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train et val df, normalize,  undersample  and preparation for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts_name=\"PARIS_TREND_1D_20D_V2\"\n",
    "multi_symbol=\"PARIS_STOCK\"\n",
    "label = \"lab_perf_20d\"\n",
    "file_name=dts_name+\"_train_colab_lstm_norm_2405\"\n",
    "scaler_name=file_name+\"_scaler.save\"\n",
    "scaler=joblib.load(PATH_DATA_DTS+scaler_name)\n",
    "\n",
    "\n",
    "df_class=pd.read_csv(PATH_DATA_DTS+dts_name+SUFFIX_TRAIN,sep=\",\",index_col=[\"OPEN_DATETIME\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "df_class=df_class.dropna(subset=[label])\n",
    "df_class=df_class.loc['1995-01-01':] # drop rows < 1995-01-01\n",
    "df_class=df_class.sort_index()\n",
    "df_class_val=pd.read_csv(PATH_DATA_DTS+dts_name+SUFFIX_VAL,sep=\",\",index_col=[\"OPEN_DATETIME\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "df_class_val=df_class_val.dropna(subset=[label])\n",
    "df_class_val=df_class_val.sort_index()\n",
    "\n",
    "# normalize df_class and df_class_val\n",
    "df_class_train_norm=balance.normalize_df_scaler(df_in=df_class, str_label=label,scaler=scaler)\n",
    "df_class_val_norm=balance.normalize_df_scaler(df_in=df_class_val, str_label=label,scaler=scaler)\n",
    "\n",
    "list_feat = df_class.columns.values.tolist()\n",
    "list_feat.remove(label)\n",
    "X, y = sm.split_df_x_y(\n",
    "    df_in=df_class_train_norm, list_features=list_feat, str_label=label, drop_na=True)\n",
    "nb_val=20000#211000\n",
    "method = RandomUnderSampler(sampling_strategy={0:nb_val,1:nb_val,2:nb_val,3:nb_val}) \n",
    "df_x_train, col_y_train=  method.fit_resample(X, y)\n",
    "# print(col_y_train.value_counts().sort_index())\n",
    "\n",
    "X, y = sm.split_df_x_y(\n",
    "    df_in=df_class_val_norm, list_features=list_feat, str_label=label, drop_na=True)\n",
    "nb_val=5000#53000\n",
    "method = RandomUnderSampler(sampling_strategy={0:nb_val,1:nb_val,2:nb_val,3:nb_val}) # 53000 pour lab 20 et nn pour lab 50\n",
    "df_x_val, col_y_val=  method.fit_resample(X, y)\n",
    "# print(col_y_val.value_counts().sort_index())\n",
    "\n",
    "sequence_length = 10\n",
    "\n",
    "x_train=df_x_train.values\n",
    "y_train=col_y_train.values\n",
    "x_val=df_x_val.values\n",
    "y_val=col_y_val.values\n",
    "x_train_lstm,y_train_lstm=sm.prepare_sequences(x_train,y_train,sequence_length)\n",
    "x_val_lstm,y_val_lstm=sm.prepare_sequences(x_val,y_val,sequence_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_train = df_x_train.corr()\n",
    "plt.clf()\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "corr_train.replace(1,0,inplace=True)\n",
    "corr_train=corr_train.applymap(lambda x : None if x< 0.7 and x>-0.7 else x)\n",
    "corr_train.dropna(axis=0,how='all',inplace=True)\n",
    "corr_train.dropna(axis=1,how='all',inplace=True)\n",
    "\n",
    "# corr_train_check=corr_train[corr_train >0.8]\n",
    "corr_train_check=corr_train\n",
    "sns.heatmap(corr_train_check, annot=False, cmap='coolwarm', vmin=-1, vmax=1, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df_class, x='pos_sma200', y='pos_top50', hue='lab_perf_20d', palette='Set1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit__batch_size': 256, 'model__dropout': 0.05, 'model__layers': [64, 10], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.9}\n",
      "Epoch 1/20\n",
      "313/313 [==============================] - 49s 142ms/step - loss: 1.2540 - accuracy: 0.3728 - val_loss: 1.2378 - val_accuracy: 0.3751\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 53s 169ms/step - loss: 1.2095 - accuracy: 0.4015 - val_loss: 1.2202 - val_accuracy: 0.3852\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 53s 169ms/step - loss: 1.1968 - accuracy: 0.4102 - val_loss: 1.1764 - val_accuracy: 0.4240\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 55s 175ms/step - loss: 1.1873 - accuracy: 0.4166 - val_loss: 1.3171 - val_accuracy: 0.3441\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 55s 174ms/step - loss: 1.1808 - accuracy: 0.4275 - val_loss: 1.1434 - val_accuracy: 0.4517\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 54s 171ms/step - loss: 1.1753 - accuracy: 0.4326 - val_loss: 1.1989 - val_accuracy: 0.4174\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 54s 172ms/step - loss: 1.1644 - accuracy: 0.4416 - val_loss: 1.2085 - val_accuracy: 0.4150\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 53s 169ms/step - loss: 1.1586 - accuracy: 0.4464 - val_loss: 1.1679 - val_accuracy: 0.4318\n",
      "Epoch 8: early stopping\n",
      "625/625 [==============================] - 8s 11ms/step\n",
      "Accuracy on Validation Set: 0.45170326646991144 cpt=1\n",
      "Check class i=1 nb_lab=3351 check_class=False check_class_limit=3748.3125\n",
      "Epoch 1/20\n",
      "313/313 [==============================] - 65s 177ms/step - loss: 1.2488 - accuracy: 0.3782 - val_loss: 1.1817 - val_accuracy: 0.4039\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 53s 169ms/step - loss: 1.2047 - accuracy: 0.4049 - val_loss: 1.2202 - val_accuracy: 0.3801\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 56s 178ms/step - loss: 1.1965 - accuracy: 0.4121 - val_loss: 1.2562 - val_accuracy: 0.3839\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 56s 180ms/step - loss: 1.1896 - accuracy: 0.4139 - val_loss: 1.1615 - val_accuracy: 0.4262\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 54s 171ms/step - loss: 1.1835 - accuracy: 0.4217 - val_loss: 1.1645 - val_accuracy: 0.4331\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 51s 164ms/step - loss: 1.1751 - accuracy: 0.4321 - val_loss: 1.2148 - val_accuracy: 0.3922\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 53s 170ms/step - loss: 1.1647 - accuracy: 0.4381 - val_loss: 1.1818 - val_accuracy: 0.4257\n",
      "Epoch 7: early stopping\n",
      "625/625 [==============================] - 8s 12ms/step\n",
      "Accuracy on Validation Set: 0.42619178630383675 cpt=2\n",
      "Check class i=2 nb_lab=3609 check_class=False check_class_limit=3748.3125\n",
      "Epoch 1/20\n",
      "313/313 [==============================] - 57s 164ms/step - loss: 1.2557 - accuracy: 0.3713 - val_loss: 1.1841 - val_accuracy: 0.3946\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 50s 159ms/step - loss: 1.2106 - accuracy: 0.4000 - val_loss: 1.1871 - val_accuracy: 0.3901\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 50s 160ms/step - loss: 1.2013 - accuracy: 0.4082 - val_loss: 1.1873 - val_accuracy: 0.4144\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 49s 158ms/step - loss: 1.1920 - accuracy: 0.4168 - val_loss: 1.1584 - val_accuracy: 0.4326\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 50s 160ms/step - loss: 1.1845 - accuracy: 0.4242 - val_loss: 1.1720 - val_accuracy: 0.4339\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 50s 161ms/step - loss: 1.1724 - accuracy: 0.4342 - val_loss: 1.1611 - val_accuracy: 0.4370\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 51s 164ms/step - loss: 1.1705 - accuracy: 0.4383 - val_loss: 1.1798 - val_accuracy: 0.4296\n",
      "Epoch 7: early stopping\n",
      "625/625 [==============================] - 8s 11ms/step\n",
      "Accuracy on Validation Set: 0.43264469011054973 cpt=3\n",
      "Check class i=1 nb_lab=352 check_class=False check_class_limit=3748.3125\n",
      "Epoch 1/20\n",
      "313/313 [==============================] - 60s 169ms/step - loss: 1.2576 - accuracy: 0.3731 - val_loss: 1.1814 - val_accuracy: 0.3972\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 47s 151ms/step - loss: 1.2093 - accuracy: 0.4005 - val_loss: 1.2076 - val_accuracy: 0.3927\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 45s 145ms/step - loss: 1.1968 - accuracy: 0.4112 - val_loss: 1.1752 - val_accuracy: 0.4160\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 48s 154ms/step - loss: 1.1910 - accuracy: 0.4166 - val_loss: 1.1645 - val_accuracy: 0.4328\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 1.1831 - accuracy: 0.4231 - val_loss: 1.1682 - val_accuracy: 0.4362\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 1.1745 - accuracy: 0.4305 - val_loss: 1.1525 - val_accuracy: 0.4372\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 1.1655 - accuracy: 0.4372 - val_loss: 1.1909 - val_accuracy: 0.4218\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 58s 186ms/step - loss: 1.1578 - accuracy: 0.4458 - val_loss: 1.1487 - val_accuracy: 0.4446\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 68s 219ms/step - loss: 1.1450 - accuracy: 0.4517 - val_loss: 1.1923 - val_accuracy: 0.4185\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 51s 162ms/step - loss: 1.1386 - accuracy: 0.4589 - val_loss: 1.1973 - val_accuracy: 0.4176\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 49s 157ms/step - loss: 1.1313 - accuracy: 0.4632 - val_loss: 1.2258 - val_accuracy: 0.4044\n",
      "Epoch 11: early stopping\n",
      "625/625 [==============================] - 10s 11ms/step\n",
      "Accuracy on Validation Set: 0.4445500475213846 cpt=4\n",
      "Check class i=1 nb_lab=939 check_class=False check_class_limit=3748.3125\n",
      "Epoch 1/20\n",
      "313/313 [==============================] - 62s 181ms/step - loss: 1.2483 - accuracy: 0.3716 - val_loss: 1.1960 - val_accuracy: 0.4050\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 54s 171ms/step - loss: 1.2071 - accuracy: 0.4040 - val_loss: 1.1726 - val_accuracy: 0.4309\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 53s 170ms/step - loss: 1.1963 - accuracy: 0.4127 - val_loss: 1.1660 - val_accuracy: 0.4307\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 53s 168ms/step - loss: 1.1870 - accuracy: 0.4190 - val_loss: 1.1738 - val_accuracy: 0.4213\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 52s 166ms/step - loss: 1.1789 - accuracy: 0.4232 - val_loss: 1.1929 - val_accuracy: 0.4110\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 52s 167ms/step - loss: 1.1729 - accuracy: 0.4323 - val_loss: 1.1665 - val_accuracy: 0.4370\n",
      "Epoch 6: early stopping\n",
      "625/625 [==============================] - 8s 11ms/step\n",
      "Accuracy on Validation Set: 0.43069381221549696 cpt=5\n",
      "Check class i=1 nb_lab=1835 check_class=False check_class_limit=3748.3125\n",
      "Check class i=3 nb_lab=3448 check_class=False check_class_limit=3748.3125\n",
      "Epoch 1/20\n",
      "313/313 [==============================] - 61s 175ms/step - loss: 1.2495 - accuracy: 0.3747 - val_loss: 1.1820 - val_accuracy: 0.4115\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 53s 168ms/step - loss: 1.2095 - accuracy: 0.4029 - val_loss: 1.2587 - val_accuracy: 0.3680\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 52s 166ms/step - loss: 1.1997 - accuracy: 0.4101 - val_loss: 1.1717 - val_accuracy: 0.4346\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 50s 160ms/step - loss: 1.1883 - accuracy: 0.4174 - val_loss: 1.1500 - val_accuracy: 0.4363\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 53s 168ms/step - loss: 1.1837 - accuracy: 0.4254 - val_loss: 1.2052 - val_accuracy: 0.4138\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 51s 164ms/step - loss: 1.1740 - accuracy: 0.4329 - val_loss: 1.2105 - val_accuracy: 0.4095\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 51s 165ms/step - loss: 1.1641 - accuracy: 0.4384 - val_loss: 1.1499 - val_accuracy: 0.4486\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 57s 182ms/step - loss: 1.1567 - accuracy: 0.4472 - val_loss: 1.1496 - val_accuracy: 0.4454\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 1.1411 - accuracy: 0.4576 - val_loss: 1.2375 - val_accuracy: 0.3978\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 54s 172ms/step - loss: 1.1328 - accuracy: 0.4622 - val_loss: 1.1409 - val_accuracy: 0.4477\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 60s 193ms/step - loss: 1.1264 - accuracy: 0.4669 - val_loss: 1.2525 - val_accuracy: 0.3947\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 70s 223ms/step - loss: 1.1178 - accuracy: 0.4734 - val_loss: 1.1731 - val_accuracy: 0.4270\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 57s 183ms/step - loss: 1.1129 - accuracy: 0.4778 - val_loss: 1.1626 - val_accuracy: 0.4344\n",
      "Epoch 13: early stopping\n",
      "625/625 [==============================] - 9s 12ms/step\n",
      "Accuracy on Validation Set: 0.44765144314941724 cpt=6\n",
      "Check class i=1 nb_lab=3366 check_class=False check_class_limit=3748.3125\n",
      "Epoch 1/20\n",
      "313/313 [==============================] - 68s 193ms/step - loss: 1.2612 - accuracy: 0.3693 - val_loss: 1.2008 - val_accuracy: 0.3874\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 67s 215ms/step - loss: 1.2094 - accuracy: 0.4025 - val_loss: 1.2222 - val_accuracy: 0.3898\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 65s 208ms/step - loss: 1.1951 - accuracy: 0.4136 - val_loss: 1.2050 - val_accuracy: 0.3865\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 62s 199ms/step - loss: 1.1886 - accuracy: 0.4214 - val_loss: 1.2174 - val_accuracy: 0.4110\n",
      "Epoch 4: early stopping\n",
      "625/625 [==============================] - 8s 11ms/step\n",
      "Accuracy on Validation Set: 0.3873743184432995 cpt=7\n",
      "Epoch 1/20\n",
      "313/313 [==============================] - 75s 216ms/step - loss: 1.2531 - accuracy: 0.3677 - val_loss: 1.2011 - val_accuracy: 0.3766\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 54s 173ms/step - loss: 1.2083 - accuracy: 0.3967 - val_loss: 1.2162 - val_accuracy: 0.3931\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 57s 183ms/step - loss: 1.1978 - accuracy: 0.4068 - val_loss: 1.1790 - val_accuracy: 0.4019\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 56s 180ms/step - loss: 1.1904 - accuracy: 0.4130 - val_loss: 1.1813 - val_accuracy: 0.4075\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 58s 184ms/step - loss: 1.1856 - accuracy: 0.4221 - val_loss: 1.2198 - val_accuracy: 0.4105\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 56s 179ms/step - loss: 1.1767 - accuracy: 0.4283 - val_loss: 1.2350 - val_accuracy: 0.4005\n",
      "Epoch 6: early stopping\n",
      "625/625 [==============================] - 8s 11ms/step\n",
      "Accuracy on Validation Set: 0.40193086889100094 cpt=8\n",
      "Check class i=3 nb_lab=1050 check_class=False check_class_limit=3748.3125\n",
      "Epoch 1/20\n",
      "313/313 [==============================] - 71s 205ms/step - loss: 1.2522 - accuracy: 0.3717 - val_loss: 1.2697 - val_accuracy: 0.3414\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 62s 197ms/step - loss: 1.2098 - accuracy: 0.4019 - val_loss: 1.2959 - val_accuracy: 0.3334\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 63s 203ms/step - loss: 1.1987 - accuracy: 0.4115 - val_loss: 1.1624 - val_accuracy: 0.4233\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 59s 190ms/step - loss: 1.1897 - accuracy: 0.4143 - val_loss: 1.1741 - val_accuracy: 0.4329\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 67s 214ms/step - loss: 1.1833 - accuracy: 0.4202 - val_loss: 1.1877 - val_accuracy: 0.4158\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 71s 227ms/step - loss: 1.1785 - accuracy: 0.4256 - val_loss: 1.2286 - val_accuracy: 0.3945\n",
      "Epoch 6: early stopping\n",
      "625/625 [==============================] - 15s 19ms/step\n",
      "Accuracy on Validation Set: 0.4233405032264519 cpt=9\n",
      "Check class i=1 nb_lab=1635 check_class=False check_class_limit=3748.3125\n",
      "Check class i=3 nb_lab=2771 check_class=False check_class_limit=3748.3125\n",
      "Epoch 1/20\n",
      "313/313 [==============================] - 67s 195ms/step - loss: 1.2618 - accuracy: 0.3635 - val_loss: 1.2074 - val_accuracy: 0.3846\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 61s 194ms/step - loss: 1.2107 - accuracy: 0.3969 - val_loss: 1.2319 - val_accuracy: 0.3663\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 62s 197ms/step - loss: 1.2023 - accuracy: 0.4060 - val_loss: 1.1773 - val_accuracy: 0.4162\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 71s 227ms/step - loss: 1.1915 - accuracy: 0.4155 - val_loss: 1.1663 - val_accuracy: 0.4177\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 68s 215ms/step - loss: 1.1830 - accuracy: 0.4223 - val_loss: 1.1555 - val_accuracy: 0.4376\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 65s 207ms/step - loss: 1.1753 - accuracy: 0.4329 - val_loss: 1.1743 - val_accuracy: 0.4271\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 61s 194ms/step - loss: 1.1669 - accuracy: 0.4407 - val_loss: 1.2558 - val_accuracy: 0.3827\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 61s 193ms/step - loss: 1.1614 - accuracy: 0.4436 - val_loss: 1.2019 - val_accuracy: 0.4076\n",
      "Epoch 8: early stopping\n",
      "625/625 [==============================] - 9s 12ms/step\n",
      "Accuracy on Validation Set: 0.437596918613376 cpt=10\n",
      "Check class i=1 nb_lab=3098 check_class=False check_class_limit=3748.3125\n",
      "Check class i=3 nb_lab=2715 check_class=False check_class_limit=3748.3125\n",
      "Optim fail cpt=10 param suivant cpt_param=1\n",
      "Optim fail cpt=10\n"
     ]
    }
   ],
   "source": [
    "list_param_valid = [\n",
    "                    {'fit__batch_size': 256, 'model__dropout': 0.05, 'model__layers': [64, 10], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.9},\n",
    "                    # {'fit__batch_size': 32, 'fit__epochs': 350, 'model__dropout': 0.05, 'model__layers': [128, 20], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.7},\n",
    "                    # {'fit__batch_size': 32, 'fit__epochs': 350, 'model__dropout': 0.05, 'model__layers': [128, 20], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.5},\n",
    "                    # {'fit__batch_size': 64, 'fit__epochs': 350, 'model__dropout': 0.05, 'model__layers': [128, 20], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.9},\n",
    "                    # {'fit__batch_size': 64, 'fit__epochs': 350, 'model__dropout': 0.05, 'model__layers': [128, 20], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.7},\n",
    "                    # {'fit__batch_size': 64, 'fit__epochs': 350, 'model__dropout': 0.05, 'model__layers': [128, 20], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.5},\n",
    "]\n",
    "\n",
    "input_dim = x_train.shape[-1]\n",
    "num_classes = 4\n",
    "epochs = 20#350\n",
    "suffix=\"lstm_v1\"\n",
    "filename_tmp_model = dts_name+\"_\"+suffix+\".h5\"\n",
    "patience = 3\n",
    "\n",
    "val_accuracy=0.0\n",
    "obj_acc=0.4\n",
    "cpt_param=0\n",
    "try_limit=10\n",
    "pct_check_class=0.75 # check if at least n% of the validation set per class\n",
    "\n",
    "len_val=len(x_val_lstm)\n",
    "check_class_limit=(len_val/num_classes)*pct_check_class\n",
    "check_class=False # check if at least obj_acc accuracy per class\n",
    "\n",
    "while(cpt_param<len(list_param_valid) and check_class==False):\n",
    "    param_valid=list_param_valid[cpt_param]\n",
    "    print(param_valid)\n",
    "    cpt=0\n",
    "\n",
    "    while(cpt<try_limit and check_class==False):\n",
    "        cpt+=1\n",
    "        es = EarlyStopping(monitor=\"val_loss\", patience=patience, mode=\"min\", verbose=2)\n",
    "        mc = ModelCheckpoint(filename_tmp_model, monitor=\"val_loss\",\n",
    "                            mode=\"min\", save_freq=\"epoch\", save_best_only=True)\n",
    "        lstm_model = scikeras_KerasClassifier(model=modmgr.create_scikeras_lstm_model, optimizer=\"adam\",optimizer__momentum=param_valid['optimizer__momentum'],\n",
    "                                            optimizer__lr=param_valid['optimizer__lr'], model__layers=param_valid['model__layers'], model__dropout=param_valid['model__dropout'],\n",
    "                                                callbacks=[es, mc], verbose=1)\n",
    "\n",
    "        history = lstm_model.fit(\n",
    "            x_train_lstm, y_train_lstm, batch_size=param_valid['fit__batch_size'], epochs=epochs, validation_data=(x_val_lstm, y_val_lstm))\n",
    "\n",
    "        train_loss = history.history_['loss']\n",
    "        val_loss = history.history_['val_loss']\n",
    "\n",
    "        # Plot loss\n",
    "        # epochs_done = range(1, len(train_loss) + 1)\n",
    "        # plt.plot(epochs_done, train_loss, 'bo-', label='Training Loss')\n",
    "        # plt.plot(epochs_done, val_loss, 'ro-', label='Validation Loss')\n",
    "        # plt.legend()\n",
    "        # plt.show()\n",
    "\n",
    "        saved_model = load_model(filename_tmp_model)\n",
    "        # saved_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['loss'])\n",
    "        # loss, accuracy = saved_model.evaluate(x_valid, y_valid)\n",
    "\n",
    "        # Prediction on validation\n",
    "        y_pred = saved_model.predict(x_val_lstm)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        # Accuracy on validation\n",
    "        val_accuracy = metrics.accuracy_score(y_val_lstm.argmax(axis=1), y_pred_classes)\n",
    "        print(f\"Accuracy on Validation Set: {val_accuracy} {cpt=}\")\n",
    "\n",
    "        # check prediction au moins 30 par classe\n",
    "        if val_accuracy>=obj_acc:\n",
    "            check_class=True\n",
    "            for i in range(num_classes):\n",
    "                nb_lab=sum(y_pred_classes == i)\n",
    "                if nb_lab<check_class_limit  :\n",
    "                    check_class=False\n",
    "                    print(f\"Check class {i=} {nb_lab=} {check_class=} {check_class_limit=}\")\n",
    "\n",
    "    if cpt>=try_limit :\n",
    "        cpt_param+=1\n",
    "        print(f\"Optim fail {cpt=} param suivant {cpt_param=}\")\n",
    "\n",
    "if cpt>=try_limit :\n",
    "    print(f\"Optim fail {cpt=}\")\n",
    "\n",
    "else :\n",
    "    confusion = metrics.confusion_matrix(y_val_lstm.argmax(axis=1), y_pred_classes)\n",
    "    print(confusion)\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        print(f\"Categ {i}: real {sum(y_val_lstm.argmax(axis=1) == i)} predict {sum(y_pred_classes == i)}\")\n",
    "\n",
    "    #check saved model\n",
    "    saved_model = load_model(filename_tmp_model)\n",
    "    y_pred = saved_model.predict(x_val_lstm)\n",
    "    confusion = metrics.confusion_matrix(y_val_lstm.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "    print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_train.shape[-1]\n",
    "window_size = sequence_length\n",
    "dropout = 0.2\n",
    "num_classes = 4\n",
    "\n",
    "# cat_y_train = keras.utils.to_categorical(col_y_train, num_classes)\n",
    "# cat_y_valid = keras.utils.to_categorical(col_y_valid, num_classes)\n",
    "\n",
    "# df_x_train_exp = np.expand_dims(df_x_train, axis=2)\n",
    "# df_x_valid_exp = np.expand_dims(df_x_valid, axis=2)\n",
    "\n",
    "\n",
    "model_LSTM = Sequential()\n",
    "model_LSTM.add(LSTM(units=20, return_sequences=False,#True\n",
    "               input_shape=(window_size, input_dim)))\n",
    "#,kernel_regularizer=l2(0.1), recurrent_regularizer=l2(0.1), bias_regularizer=l2(0.1)\n",
    "model_LSTM.add(Dropout(rate=dropout))   \n",
    "# model_LSTM.add(Dropout(rate=dropout))\n",
    "# model_LSTM.add(Bidirectional(LSTM((window_size * 2), return_sequences=True)))\n",
    "# model_LSTM.add(Dropout(rate=dropout))\n",
    "# model_LSTM.add(Bidirectional(LSTM(window_size, return_sequences=False)))\n",
    "model_LSTM.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "model_LSTM.compile(loss='categorical_crossentropy',\n",
    "                   optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model_LSTM.fit(x_train_lstm, y_train_lstm, batch_size=1024,\n",
    "                         shuffle=False, epochs=20, validation_data=(x_val_lstm, y_val_lstm))#,verbose=0\n",
    "\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Plot loss\n",
    "epochs = range(1, len(train_accuracy) + 1)\n",
    "plt.plot(epochs, train_accuracy, 'bo-', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'ro-', label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12302096189872760406\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# print if keras can use the gpu to train the model\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
