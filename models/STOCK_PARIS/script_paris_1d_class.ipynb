{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random as rd\n",
    "import csv\n",
    "import ta\n",
    "import random\n",
    "from pathlib import Path\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sma\n",
    "import statsmodels.stats.outliers_influence  as smo\n",
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "import sqlite_io as sio\n",
    "import add_indicators as indic\n",
    "import split_merge as sm\n",
    "import balance\n",
    "import model_mngr as modmgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = \"C:\\Projets\\Data\"\n",
    "PATH_DB_FWK=\"C:\\Projets\\Data\\sqlite\\dataset_market.db\"\n",
    "PATH_DB_STOCK=\"C:\\Projets\\Data\\sqlite\\dataset_paris_stock_adjusted.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONNECTION TO SQLITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"con_stock\" in locals():\n",
    "        sio.close_connection(con_stock)\n",
    "con_stock = sio.get_connection(str_db_path=PATH_DB_STOCK)\n",
    "\n",
    "if \"con_fwk\" in locals():\n",
    "        sio.close_connection(con_fwk)\n",
    "con_fwk = sio.get_connection(str_db_path=PATH_DB_FWK)\n",
    "\n",
    "my_session_maker = sessionmaker(bind=con_fwk)\n",
    "session=my_session_maker()\n",
    "\n",
    "table_stock=\"DS_PARIS_1D_ADJ_CLEAN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts_name=\"PARIS_TREND_1D_20D_V1\"\n",
    "multi_symbol=\"PARIS_STOCK\"\n",
    "\n",
    "df_base=sio.get_candles_to_df(session=session,con=con_stock, target_table=table_stock)\n",
    "df_work=pd.DataFrame()\n",
    "for code_value in df_base.index.get_level_values('CODE').unique():\n",
    "    sub_df=df_base[df_base.index.get_level_values('CODE') == code_value]\n",
    "    df_work_tmp = indic.add_indicators_to_df(con=con_fwk, df_in=sub_df, dts_name=dts_name,symbol=multi_symbol)\n",
    "    df_work = pd.concat([df_work, df_work_tmp])\n",
    "    \n",
    "df_work.sort_index(inplace=True)\n",
    "df_work.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_work[10000:10010]\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# print(df_work.describe())\n",
    "\n",
    "# df_work.round(5).to_csv(\n",
    "    PATH_DATA+\"\\DTS_FULL\\PARIS_TREND_1D_20D_V1_BASE.zip\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>sma20</th>\n",
       "      <th>pos_sma20</th>\n",
       "      <th>sma50</th>\n",
       "      <th>sma200</th>\n",
       "      <th>pos_sma50</th>\n",
       "      <th>...</th>\n",
       "      <th>donchian20_lo</th>\n",
       "      <th>pos_donchian20_hi</th>\n",
       "      <th>pos_donchian20_lo</th>\n",
       "      <th>adx14</th>\n",
       "      <th>adx14_neg</th>\n",
       "      <th>adx14_pos</th>\n",
       "      <th>adx14_dif</th>\n",
       "      <th>avg_vol14</th>\n",
       "      <th>pos_avg_vol14</th>\n",
       "      <th>pos_sma20_200</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPEN_DATETIME</th>\n",
       "      <th>CODE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <th>AAA.PA</th>\n",
       "      <td>20.3331</td>\n",
       "      <td>20.8291</td>\n",
       "      <td>20.3331</td>\n",
       "      <td>20.8291</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.82910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <th>AAA.PA</th>\n",
       "      <td>20.8291</td>\n",
       "      <td>20.8291</td>\n",
       "      <td>20.8291</td>\n",
       "      <td>20.8291</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.82910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <th>AAA.PA</th>\n",
       "      <td>20.8291</td>\n",
       "      <td>21.8209</td>\n",
       "      <td>20.8291</td>\n",
       "      <td>21.8209</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.15970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <th>AAA.PA</th>\n",
       "      <td>22.8128</td>\n",
       "      <td>22.8128</td>\n",
       "      <td>22.8128</td>\n",
       "      <td>22.8128</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.57298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05747</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <th>AAA.PA</th>\n",
       "      <td>23.8046</td>\n",
       "      <td>23.8046</td>\n",
       "      <td>23.8046</td>\n",
       "      <td>23.8046</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.01930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08108</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         OPEN     HIGH      LOW    CLOSE  VOLUME  sma20  \\\n",
       "OPEN_DATETIME CODE                                                        \n",
       "2000-01-03    AAA.PA  20.3331  20.8291  20.3331  20.8291    45.0    NaN   \n",
       "2000-01-04    AAA.PA  20.8291  20.8291  20.8291  20.8291    10.0    NaN   \n",
       "2000-01-05    AAA.PA  20.8291  21.8209  20.8291  21.8209    20.0    NaN   \n",
       "2000-01-06    AAA.PA  22.8128  22.8128  22.8128  22.8128    30.0    NaN   \n",
       "2000-01-07    AAA.PA  23.8046  23.8046  23.8046  23.8046    25.0    NaN   \n",
       "\n",
       "                      pos_sma20     sma50  sma200  pos_sma50  ...  \\\n",
       "OPEN_DATETIME CODE                                            ...   \n",
       "2000-01-03    AAA.PA        NaN  20.82910     NaN    0.00000  ...   \n",
       "2000-01-04    AAA.PA        NaN  20.82910     NaN    0.00000  ...   \n",
       "2000-01-05    AAA.PA        NaN  21.15970     NaN    0.03125  ...   \n",
       "2000-01-06    AAA.PA        NaN  21.57298     NaN    0.05747  ...   \n",
       "2000-01-07    AAA.PA        NaN  22.01930     NaN    0.08108  ...   \n",
       "\n",
       "                      donchian20_lo  pos_donchian20_hi  pos_donchian20_lo  \\\n",
       "OPEN_DATETIME CODE                                                          \n",
       "2000-01-03    AAA.PA            NaN                NaN                NaN   \n",
       "2000-01-04    AAA.PA            NaN                NaN                NaN   \n",
       "2000-01-05    AAA.PA            NaN                NaN                NaN   \n",
       "2000-01-06    AAA.PA            NaN                NaN                NaN   \n",
       "2000-01-07    AAA.PA            NaN                NaN                NaN   \n",
       "\n",
       "                      adx14  adx14_neg  adx14_pos  adx14_dif  avg_vol14  \\\n",
       "OPEN_DATETIME CODE                                                        \n",
       "2000-01-03    AAA.PA    0.0        0.0        0.0        0.0        NaN   \n",
       "2000-01-04    AAA.PA    0.0        0.0        0.0        0.0        NaN   \n",
       "2000-01-05    AAA.PA    0.0        0.0        0.0        0.0        NaN   \n",
       "2000-01-06    AAA.PA    0.0        0.0        0.0        0.0        NaN   \n",
       "2000-01-07    AAA.PA    0.0        0.0        0.0        0.0        NaN   \n",
       "\n",
       "                      pos_avg_vol14  pos_sma20_200  \n",
       "OPEN_DATETIME CODE                                  \n",
       "2000-01-03    AAA.PA            NaN            NaN  \n",
       "2000-01-04    AAA.PA            NaN            NaN  \n",
       "2000-01-05    AAA.PA            NaN            NaN  \n",
       "2000-01-06    AAA.PA            NaN            NaN  \n",
       "2000-01-07    AAA.PA            NaN            NaN  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dts_name=\"PARIS_TREND_1D_20D_V1\"\n",
    "multi_symbol=\"PARIS_STOCK\"\n",
    "\n",
    "df_work=pd.read_csv(PATH_DATA+\"\\DTS_FULL\\PARIS_TREND_1D_20D_V1_BASE.zip\",sep=\",\",index_col=[\"OPEN_DATETIME\",\"CODE\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "df_work.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check=df_work[df_work['stdev20_1d'] > 1000]\n",
    "# df_check=df_check[df_check['ret_1d'] <= 2]\n",
    "df_check.index.get_level_values('CODE').unique()\n",
    "# df_check[df_check.index.get_level_values('CODE')=='AKW.PA']\n",
    "# df_check=df_work[df_work.index.get_level_values('CODE')=='AI.PA']\n",
    "# CATG\n",
    "mask = df_work['stdev20_1d'] > 1000\n",
    "df_work.drop(df_work[mask].index, inplace=True)\n",
    "# df_check[6000:6010]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           LABEL\n",
      "0   lab_perf_20d\n",
      "1   lab_perf_50d\n",
      "2  lab_perf_125d\n"
     ]
    }
   ],
   "source": [
    "df_work = indic.drop_indicators_by_type(\n",
    "    con=con_fwk, df_in=df_work, dts_name=dts_name, symbol=multi_symbol, ind_type=0)\n",
    "list_label = indic.get_ind_list_by_type_for_dts(\n",
    "    con=con_fwk, dts_name=dts_name, symbol_code=multi_symbol, ind_type=2)\n",
    "print(list_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>pos_sma20</th>\n",
       "      <th>pos_sma50</th>\n",
       "      <th>pos_sma200</th>\n",
       "      <th>pos_sma50_200</th>\n",
       "      <th>pos_sma20_50</th>\n",
       "      <th>...</th>\n",
       "      <th>stoch14_dif</th>\n",
       "      <th>cmf_20</th>\n",
       "      <th>pos_donchian20_hi</th>\n",
       "      <th>pos_donchian20_lo</th>\n",
       "      <th>adx14</th>\n",
       "      <th>adx14_neg</th>\n",
       "      <th>adx14_pos</th>\n",
       "      <th>adx14_dif</th>\n",
       "      <th>pos_avg_vol14</th>\n",
       "      <th>pos_sma20_200</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPEN_DATETIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1989-01-16</th>\n",
       "      <td>1.9958</td>\n",
       "      <td>2.0179</td>\n",
       "      <td>1.9847</td>\n",
       "      <td>1.9958</td>\n",
       "      <td>663163.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-01-17</th>\n",
       "      <td>1.9958</td>\n",
       "      <td>1.9958</td>\n",
       "      <td>1.9958</td>\n",
       "      <td>1.9958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-01-18</th>\n",
       "      <td>1.9958</td>\n",
       "      <td>1.9958</td>\n",
       "      <td>1.9958</td>\n",
       "      <td>1.9958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-01-19</th>\n",
       "      <td>1.9442</td>\n",
       "      <td>1.9682</td>\n",
       "      <td>1.9368</td>\n",
       "      <td>1.9442</td>\n",
       "      <td>1641505.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.01952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-01-20</th>\n",
       "      <td>1.9350</td>\n",
       "      <td>1.9663</td>\n",
       "      <td>1.9350</td>\n",
       "      <td>1.9350</td>\n",
       "      <td>1129887.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.01942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 OPEN    HIGH     LOW   CLOSE     VOLUME  pos_sma20  \\\n",
       "OPEN_DATETIME                                                         \n",
       "1989-01-16     1.9958  2.0179  1.9847  1.9958   663163.0        NaN   \n",
       "1989-01-17     1.9958  1.9958  1.9958  1.9958        0.0        NaN   \n",
       "1989-01-18     1.9958  1.9958  1.9958  1.9958        0.0        NaN   \n",
       "1989-01-19     1.9442  1.9682  1.9368  1.9442  1641505.0        NaN   \n",
       "1989-01-20     1.9350  1.9663  1.9350  1.9350  1129887.0        NaN   \n",
       "\n",
       "               pos_sma50  pos_sma200  pos_sma50_200  pos_sma20_50  ...  \\\n",
       "OPEN_DATETIME                                                      ...   \n",
       "1989-01-16       0.00000         NaN            NaN           NaN  ...   \n",
       "1989-01-17       0.00000         NaN            NaN           NaN  ...   \n",
       "1989-01-18       0.00000         NaN            NaN           NaN  ...   \n",
       "1989-01-19      -0.01952         NaN            NaN           NaN  ...   \n",
       "1989-01-20      -0.01942         NaN            NaN           NaN  ...   \n",
       "\n",
       "               stoch14_dif  cmf_20  pos_donchian20_hi  pos_donchian20_lo  \\\n",
       "OPEN_DATETIME                                                              \n",
       "1989-01-16             NaN     NaN                NaN                NaN   \n",
       "1989-01-17             NaN     NaN                NaN                NaN   \n",
       "1989-01-18             NaN     NaN                NaN                NaN   \n",
       "1989-01-19             NaN     NaN                NaN                NaN   \n",
       "1989-01-20             NaN     NaN                NaN                NaN   \n",
       "\n",
       "               adx14  adx14_neg  adx14_pos  adx14_dif  pos_avg_vol14  \\\n",
       "OPEN_DATETIME                                                          \n",
       "1989-01-16       0.0        0.0        0.0        0.0            NaN   \n",
       "1989-01-17       0.0        0.0        0.0        0.0            NaN   \n",
       "1989-01-18       0.0        0.0        0.0        0.0            NaN   \n",
       "1989-01-19       0.0        0.0        0.0        0.0            NaN   \n",
       "1989-01-20       0.0        0.0        0.0        0.0            NaN   \n",
       "\n",
       "               pos_sma20_200  \n",
       "OPEN_DATETIME                 \n",
       "1989-01-16               NaN  \n",
       "1989-01-17               NaN  \n",
       "1989-01-18               NaN  \n",
       "1989-01-19               NaN  \n",
       "1989-01-20               NaN  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_work=df_work.droplevel('CODE')\n",
    "df_work.sort_index(inplace=True)\n",
    "df_work.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected: df_selected.shape=(940314, 29) valid: df_valid.shape=(263768, 29) confirm: df_confirm.shape=(281462, 29)\n"
     ]
    }
   ],
   "source": [
    "lab_studied = \"lab_perf_20d\"\n",
    "algo_studied = \"XG_BOOST_CLASS\"\n",
    "\n",
    "df_work = indic.drop_indicators_not_selected(con=con_fwk, df_in=df_work, dts_name=dts_name, symbol=multi_symbol,label=lab_studied,algo=algo_studied)\n",
    "\n",
    "df_split=sm.split_df_by_label_strat(\n",
    "    df_in=df_work, list_label=[lab_studied], split_timeframe=\"M\",random_split=False,split_strat=(80,10,10))\n",
    "df_selected = df_split['df_'+lab_studied+'_train']\n",
    "df_valid = df_split['df_'+lab_studied+'_valid']\n",
    "df_confirm = df_split['df_'+lab_studied+'_confirm']\n",
    "df_selected.sort_index(inplace=True)\n",
    "df_valid.sort_index(inplace=True)\n",
    "df_confirm.sort_index(inplace=True)\n",
    "\n",
    "print(f\"selected: {df_selected.shape=} valid: {df_valid.shape=} confirm: {df_confirm.shape=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPEN_DATETIME\n",
      "1989-10-20    4\n",
      "2017-02-28    2\n",
      "Name: lab_perf_20d, dtype: int64\n",
      "OPEN_DATETIME\n",
      "2017-03-01    2.0\n",
      "2020-07-31    3.0\n",
      "Name: lab_perf_20d, dtype: float64\n",
      "lab_perf_20d\n",
      "0    188080\n",
      "1    188068\n",
      "2    188085\n",
      "3    188020\n",
      "4    188061\n",
      "Name: count, dtype: int64\n",
      "lab_perf_20d\n",
      "0.0    59173\n",
      "1.0    53967\n",
      "2.0    52413\n",
      "3.0    50317\n",
      "4.0    47889\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label=lab_studied\n",
    "df_class=balance.add_class_by_lab_nb_lines(df_in=df_selected,str_label=lab_studied,nb_class=5,bool_replace_label=True)\n",
    "df_class.sort_index(inplace=True)\n",
    "categ={0:[-1,-0.05172],1:[-0.05172,-0.00868],2:[-0.00868,0.02272],3:[0.02272,0.07058],4:[0.07059,5]}\n",
    "df_class_val=balance.add_lab_by_class(df_in=df_valid,str_label=lab_studied, categ=categ,bool_replace_label=True)\n",
    "df_class_val.sort_index(inplace=True)\n",
    "print(df_class.loc[:, label].dropna().iloc[[0, -1]])\n",
    "print(df_class_val.loc[:, label].dropna().iloc[[0, -1]])\n",
    "# df_class_clean=df_class.drop(['OPEN','HIGH','LOW','CLOSE','VOLUME','lab_perf_125d','lab_perf_20d','lab_perf_50d'],axis=1)\n",
    "data = df_class[label]\n",
    "print(data.value_counts().sort_index())\n",
    "data_val = df_class_val[label]\n",
    "print(data_val.value_counts().sort_index())\n",
    "\n",
    "# min_max_lab_by_class = df_class.groupby(label+'_class')[label].agg(['min', 'max'])\n",
    "# print(min_max_lab_by_class)\n",
    "\n",
    "#                         min      max\n",
    "# lab_perf_20d_class                  \n",
    "# 0                  -0.87743 -0.05172\n",
    "# 1                  -0.05171 -0.00868\n",
    "# 2                  -0.00867  0.02272\n",
    "# 3                   0.02273  0.07058\n",
    "# 4                   0.07059  3.82176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feat = df_class.columns.values.tolist()\n",
    "list_feat.remove(label)\n",
    "df_x_train, col_y_train = sm.split_df_x_y(\n",
    "    df_in=df_class, list_features=list_feat, str_label=label, drop_na=True)\n",
    "df_x_val, col_y_val = sm.split_df_x_y(\n",
    "    df_in=df_class_val, list_features=list_feat, str_label=label, drop_na=True)\n",
    "\n",
    "df_class.round(5).to_csv(\n",
    "    PATH_DATA+\"\\DTS_FULL\\PARIS_TREND_1D_20D_V1_TRAIN.zip\", sep=\",\")\n",
    "df_class_val.round(5).to_csv(\n",
    "    PATH_DATA+\"\\DTS_FULL\\PARIS_TREND_1D_20D_V1_VAL.zip\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lab_perf_20d\n",
      "0.0    47000\n",
      "1.0    47000\n",
      "2.0    47000\n",
      "3.0    47000\n",
      "4.0    47000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dts_name=\"PARIS_TREND_1D_20D_V1\"\n",
    "multi_symbol=\"PARIS_STOCK\"\n",
    "label = \"lab_perf_20d\"\n",
    "\n",
    "df_class=pd.read_csv(PATH_DATA+\"\\DTS_FULL\\PARIS_TREND_1D_20D_V1_TRAIN.zip\",sep=\",\",index_col=[\"OPEN_DATETIME\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "df_class.dropna(subset=[label], inplace=True)\n",
    "df_class.sort_index(inplace=True)\n",
    "df_class_val=pd.read_csv(PATH_DATA+\"\\DTS_FULL\\PARIS_TREND_1D_20D_V1_VAL.zip\",sep=\",\",index_col=[\"OPEN_DATETIME\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "df_class_val.dropna(subset=[label], inplace=True)\n",
    "df_class_val.sort_index(inplace=True)\n",
    "\n",
    "list_feat = df_class.columns.values.tolist()\n",
    "list_feat.remove(label)\n",
    "df_x_train, col_y_train = sm.split_df_x_y(\n",
    "    df_in=df_class, list_features=list_feat, str_label=label, drop_na=True)\n",
    "\n",
    "X = df_class_val.drop(label, axis=1, inplace=False)\n",
    "y = df_class_val[label]\n",
    "method = RandomUnderSampler(sampling_strategy={0:47000,1:47000,2:47000,3:47000,4:47000})\n",
    "df_x_val, col_y_val=  method.fit_resample(X, y)\n",
    "print(col_y_val.value_counts().sort_index())\n",
    "# df_x_val, col_y_val = sm.split_df_x_y(\n",
    "    # df_in=df_class_val, list_features=list_feat, str_label=label, drop_na=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_train = df_x_train.corr()\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "corr_train.replace(1,0,inplace=True)\n",
    "corr_train=corr_train.applymap(lambda x : None if x< 0.8 and x>-0.8 else x)\n",
    "corr_train.dropna(axis=0,how='all',inplace=True)\n",
    "corr_train.dropna(axis=1,how='all',inplace=True)\n",
    "\n",
    "corr_train_check=corr_train[corr_train >0.8]\n",
    "corr_train_check.head()\n",
    "sns.heatmap(corr_train_check, annot=False, cmap='coolwarm', vmin=-1, vmax=1, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_train_VIF = sma.add_constant(df_x_train)\n",
    "vif = pd.DataFrame()\n",
    "vif[\"feature\"]=df_x_train_VIF.columns\n",
    "vif[\"VIF\"]= [smo.variance_inflation_factor(df_x_train_VIF.values, i) for i in range(df_x_train_VIF.shape[1])]\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_key=28\n",
    "n_jobs=3\n",
    "\n",
    "df_usamp=df_x_train[:300000]\n",
    "print(f\"{df_usamp.shape=}\")\n",
    "df_x_boruta, col_y_boruta = sm.split_df_x_y(\n",
    "    df_in=df_usamp, list_features=list_feat, str_label=label, drop_na=True)\n",
    "\n",
    "rf_bo = RandomForestClassifier(n_estimators=100, n_jobs=n_jobs)\n",
    "boruta_selector = BorutaPy(rf_bo, n_estimators='auto',\n",
    "                           verbose=1, random_state=int(rnd_key))\n",
    "boruta_selector.fit(df_x_boruta.values, col_y_boruta.values)\n",
    "selected_features = df_x_boruta.columns[boruta_selector.support_]\n",
    "print(selected_features)\n",
    "\n",
    "not_selected_features = set(df_x_boruta.columns) - set(selected_features)\n",
    "print(not_selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_x_train.shape=(940314, 28) df_x_val.shape=(263759, 28) col_y_train.size=940314 col_y_val.size=263759\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "# print(df_x_train.describe())\n",
    "\n",
    "print(f\"{df_x_train.shape=} {df_x_val.shape=} {col_y_train.size=} {col_y_val.size=}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_x_train.shape=(940314, 28) df_x_val.shape=(263759, 28) col_y_train_int.size=940314 col_y_val_int.size=263759\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[0]\tvalidation_0-merror:0.73114\n",
      "[1]\tvalidation_0-merror:0.72858\n",
      "[2]\tvalidation_0-merror:0.72724\n",
      "[3]\tvalidation_0-merror:0.72826\n",
      "[4]\tvalidation_0-merror:0.72752\n",
      "[5]\tvalidation_0-merror:0.72750\n",
      "[6]\tvalidation_0-merror:0.72716\n",
      "[7]\tvalidation_0-merror:0.72797\n",
      "[8]\tvalidation_0-merror:0.72733\n",
      "[9]\tvalidation_0-merror:0.72700\n",
      "[10]\tvalidation_0-merror:0.72676\n",
      "[11]\tvalidation_0-merror:0.72639\n",
      "[12]\tvalidation_0-merror:0.72590\n",
      "[13]\tvalidation_0-merror:0.72544\n",
      "[14]\tvalidation_0-merror:0.72537\n",
      "[15]\tvalidation_0-merror:0.72457\n",
      "[16]\tvalidation_0-merror:0.72431\n",
      "[17]\tvalidation_0-merror:0.72427\n",
      "[18]\tvalidation_0-merror:0.72408\n",
      "[19]\tvalidation_0-merror:0.72415\n",
      "[20]\tvalidation_0-merror:0.72412\n",
      "[21]\tvalidation_0-merror:0.72362\n",
      "[22]\tvalidation_0-merror:0.72372\n",
      "[23]\tvalidation_0-merror:0.72377\n",
      "[24]\tvalidation_0-merror:0.72321\n",
      "[25]\tvalidation_0-merror:0.72335\n",
      "[26]\tvalidation_0-merror:0.72341\n",
      "[27]\tvalidation_0-merror:0.72342\n",
      "[28]\tvalidation_0-merror:0.72348\n",
      "[29]\tvalidation_0-merror:0.72348\n",
      "Accuracy train ({'accuracy': make_scorer(accuracy_score), 'precision_weighted': make_scorer(precision_score, average=weighted), 'recall_weighted': make_scorer(recall_score, average=weighted), 'f1_weighted': make_scorer(f1_score, average=weighted)}) :0.29471122716991804\n",
      "Rank 1: mean_test_precision_weighted 0.2612, Parameters: subsample: 0.8, n_estimators: 100, max_depth: 6, max_delta_step: 1, learning_rate: 0.1, gamma: 0.0\n",
      "Rank 2: mean_test_precision_weighted 0.2609, Parameters: subsample: 0.5, n_estimators: 50, max_depth: 6, max_delta_step: 1, learning_rate: 0.1, gamma: 0.0\n",
      "Rank 3: mean_test_precision_weighted 0.2603, Parameters: subsample: 1.0, n_estimators: 100, max_depth: 6, max_delta_step: 0, learning_rate: 0.1, gamma: 0.1\n",
      "Rank 4: mean_test_precision_weighted 0.2596, Parameters: subsample: 1.0, n_estimators: 50, max_depth: 4, max_delta_step: 0, learning_rate: 0.1, gamma: 0.1\n",
      "Rank 5: mean_test_precision_weighted 0.2595, Parameters: subsample: 0.5, n_estimators: 100, max_depth: 5, max_delta_step: 1, learning_rate: 0.1, gamma: 0.0\n",
      "Rank 6: mean_test_precision_weighted 0.2585, Parameters: subsample: 0.8, n_estimators: 150, max_depth: 4, max_delta_step: 0, learning_rate: 0.1, gamma: 0.1\n",
      "Rank 7: mean_test_precision_weighted 0.2582, Parameters: subsample: 0.8, n_estimators: 100, max_depth: 5, max_delta_step: 0, learning_rate: 0.1, gamma: 0.1\n",
      "Rank 8: mean_test_precision_weighted 0.2581, Parameters: subsample: 0.8, n_estimators: 50, max_depth: 4, max_delta_step: 1, learning_rate: 0.1, gamma: 0.1\n",
      "Rank 9: mean_test_precision_weighted 0.2581, Parameters: subsample: 0.8, n_estimators: 150, max_depth: 4, max_delta_step: 1, learning_rate: 0.1, gamma: 0.1\n",
      "Rank 10: mean_test_precision_weighted 0.2581, Parameters: subsample: 0.8, n_estimators: 100, max_depth: 4, max_delta_step: 1, learning_rate: 0.1, gamma: 0.0\n",
      "Rank 11: mean_test_precision_weighted 0.2581, Parameters: subsample: 0.8, n_estimators: 50, max_depth: 4, max_delta_step: 1, learning_rate: 0.1, gamma: 0.0\n",
      "Rank 12: mean_test_precision_weighted 0.2580, Parameters: subsample: 0.8, n_estimators: 150, max_depth: 5, max_delta_step: 1, learning_rate: 0.1, gamma: 0.1\n",
      "Rank 13: mean_test_precision_weighted 0.2569, Parameters: subsample: 1.0, n_estimators: 100, max_depth: 5, max_delta_step: 1, learning_rate: 0.1, gamma: 0.0\n",
      "Rank 14: mean_test_precision_weighted 0.2559, Parameters: subsample: 0.5, n_estimators: 100, max_depth: 4, max_delta_step: 1, learning_rate: 0.1, gamma: 0.1\n",
      "Rank 15: mean_test_precision_weighted 0.2559, Parameters: subsample: 0.5, n_estimators: 50, max_depth: 4, max_delta_step: 1, learning_rate: 0.1, gamma: 0.0\n",
      "Rank 16: mean_test_precision_weighted 0.2549, Parameters: subsample: 0.5, n_estimators: 50, max_depth: 2, max_delta_step: 1, learning_rate: 0.1, gamma: 0.1\n",
      "Rank 17: mean_test_precision_weighted 0.2540, Parameters: subsample: 0.5, n_estimators: 100, max_depth: 4, max_delta_step: 0, learning_rate: 0.1, gamma: 0.0\n",
      "Rank 18: mean_test_precision_weighted 0.2531, Parameters: subsample: 0.5, n_estimators: 50, max_depth: 3, max_delta_step: 0, learning_rate: 0.1, gamma: 0.1\n",
      "Rank 19: mean_test_precision_weighted 0.2478, Parameters: subsample: 0.8, n_estimators: 150, max_depth: 2, max_delta_step: 1, learning_rate: 0.1, gamma: 0.0\n",
      "Rank 20: mean_test_precision_weighted 0.2478, Parameters: subsample: 0.8, n_estimators: 100, max_depth: 2, max_delta_step: 1, learning_rate: 0.1, gamma: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rnd_key=28\n",
    "n_jobs=2\n",
    "\n",
    "col_y_train_int = col_y_train.to_numpy().astype(int)\n",
    "col_y_val_int = col_y_val.to_numpy().astype(int)\n",
    "\n",
    "time_split = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "eval_set=[(df_x_val, col_y_val_int)]\n",
    "\n",
    "print(f\"{df_x_train.shape=} {df_x_val.shape=} {col_y_train_int.size=} {col_y_val_int.size=}\")\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': metrics.make_scorer(metrics.accuracy_score),\n",
    "    'precision_weighted': metrics.make_scorer(metrics.precision_score, average='weighted'),\n",
    "    'recall_weighted': metrics.make_scorer(metrics.recall_score, average='weighted'),\n",
    "    'f1_weighted': metrics.make_scorer(metrics.f1_score, average='weighted')\n",
    "}\n",
    "\n",
    "\n",
    "grid = {\n",
    "    # default 1 subsample ratio of columns when constructing each tree\n",
    "    # \"colsample_bytree\": [x for x in np.linspace(0.5, 1.0, num=6, endpoint=True)],\n",
    "    # \"colsample_bylevel\": [x for x in np.linspace(0.5, 1.0, num=6, endpoint=True)],\n",
    "    # \"colsample_bynode\": [x for x in np.linspace(0.5, 1.0, num=6, endpoint=True)],\n",
    "    # default 0 minimum loss reduction to make a further patition on a leaf [x for x in np.linspace(0, 0.1, num=2, endpoint=True)]\n",
    "    \"gamma\": [0],\n",
    "    # [x for x in np.linspace(0.01, 0.3, num=8, endpoint=True)],  # default 0.1 [0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3],\n",
    "    \"learning_rate\": [0.1],\n",
    "    # default 6 max depth of the tree \n",
    "    \"max_depth\": [int(x) for x in np.linspace(5, 7, num=3, endpoint=True, dtype=int)],\n",
    "    # default 100\n",
    "    \"n_estimators\": [int(x) for x in np.linspace(start=50, stop=150, num=3, endpoint=True, dtype=int)],\n",
    "    # default 1 subsample ratio of the training instances\n",
    "    # [x for x in np.linspace(0.6, 1.0, num=3, endpoint=True)],[0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 1.0],\n",
    "    \"subsample\": [1.0],\n",
    "    # default 1 minimum sum of instance weight needed in a child\n",
    "    # \"min_child_weight\": [x for x in np.linspace(0.5, 3, num=6, endpoint=True)],\n",
    "    # default 0 Maximum delta step we allow each leaf output to be.\n",
    "    \"max_delta_step\": [0]\n",
    "    # default 1 L2 regularization term on weights. Increasing this value will make model more conservative.\n",
    "    #\"lambda\": [0.5, 1, 1.5, 2],\n",
    "    # default 0 L1 regularization term on weights. Increasing this value will make model more conservative.\n",
    "    #\"alpha\": [0, 0.25, 0.5, 0.75, 1, 1.5, 2]\n",
    "\n",
    "}\n",
    "\n",
    "xgb_class = xgb.XGBClassifier(objective='multi:softmax', num_class=5,early_stopping_rounds=5,eval_metric='merror')\n",
    "#9min pour 1 cas\n",
    "xgb_fitted = modmgr.search_cv_fit_report(estimator=xgb_class, params=grid,\n",
    "                                         x_train=df_x_train, y_train=col_y_train_int,cv=time_split,eval_set=eval_set,\n",
    "                                           n_iter=20, n_top=10, method='grid', scoring=scoring, refit='precision_weighted',n_jobs=n_jobs)\n",
    "\n",
    "mean_test_precision_weighted = xgb_fitted.cv_results_['mean_test_precision_weighted']\n",
    "params=xgb_fitted.cv_results_['params']\n",
    "\n",
    "ranked=np.argsort(-mean_test_precision_weighted)\n",
    "\n",
    "for rank,score_idx in enumerate(ranked):\n",
    "    if rank<20:\n",
    "        params_str = ', '.join(f\"{param}: {value}\" for param, value in params[score_idx].items())\n",
    "        print(f\"Rank {rank+1}: mean_test_precision_weighted {mean_test_precision_weighted[score_idx]:.4f}, Parameters: {params_str}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
