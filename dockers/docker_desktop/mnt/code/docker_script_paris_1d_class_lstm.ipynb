{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 07:44:31.995430: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Bidirectional, Dropout, Activation, Dense, LSTM\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier as scikeras_KerasClassifier\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../dataset_mngr'))\n",
    "\n",
    "import split_merge as sm\n",
    "import balance_light as balance\n",
    "import model_mngr as modmgr\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "PATH_DATA = \"/Data\"\n",
    "PATH_DATA_DTS=PATH_DATA+\"/DTS_FULL/\"\n",
    "PATH_MODELS= \"/usr/local/models/\"\n",
    "\n",
    "SUFFIX_TRAIN=\"_TRAIN.zip\"\n",
    "SUFFIX_VAL=\"_VAL.zip\"\n",
    "SUFFIX_CONF=\"_CONF.zip\"\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update and save the scaler if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "dts_name=\"PARIS_TREND_1D_20D_V2\"\n",
    "multi_symbol=\"PARIS_STOCK\"\n",
    "label = \"lab_perf_20d\"\n",
    "\n",
    "df_class=pd.read_csv(PATH_DATA_DTS+dts_name+SUFFIX_TRAIN,sep=\",\",index_col=[\"OPEN_DATETIME\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "df_class=df_class.dropna(subset=[label])\n",
    "df_class=df_class.sort_index()\n",
    "\n",
    "df_norm,norm_scaler= balance.normalize_df(df_in=df_class,str_label=label,tuple_ft_range=(-1,1))\n",
    "\n",
    "file_name=dts_name+\"_train_colab_lstm_norm_2405\"\n",
    "scaler_name=file_name+\"_scaler.save\"\n",
    "joblib.dump(norm_scaler,filename=PATH_MODELS+scaler_name)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train et val df, normalize,  undersample  and preparation for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "dts_name=\"PARIS_TREND_1D_20D_V2\"\n",
    "multi_symbol=\"PARIS_STOCK\"\n",
    "label = \"lab_perf_20d\"\n",
    "file_name=dts_name+\"_train_colab_lstm_norm_2405\"\n",
    "scaler_name=file_name+\"_scaler.save\"\n",
    "scaler=joblib.load(PATH_MODELS+scaler_name)\n",
    "\n",
    "\n",
    "df_class=pd.read_csv(PATH_DATA_DTS+dts_name+SUFFIX_TRAIN,sep=\",\",index_col=[\"OPEN_DATETIME\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "df_class=df_class.dropna(subset=[label])\n",
    "df_class=df_class.loc['1995-01-01':] # drop rows < 1995-01-01\n",
    "df_class=df_class.sort_index()\n",
    "df_class_val=pd.read_csv(PATH_DATA_DTS+dts_name+SUFFIX_VAL,sep=\",\",index_col=[\"OPEN_DATETIME\"],parse_dates=[\"OPEN_DATETIME\"])\n",
    "df_class_val=df_class_val.dropna(subset=[label])\n",
    "df_class_val=df_class_val.sort_index()\n",
    "\n",
    "# normalize df_class and df_class_val\n",
    "df_class_train_norm=balance.normalize_df_scaler(df_in=df_class, str_label=label,scaler=scaler)\n",
    "df_class_val_norm=balance.normalize_df_scaler(df_in=df_class_val, str_label=label,scaler=scaler)\n",
    "\n",
    "list_feat = df_class.columns.values.tolist()\n",
    "list_feat.remove(label)\n",
    "\n",
    "# nb_val=211000 #211000\n",
    "# df_class_train_norm=balance.class_custom_undersampler(df_class_train_norm,label,nb_val)\n",
    "df_x_train, col_y_train = sm.split_df_x_y(\n",
    "    df_in=df_class_train_norm, list_features=list_feat, str_label=label, drop_na=True)\n",
    "# print(col_y_train.value_counts().sort_index())\n",
    "\n",
    "# nb_val=53000#53000\n",
    "# df_class_val_norm=balance.class_custom_undersampler(df_class_val_norm,label,nb_val)\n",
    "df_x_val, col_y_val = sm.split_df_x_y(\n",
    "    df_in=df_class_val_norm, list_features=list_feat, str_label=label, drop_na=True)\n",
    "\n",
    "sequence_length = 10\n",
    "\n",
    "x_train=df_x_train.values\n",
    "y_train=col_y_train.values\n",
    "x_val=df_x_val.values\n",
    "y_val=col_y_val.values\n",
    "x_train_lstm,y_train_lstm=sm.prepare_sequences(x_train,y_train,sequence_length)\n",
    "x_val_lstm,y_val_lstm=sm.prepare_sequences(x_val,y_val,sequence_length)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "check_class_limit=34959.45\n",
      "device_name='/device:GPU:0'\n",
      "{'fit__batch_size': 4096, 'model__dropout': 0.05, 'model__layers': [128, 20], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 07:45:55.822349: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 07:45:55.928230: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 07:45:55.928276: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 07:45:55.931906: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 07:45:55.931966: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 07:45:55.932006: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 07:45:56.199711: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 07:45:56.199768: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 07:45:56.199781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 07:45:56.199820: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 07:45:56.200622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1962 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers=[128, 20] meta={'classes_': array([0, 1, 2, 3]), 'target_type_': 'multilabel-indicator', 'y_dtype_': dtype('bool'), 'y_ndim_': 2, 'X_dtype_': dtype('float64'), 'X_shape_': (837045, 10, 27), 'n_features_in_': 10, 'target_encoder_': ClassifierLabelEncoder(), 'n_classes_': 4, 'n_outputs_': 1, 'n_outputs_expected_': 1, 'feature_encoder_': FunctionTransformer()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-06-09 07:46:00.510895: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 904008600 exceeds 10% of free system memory.\n",
      "2024-06-09 07:46:02.461662: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 904008600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 07:46:10.549102: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.2835 - loss: 1.3792"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 07:46:27.794930: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 251708040 exceeds 10% of free system memory.\n",
      "2024-06-09 07:46:27.986799: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 251708040 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 96ms/step - accuracy: 0.2835 - loss: 1.3792 - val_accuracy: 0.2830 - val_loss: 1.3703\n",
      "Epoch 2/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 88ms/step - accuracy: 0.3079 - loss: 1.3596 - val_accuracy: 0.3193 - val_loss: 1.3538\n",
      "Epoch 3/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3213 - loss: 1.3496 - val_accuracy: 0.3284 - val_loss: 1.3520\n",
      "Epoch 4/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 88ms/step - accuracy: 0.3244 - loss: 1.3481 - val_accuracy: 0.3276 - val_loss: 1.3515\n",
      "Epoch 5/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3274 - loss: 1.3459 - val_accuracy: 0.3224 - val_loss: 1.3562\n",
      "Epoch 6/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 89ms/step - accuracy: 0.3299 - loss: 1.3443 - val_accuracy: 0.3234 - val_loss: 1.3539\n",
      "Epoch 7/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3310 - loss: 1.3431 - val_accuracy: 0.3232 - val_loss: 1.3539\n",
      "Epoch 8/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 89ms/step - accuracy: 0.3330 - loss: 1.3424 - val_accuracy: 0.3233 - val_loss: 1.3538\n",
      "Epoch 9/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 88ms/step - accuracy: 0.3344 - loss: 1.3407 - val_accuracy: 0.3182 - val_loss: 1.3553\n",
      "Epoch 9: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 07:48:58.483624: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 251708040 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7284/7284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 18ms/step\n",
      "Accuracy on Validation Set: 0.3275938265619167 cpt=1\n",
      "layers=[128, 20] meta={'classes_': array([0, 1, 2, 3]), 'target_type_': 'multilabel-indicator', 'y_dtype_': dtype('bool'), 'y_ndim_': 2, 'X_dtype_': dtype('float64'), 'X_shape_': (837045, 10, 27), 'n_features_in_': 10, 'target_encoder_': ClassifierLabelEncoder(), 'n_classes_': 4, 'n_outputs_': 1, 'n_outputs_expected_': 1, 'feature_encoder_': FunctionTransformer()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 93ms/step - accuracy: 0.2817 - loss: 1.3790 - val_accuracy: 0.3027 - val_loss: 1.3609\n",
      "Epoch 2/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3123 - loss: 1.3569 - val_accuracy: 0.3076 - val_loss: 1.3579\n",
      "Epoch 3/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3226 - loss: 1.3492 - val_accuracy: 0.3246 - val_loss: 1.3519\n",
      "Epoch 4/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 86ms/step - accuracy: 0.3257 - loss: 1.3469 - val_accuracy: 0.3289 - val_loss: 1.3517\n",
      "Epoch 5/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 86ms/step - accuracy: 0.3280 - loss: 1.3447 - val_accuracy: 0.3185 - val_loss: 1.3566\n",
      "Epoch 6/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3297 - loss: 1.3437 - val_accuracy: 0.3304 - val_loss: 1.3504\n",
      "Epoch 7/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3316 - loss: 1.3426 - val_accuracy: 0.3250 - val_loss: 1.3548\n",
      "Epoch 8/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3331 - loss: 1.3417 - val_accuracy: 0.3298 - val_loss: 1.3525\n",
      "Epoch 9/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 88ms/step - accuracy: 0.3355 - loss: 1.3406 - val_accuracy: 0.3076 - val_loss: 1.3619\n",
      "Epoch 10/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 88ms/step - accuracy: 0.3362 - loss: 1.3391 - val_accuracy: 0.3149 - val_loss: 1.3592\n",
      "Epoch 11/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 88ms/step - accuracy: 0.3390 - loss: 1.3376 - val_accuracy: 0.3183 - val_loss: 1.3592\n",
      "Epoch 11: early stopping\n",
      "\u001b[1m7284/7284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 19ms/step\n",
      "Accuracy on Validation Set: 0.3304256788936897 cpt=2\n",
      "layers=[128, 20] meta={'classes_': array([0, 1, 2, 3]), 'target_type_': 'multilabel-indicator', 'y_dtype_': dtype('bool'), 'y_ndim_': 2, 'X_dtype_': dtype('float64'), 'X_shape_': (837045, 10, 27), 'n_features_in_': 10, 'target_encoder_': ClassifierLabelEncoder(), 'n_classes_': 4, 'n_outputs_': 1, 'n_outputs_expected_': 1, 'feature_encoder_': FunctionTransformer()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 101ms/step - accuracy: 0.2821 - loss: 1.3789 - val_accuracy: 0.3027 - val_loss: 1.3670\n",
      "Epoch 2/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 88ms/step - accuracy: 0.3105 - loss: 1.3580 - val_accuracy: 0.3198 - val_loss: 1.3546\n",
      "Epoch 3/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 86ms/step - accuracy: 0.3224 - loss: 1.3494 - val_accuracy: 0.3173 - val_loss: 1.3547\n",
      "Epoch 4/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 86ms/step - accuracy: 0.3249 - loss: 1.3466 - val_accuracy: 0.3268 - val_loss: 1.3524\n",
      "Epoch 5/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3279 - loss: 1.3446 - val_accuracy: 0.3260 - val_loss: 1.3506\n",
      "Epoch 6/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 86ms/step - accuracy: 0.3303 - loss: 1.3436 - val_accuracy: 0.3265 - val_loss: 1.3519\n",
      "Epoch 7/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 87ms/step - accuracy: 0.3320 - loss: 1.3420 - val_accuracy: 0.3213 - val_loss: 1.3569\n",
      "Epoch 8/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 89ms/step - accuracy: 0.3339 - loss: 1.3418 - val_accuracy: 0.3176 - val_loss: 1.3577\n",
      "Epoch 9/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 91ms/step - accuracy: 0.3348 - loss: 1.3403 - val_accuracy: 0.3266 - val_loss: 1.3557\n",
      "Epoch 10/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 89ms/step - accuracy: 0.3382 - loss: 1.3387 - val_accuracy: 0.3195 - val_loss: 1.3567\n",
      "Epoch 10: early stopping\n",
      "\u001b[1m7284/7284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 17ms/step\n",
      "Accuracy on Validation Set: 0.3259805288698764 cpt=3\n",
      "layers=[128, 20] meta={'classes_': array([0, 1, 2, 3]), 'target_type_': 'multilabel-indicator', 'y_dtype_': dtype('bool'), 'y_ndim_': 2, 'X_dtype_': dtype('float64'), 'X_shape_': (837045, 10, 27), 'n_features_in_': 10, 'target_encoder_': ClassifierLabelEncoder(), 'n_classes_': 4, 'n_outputs_': 1, 'n_outputs_expected_': 1, 'feature_encoder_': FunctionTransformer()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 95ms/step - accuracy: 0.2815 - loss: 1.3792 - val_accuracy: 0.3001 - val_loss: 1.3626\n",
      "Epoch 2/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 89ms/step - accuracy: 0.3095 - loss: 1.3586 - val_accuracy: 0.3053 - val_loss: 1.3615\n",
      "Epoch 3/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 88ms/step - accuracy: 0.3205 - loss: 1.3502 - val_accuracy: 0.3162 - val_loss: 1.3578\n",
      "Epoch 4/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 89ms/step - accuracy: 0.3252 - loss: 1.3467 - val_accuracy: 0.3269 - val_loss: 1.3509\n",
      "Epoch 5/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 88ms/step - accuracy: 0.3273 - loss: 1.3456 - val_accuracy: 0.3207 - val_loss: 1.3566\n",
      "Epoch 6/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 89ms/step - accuracy: 0.3306 - loss: 1.3439 - val_accuracy: 0.3252 - val_loss: 1.3526\n",
      "Epoch 7/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 88ms/step - accuracy: 0.3296 - loss: 1.3436 - val_accuracy: 0.3249 - val_loss: 1.3541\n",
      "Epoch 8/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 89ms/step - accuracy: 0.3330 - loss: 1.3419 - val_accuracy: 0.3180 - val_loss: 1.3582\n",
      "Epoch 9/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 88ms/step - accuracy: 0.3348 - loss: 1.3406 - val_accuracy: 0.3241 - val_loss: 1.3592\n",
      "Epoch 9: early stopping\n",
      "\u001b[1m7284/7284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 19ms/step\n",
      "Accuracy on Validation Set: 0.3268515379961641 cpt=4\n",
      "layers=[128, 20] meta={'classes_': array([0, 1, 2, 3]), 'target_type_': 'multilabel-indicator', 'y_dtype_': dtype('bool'), 'y_ndim_': 2, 'X_dtype_': dtype('float64'), 'X_shape_': (837045, 10, 27), 'n_features_in_': 10, 'target_encoder_': ClassifierLabelEncoder(), 'n_classes_': 4, 'n_outputs_': 1, 'n_outputs_expected_': 1, 'feature_encoder_': FunctionTransformer()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 96ms/step - accuracy: 0.2823 - loss: 1.3793 - val_accuracy: 0.3040 - val_loss: 1.3623\n",
      "Epoch 2/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 89ms/step - accuracy: 0.3116 - loss: 1.3571 - val_accuracy: 0.3189 - val_loss: 1.3545\n",
      "Epoch 3/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 89ms/step - accuracy: 0.3210 - loss: 1.3496 - val_accuracy: 0.3162 - val_loss: 1.3553\n",
      "Epoch 4/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 89ms/step - accuracy: 0.3258 - loss: 1.3471 - val_accuracy: 0.3287 - val_loss: 1.3516\n",
      "Epoch 5/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 88ms/step - accuracy: 0.3279 - loss: 1.3452 - val_accuracy: 0.3163 - val_loss: 1.3570\n",
      "Epoch 6/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 89ms/step - accuracy: 0.3296 - loss: 1.3441 - val_accuracy: 0.3225 - val_loss: 1.3562\n",
      "Epoch 7/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 89ms/step - accuracy: 0.3305 - loss: 1.3437 - val_accuracy: 0.3318 - val_loss: 1.3501\n",
      "Epoch 8/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 89ms/step - accuracy: 0.3346 - loss: 1.3416 - val_accuracy: 0.3229 - val_loss: 1.3591\n",
      "Epoch 9/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 90ms/step - accuracy: 0.3345 - loss: 1.3411 - val_accuracy: 0.3246 - val_loss: 1.3554\n",
      "Epoch 10/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 89ms/step - accuracy: 0.3353 - loss: 1.3404 - val_accuracy: 0.3173 - val_loss: 1.3606\n",
      "Epoch 11/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 89ms/step - accuracy: 0.3378 - loss: 1.3383 - val_accuracy: 0.3104 - val_loss: 1.3623\n",
      "Epoch 12/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 89ms/step - accuracy: 0.3400 - loss: 1.3374 - val_accuracy: 0.3174 - val_loss: 1.3581\n",
      "Epoch 12: early stopping\n",
      "\u001b[1m7284/7284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 20ms/step\n",
      "Accuracy on Validation Set: 0.33178582615001095 cpt=5\n",
      "layers=[128, 20] meta={'classes_': array([0, 1, 2, 3]), 'target_type_': 'multilabel-indicator', 'y_dtype_': dtype('bool'), 'y_ndim_': 2, 'X_dtype_': dtype('float64'), 'X_shape_': (837045, 10, 27), 'n_features_in_': 10, 'target_encoder_': ClassifierLabelEncoder(), 'n_classes_': 4, 'n_outputs_': 1, 'n_outputs_expected_': 1, 'feature_encoder_': FunctionTransformer()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 93ms/step - accuracy: 0.2830 - loss: 1.3790 - val_accuracy: 0.3044 - val_loss: 1.3616\n",
      "Epoch 2/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 87ms/step - accuracy: 0.3109 - loss: 1.3575 - val_accuracy: 0.3050 - val_loss: 1.3562\n",
      "Epoch 3/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3218 - loss: 1.3496 - val_accuracy: 0.3204 - val_loss: 1.3532\n",
      "Epoch 4/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 87ms/step - accuracy: 0.3246 - loss: 1.3470 - val_accuracy: 0.3220 - val_loss: 1.3538\n",
      "Epoch 5/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3271 - loss: 1.3452 - val_accuracy: 0.3116 - val_loss: 1.3572\n",
      "Epoch 6/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3290 - loss: 1.3443 - val_accuracy: 0.3283 - val_loss: 1.3511\n",
      "Epoch 7/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3307 - loss: 1.3428 - val_accuracy: 0.3249 - val_loss: 1.3527\n",
      "Epoch 8/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3330 - loss: 1.3420 - val_accuracy: 0.3258 - val_loss: 1.3551\n",
      "Epoch 9/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3343 - loss: 1.3401 - val_accuracy: 0.3242 - val_loss: 1.3546\n",
      "Epoch 10/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 87ms/step - accuracy: 0.3355 - loss: 1.3394 - val_accuracy: 0.3163 - val_loss: 1.3560\n",
      "Epoch 11/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3380 - loss: 1.3384 - val_accuracy: 0.3175 - val_loss: 1.3573\n",
      "Epoch 11: early stopping\n",
      "\u001b[1m7284/7284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 17ms/step\n",
      "Accuracy on Validation Set: 0.32830608033021114 cpt=6\n",
      "layers=[128, 20] meta={'classes_': array([0, 1, 2, 3]), 'target_type_': 'multilabel-indicator', 'y_dtype_': dtype('bool'), 'y_ndim_': 2, 'X_dtype_': dtype('float64'), 'X_shape_': (837045, 10, 27), 'n_features_in_': 10, 'target_encoder_': ClassifierLabelEncoder(), 'n_classes_': 4, 'n_outputs_': 1, 'n_outputs_expected_': 1, 'feature_encoder_': FunctionTransformer()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 93ms/step - accuracy: 0.2834 - loss: 1.3787 - val_accuracy: 0.2966 - val_loss: 1.3671\n",
      "Epoch 2/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3071 - loss: 1.3606 - val_accuracy: 0.3179 - val_loss: 1.3596\n",
      "Epoch 3/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 88ms/step - accuracy: 0.3224 - loss: 1.3497 - val_accuracy: 0.3249 - val_loss: 1.3519\n",
      "Epoch 4/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3264 - loss: 1.3468 - val_accuracy: 0.3206 - val_loss: 1.3531\n",
      "Epoch 5/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3279 - loss: 1.3453 - val_accuracy: 0.3202 - val_loss: 1.3559\n",
      "Epoch 6/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3304 - loss: 1.3435 - val_accuracy: 0.3324 - val_loss: 1.3506\n",
      "Epoch 7/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3315 - loss: 1.3431 - val_accuracy: 0.3212 - val_loss: 1.3569\n",
      "Epoch 8/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3340 - loss: 1.3413 - val_accuracy: 0.3288 - val_loss: 1.3517\n",
      "Epoch 9/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3356 - loss: 1.3401 - val_accuracy: 0.3252 - val_loss: 1.3554\n",
      "Epoch 10/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3359 - loss: 1.3397 - val_accuracy: 0.3225 - val_loss: 1.3552\n",
      "Epoch 11/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3383 - loss: 1.3375 - val_accuracy: 0.3203 - val_loss: 1.3572\n",
      "Epoch 11: early stopping\n",
      "\u001b[1m7284/7284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 18ms/step\n",
      "Accuracy on Validation Set: 0.3323564873017167 cpt=7\n",
      "layers=[128, 20] meta={'classes_': array([0, 1, 2, 3]), 'target_type_': 'multilabel-indicator', 'y_dtype_': dtype('bool'), 'y_ndim_': 2, 'X_dtype_': dtype('float64'), 'X_shape_': (837045, 10, 27), 'n_features_in_': 10, 'target_encoder_': ClassifierLabelEncoder(), 'n_classes_': 4, 'n_outputs_': 1, 'n_outputs_expected_': 1, 'feature_encoder_': FunctionTransformer()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 93ms/step - accuracy: 0.2837 - loss: 1.3792 - val_accuracy: 0.2830 - val_loss: 1.3693\n",
      "Epoch 2/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 88ms/step - accuracy: 0.3098 - loss: 1.3589 - val_accuracy: 0.3182 - val_loss: 1.3541\n",
      "Epoch 3/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3221 - loss: 1.3497 - val_accuracy: 0.3274 - val_loss: 1.3512\n",
      "Epoch 4/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3259 - loss: 1.3466 - val_accuracy: 0.3225 - val_loss: 1.3543\n",
      "Epoch 5/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3280 - loss: 1.3455 - val_accuracy: 0.3272 - val_loss: 1.3534\n",
      "Epoch 6/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 87ms/step - accuracy: 0.3301 - loss: 1.3437 - val_accuracy: 0.3207 - val_loss: 1.3562\n",
      "Epoch 7/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 88ms/step - accuracy: 0.3319 - loss: 1.3428 - val_accuracy: 0.3253 - val_loss: 1.3549\n",
      "Epoch 8/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3326 - loss: 1.3417 - val_accuracy: 0.3097 - val_loss: 1.3613\n",
      "Epoch 8: early stopping\n",
      "\u001b[1m7284/7284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 17ms/step\n",
      "Accuracy on Validation Set: 0.3273792922943582 cpt=8\n",
      "layers=[128, 20] meta={'classes_': array([0, 1, 2, 3]), 'target_type_': 'multilabel-indicator', 'y_dtype_': dtype('bool'), 'y_ndim_': 2, 'X_dtype_': dtype('float64'), 'X_shape_': (837045, 10, 27), 'n_features_in_': 10, 'target_encoder_': ClassifierLabelEncoder(), 'n_classes_': 4, 'n_outputs_': 1, 'n_outputs_expected_': 1, 'feature_encoder_': FunctionTransformer()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 93ms/step - accuracy: 0.2845 - loss: 1.3779 - val_accuracy: 0.3029 - val_loss: 1.3607\n",
      "Epoch 2/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3110 - loss: 1.3566 - val_accuracy: 0.3200 - val_loss: 1.3564\n",
      "Epoch 3/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 86ms/step - accuracy: 0.3211 - loss: 1.3487 - val_accuracy: 0.3192 - val_loss: 1.3574\n",
      "Epoch 4/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 86ms/step - accuracy: 0.3253 - loss: 1.3465 - val_accuracy: 0.3213 - val_loss: 1.3551\n",
      "Epoch 5/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3283 - loss: 1.3451 - val_accuracy: 0.3195 - val_loss: 1.3576\n",
      "Epoch 6/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 87ms/step - accuracy: 0.3301 - loss: 1.3438 - val_accuracy: 0.3278 - val_loss: 1.3518\n",
      "Epoch 7/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3328 - loss: 1.3419 - val_accuracy: 0.3274 - val_loss: 1.3526\n",
      "Epoch 8/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3346 - loss: 1.3413 - val_accuracy: 0.3147 - val_loss: 1.3587\n",
      "Epoch 9/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3345 - loss: 1.3406 - val_accuracy: 0.3128 - val_loss: 1.3605\n",
      "Epoch 10/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 87ms/step - accuracy: 0.3368 - loss: 1.3392 - val_accuracy: 0.3222 - val_loss: 1.3591\n",
      "Epoch 11/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3379 - loss: 1.3383 - val_accuracy: 0.3162 - val_loss: 1.3611\n",
      "Epoch 11: early stopping\n",
      "\u001b[1m7284/7284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 17ms/step\n",
      "Accuracy on Validation Set: 0.32776974466131475 cpt=9\n",
      "layers=[128, 20] meta={'classes_': array([0, 1, 2, 3]), 'target_type_': 'multilabel-indicator', 'y_dtype_': dtype('bool'), 'y_ndim_': 2, 'X_dtype_': dtype('float64'), 'X_shape_': (837045, 10, 27), 'n_features_in_': 10, 'target_encoder_': ClassifierLabelEncoder(), 'n_classes_': 4, 'n_outputs_': 1, 'n_outputs_expected_': 1, 'feature_encoder_': FunctionTransformer()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 93ms/step - accuracy: 0.2790 - loss: 1.3805 - val_accuracy: 0.2910 - val_loss: 1.3688\n",
      "Epoch 2/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3072 - loss: 1.3612 - val_accuracy: 0.3084 - val_loss: 1.3622\n",
      "Epoch 3/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3216 - loss: 1.3498 - val_accuracy: 0.3251 - val_loss: 1.3529\n",
      "Epoch 4/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3251 - loss: 1.3478 - val_accuracy: 0.3272 - val_loss: 1.3526\n",
      "Epoch 5/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 86ms/step - accuracy: 0.3277 - loss: 1.3454 - val_accuracy: 0.3010 - val_loss: 1.3645\n",
      "Epoch 6/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3287 - loss: 1.3449 - val_accuracy: 0.3200 - val_loss: 1.3606\n",
      "Epoch 7/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3297 - loss: 1.3438 - val_accuracy: 0.3213 - val_loss: 1.3560\n",
      "Epoch 8/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3321 - loss: 1.3424 - val_accuracy: 0.3240 - val_loss: 1.3566\n",
      "Epoch 9/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.3337 - loss: 1.3417 - val_accuracy: 0.3252 - val_loss: 1.3540\n",
      "Epoch 9: early stopping\n",
      "\u001b[1m7284/7284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 18ms/step\n",
      "Accuracy on Validation Set: 0.32715617665609725 cpt=10\n",
      "Optim fail cpt=10 param suivant cpt_param=1\n",
      "{'fit__batch_size': 4096, 'model__dropout': 0.05, 'model__layers': [64, 10], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.9}\n",
      "layers=[64, 10] meta={'classes_': array([0, 1, 2, 3]), 'target_type_': 'multilabel-indicator', 'y_dtype_': dtype('bool'), 'y_ndim_': 2, 'X_dtype_': dtype('float64'), 'X_shape_': (837045, 10, 27), 'n_features_in_': 10, 'target_encoder_': ClassifierLabelEncoder(), 'n_classes_': 4, 'n_outputs_': 1, 'n_outputs_expected_': 1, 'feature_encoder_': FunctionTransformer()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 79ms/step - accuracy: 0.2805 - loss: 1.3795 - val_accuracy: 0.2860 - val_loss: 1.3687\n",
      "Epoch 2/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3057 - loss: 1.3619 - val_accuracy: 0.3135 - val_loss: 1.3546\n",
      "Epoch 3/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 73ms/step - accuracy: 0.3173 - loss: 1.3520 - val_accuracy: 0.3132 - val_loss: 1.3545\n",
      "Epoch 4/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3217 - loss: 1.3491 - val_accuracy: 0.3210 - val_loss: 1.3522\n",
      "Epoch 5/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3245 - loss: 1.3477 - val_accuracy: 0.3158 - val_loss: 1.3540\n",
      "Epoch 6/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3259 - loss: 1.3463 - val_accuracy: 0.3254 - val_loss: 1.3507\n",
      "Epoch 7/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 73ms/step - accuracy: 0.3273 - loss: 1.3452 - val_accuracy: 0.3145 - val_loss: 1.3563\n",
      "Epoch 8/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 73ms/step - accuracy: 0.3293 - loss: 1.3443 - val_accuracy: 0.3198 - val_loss: 1.3541\n",
      "Epoch 9/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3293 - loss: 1.3439 - val_accuracy: 0.3242 - val_loss: 1.3524\n",
      "Epoch 10/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3313 - loss: 1.3432 - val_accuracy: 0.3298 - val_loss: 1.3493\n",
      "Epoch 11/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3320 - loss: 1.3424 - val_accuracy: 0.3142 - val_loss: 1.3577\n",
      "Epoch 12/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3323 - loss: 1.3417 - val_accuracy: 0.3162 - val_loss: 1.3578\n",
      "Epoch 13/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 74ms/step - accuracy: 0.3341 - loss: 1.3405 - val_accuracy: 0.3236 - val_loss: 1.3552\n",
      "Epoch 14/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 73ms/step - accuracy: 0.3338 - loss: 1.3417 - val_accuracy: 0.3207 - val_loss: 1.3551\n",
      "Epoch 15/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3365 - loss: 1.3393 - val_accuracy: 0.3227 - val_loss: 1.3539\n",
      "Epoch 15: early stopping\n",
      "\u001b[1m7284/7284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 17ms/step\n",
      "Accuracy on Validation Set: 0.3298164015738234 cpt=1\n",
      "layers=[64, 10] meta={'classes_': array([0, 1, 2, 3]), 'target_type_': 'multilabel-indicator', 'y_dtype_': dtype('bool'), 'y_ndim_': 2, 'X_dtype_': dtype('float64'), 'X_shape_': (837045, 10, 27), 'n_features_in_': 10, 'target_encoder_': ClassifierLabelEncoder(), 'n_classes_': 4, 'n_outputs_': 1, 'n_outputs_expected_': 1, 'feature_encoder_': FunctionTransformer()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 84ms/step - accuracy: 0.2782 - loss: 1.3814 - val_accuracy: 0.2793 - val_loss: 1.3741\n",
      "Epoch 2/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 73ms/step - accuracy: 0.3013 - loss: 1.3661 - val_accuracy: 0.3110 - val_loss: 1.3571\n",
      "Epoch 3/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 73ms/step - accuracy: 0.3153 - loss: 1.3534 - val_accuracy: 0.3131 - val_loss: 1.3549\n",
      "Epoch 4/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 75ms/step - accuracy: 0.3194 - loss: 1.3500 - val_accuracy: 0.3170 - val_loss: 1.3553\n",
      "Epoch 5/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3244 - loss: 1.3478 - val_accuracy: 0.3209 - val_loss: 1.3526\n",
      "Epoch 6/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3239 - loss: 1.3476 - val_accuracy: 0.3270 - val_loss: 1.3512\n",
      "Epoch 7/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 74ms/step - accuracy: 0.3258 - loss: 1.3461 - val_accuracy: 0.3226 - val_loss: 1.3538\n",
      "Epoch 8/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 73ms/step - accuracy: 0.3281 - loss: 1.3451 - val_accuracy: 0.3207 - val_loss: 1.3524\n",
      "Epoch 9/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3297 - loss: 1.3437 - val_accuracy: 0.3196 - val_loss: 1.3546\n",
      "Epoch 10/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 73ms/step - accuracy: 0.3306 - loss: 1.3433 - val_accuracy: 0.3284 - val_loss: 1.3512\n",
      "Epoch 11/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 75ms/step - accuracy: 0.3306 - loss: 1.3429 - val_accuracy: 0.3212 - val_loss: 1.3563\n",
      "Epoch 12/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3331 - loss: 1.3418 - val_accuracy: 0.3247 - val_loss: 1.3535\n",
      "Epoch 13/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3341 - loss: 1.3405 - val_accuracy: 0.3186 - val_loss: 1.3555\n",
      "Epoch 14/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3349 - loss: 1.3401 - val_accuracy: 0.3207 - val_loss: 1.3554\n",
      "Epoch 15/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3353 - loss: 1.3397 - val_accuracy: 0.2987 - val_loss: 1.3658\n",
      "Epoch 15: early stopping\n",
      "\u001b[1m7284/7284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 18ms/step\n",
      "Accuracy on Validation Set: 0.3283704406104787 cpt=2\n",
      "layers=[64, 10] meta={'classes_': array([0, 1, 2, 3]), 'target_type_': 'multilabel-indicator', 'y_dtype_': dtype('bool'), 'y_ndim_': 2, 'X_dtype_': dtype('float64'), 'X_shape_': (837045, 10, 27), 'n_features_in_': 10, 'target_encoder_': ClassifierLabelEncoder(), 'n_classes_': 4, 'n_outputs_': 1, 'n_outputs_expected_': 1, 'feature_encoder_': FunctionTransformer()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 80ms/step - accuracy: 0.2764 - loss: 1.3815 - val_accuracy: 0.2851 - val_loss: 1.3749\n",
      "Epoch 2/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3022 - loss: 1.3663 - val_accuracy: 0.2987 - val_loss: 1.3615\n",
      "Epoch 3/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3175 - loss: 1.3527 - val_accuracy: 0.3119 - val_loss: 1.3573\n",
      "Epoch 4/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3228 - loss: 1.3480 - val_accuracy: 0.3181 - val_loss: 1.3542\n",
      "Epoch 5/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3251 - loss: 1.3470 - val_accuracy: 0.3134 - val_loss: 1.3567\n",
      "Epoch 6/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3270 - loss: 1.3451 - val_accuracy: 0.3211 - val_loss: 1.3543\n",
      "Epoch 7/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3282 - loss: 1.3444 - val_accuracy: 0.3229 - val_loss: 1.3526\n",
      "Epoch 8/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3280 - loss: 1.3443 - val_accuracy: 0.3225 - val_loss: 1.3551\n",
      "Epoch 9/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3321 - loss: 1.3419 - val_accuracy: 0.3249 - val_loss: 1.3525\n",
      "Epoch 10/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 73ms/step - accuracy: 0.3322 - loss: 1.3419 - val_accuracy: 0.3193 - val_loss: 1.3572\n",
      "Epoch 11/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 75ms/step - accuracy: 0.3328 - loss: 1.3414 - val_accuracy: 0.3233 - val_loss: 1.3558\n",
      "Epoch 12/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3335 - loss: 1.3406 - val_accuracy: 0.3134 - val_loss: 1.3582\n",
      "Epoch 13/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3359 - loss: 1.3400 - val_accuracy: 0.3237 - val_loss: 1.3547\n",
      "Epoch 14/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.3366 - loss: 1.3392 - val_accuracy: 0.3201 - val_loss: 1.3556\n",
      "Epoch 14: early stopping\n",
      "\u001b[1m7284/7284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 18ms/step\n",
      "Accuracy on Validation Set: 0.3249207295881371 cpt=3\n",
      "layers=[64, 10] meta={'classes_': array([0, 1, 2, 3]), 'target_type_': 'multilabel-indicator', 'y_dtype_': dtype('bool'), 'y_ndim_': 2, 'X_dtype_': dtype('float64'), 'X_shape_': (837045, 10, 27), 'n_features_in_': 10, 'target_encoder_': ClassifierLabelEncoder(), 'n_classes_': 4, 'n_outputs_': 1, 'n_outputs_expected_': 1, 'feature_encoder_': FunctionTransformer()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "print(\"Start\")\n",
    "list_param_valid = [\n",
    "                    {'fit__batch_size':4096, 'model__dropout': 0.05, 'model__layers': [128, 20], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.9},\n",
    "                    {'fit__batch_size':4096, 'model__dropout': 0.05, 'model__layers': [64, 10], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.9},\n",
    "                    # {'fit__batch_size': 32, 'fit__epochs': 350, 'model__dropout': 0.05, 'model__layers': [128, 20], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.7},\n",
    "                    # {'fit__batch_size': 32, 'fit__epochs': 350, 'model__dropout': 0.05, 'model__layers': [128, 20], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.5},\n",
    "                    # {'fit__batch_size': 64, 'fit__epochs': 350, 'model__dropout': 0.05, 'model__layers': [128, 20], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.9},\n",
    "                    # {'fit__batch_size': 64, 'fit__epochs': 350, 'model__dropout': 0.05, 'model__layers': [128, 20], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.7},\n",
    "                    # {'fit__batch_size': 64, 'fit__epochs': 350, 'model__dropout': 0.05, 'model__layers': [128, 20], 'optimizer__lr': 0.1, 'optimizer__momentum': 0.5},\n",
    "]\n",
    "\n",
    "input_dim = x_train.shape[-1]\n",
    "num_classes = 4\n",
    "epochs = 100#350\n",
    "suffix=\"lstm_v1\"\n",
    "filename_tmp_model =PATH_MODELS+dts_name+\"_\"+suffix+\".keras\"\n",
    "patience = 5\n",
    "device_name=\"GPU\"\n",
    "\n",
    "val_accuracy=0.0\n",
    "obj_acc=0.35\n",
    "cpt_param=0\n",
    "try_limit=10\n",
    "pct_check_class=0.6 # check if at least n% of the validation set per class\n",
    "\n",
    "len_val=len(x_val_lstm)\n",
    "check_class_limit=(len_val/num_classes)*pct_check_class\n",
    "check_class=False # check if at least obj_acc accuracy per class\n",
    "\n",
    "print(f\"{check_class_limit=}\")\n",
    "\n",
    "if device_name == \"GPU\":\n",
    "    device_name = \"/device:GPU:0\"\n",
    "else:\n",
    "    device_name = \"/device:CPU:0\"\n",
    "\n",
    "print(f\"{device_name=}\")\n",
    "\n",
    "with tf.device(device_name):\n",
    "    while(cpt_param<len(list_param_valid) and check_class==False):\n",
    "        param_valid=list_param_valid[cpt_param]\n",
    "        print(param_valid)\n",
    "        cpt=0\n",
    "    \n",
    "        while(cpt<try_limit and check_class==False):\n",
    "            cpt+=1\n",
    "            es = EarlyStopping(monitor=\"val_loss\", patience=patience, mode=\"min\", verbose=2)\n",
    "            mc = ModelCheckpoint(filename_tmp_model, monitor=\"val_loss\",\n",
    "                                mode=\"min\", save_freq=\"epoch\", save_best_only=True)\n",
    "            lstm_model = scikeras_KerasClassifier(model=modmgr.create_scikeras_lstm_model, optimizer=\"adam\",optimizer__momentum=param_valid['optimizer__momentum'],\n",
    "                                                optimizer__lr=param_valid['optimizer__lr'], model__layers=param_valid['model__layers'], model__dropout=param_valid['model__dropout'],\n",
    "                                                    callbacks=[es, mc], verbose=1)\n",
    "    \n",
    "            history = lstm_model.fit(\n",
    "                x_train_lstm, y_train_lstm, batch_size=param_valid['fit__batch_size'], epochs=epochs, validation_data=(x_val_lstm, y_val_lstm))\n",
    "    \n",
    "            train_loss = history.history_['loss']\n",
    "            val_loss = history.history_['val_loss']\n",
    "    \n",
    "            # Plot loss\n",
    "            # epochs_done = range(1, len(train_loss) + 1)\n",
    "            # plt.plot(epochs_done, train_loss, 'bo-', label='Training Loss')\n",
    "            # plt.plot(epochs_done, val_loss, 'ro-', label='Validation Loss')\n",
    "            # plt.legend()\n",
    "            # plt.show()\n",
    "    \n",
    "            saved_model = load_model(filename_tmp_model)\n",
    "            # saved_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['loss'])\n",
    "            # loss, accuracy = saved_model.evaluate(x_valid, y_valid)\n",
    "    \n",
    "            # Prediction on validation\n",
    "            y_pred = saved_model.predict(x_val_lstm)\n",
    "            y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "            # Accuracy on validation\n",
    "            val_accuracy = metrics.accuracy_score(y_val_lstm.argmax(axis=1), y_pred_classes)\n",
    "            print(f\"Accuracy on Validation Set: {val_accuracy} {cpt=}\")\n",
    "    \n",
    "            # check prediction au moins 30 par classe\n",
    "            if val_accuracy>=obj_acc:\n",
    "                check_class=True\n",
    "                for i in range(num_classes):\n",
    "                    nb_lab=sum(y_pred_classes == i)\n",
    "                    if nb_lab<check_class_limit  :\n",
    "                        check_class=False\n",
    "                        print(f\"Check class {i=} {nb_lab=} {check_class=} {check_class_limit=}\")\n",
    "    \n",
    "        if cpt>=try_limit :\n",
    "            cpt_param+=1\n",
    "            print(f\"Optim fail {cpt=} param suivant {cpt_param=}\")\n",
    "    \n",
    "    if cpt>=try_limit :\n",
    "        print(f\"Optim fail {cpt=}\")\n",
    "    \n",
    "    else :\n",
    "        confusion = metrics.confusion_matrix(y_val_lstm.argmax(axis=1), y_pred_classes)\n",
    "        print(confusion)\n",
    "    \n",
    "        for i in range(num_classes):\n",
    "            print(f\"Categ {i}: real {sum(y_val_lstm.argmax(axis=1) == i)} predict {sum(y_pred_classes == i)}\")\n",
    "    \n",
    "        #check saved model\n",
    "        saved_model = load_model(filename_tmp_model)\n",
    "        y_pred = saved_model.predict(x_val_lstm)\n",
    "        confusion = metrics.confusion_matrix(y_val_lstm.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "        print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_train.shape[-1]\n",
    "window_size = sequence_length\n",
    "dropout = 0.2\n",
    "num_classes = 4\n",
    "\n",
    "# cat_y_train = keras.utils.to_categorical(col_y_train, num_classes)\n",
    "# cat_y_valid = keras.utils.to_categorical(col_y_valid, num_classes)\n",
    "\n",
    "# df_x_train_exp = np.expand_dims(df_x_train, axis=2)\n",
    "# df_x_valid_exp = np.expand_dims(df_x_valid, axis=2)\n",
    "\n",
    "\n",
    "model_LSTM = Sequential()\n",
    "model_LSTM.add(LSTM(units=20, return_sequences=False,#True\n",
    "               input_shape=(window_size, input_dim)))\n",
    "#,kernel_regularizer=l2(0.1), recurrent_regularizer=l2(0.1), bias_regularizer=l2(0.1)\n",
    "model_LSTM.add(Dropout(rate=dropout))   \n",
    "# model_LSTM.add(Dropout(rate=dropout))\n",
    "# model_LSTM.add(Bidirectional(LSTM((window_size * 2), return_sequences=True)))\n",
    "# model_LSTM.add(Dropout(rate=dropout))\n",
    "# model_LSTM.add(Bidirectional(LSTM(window_size, return_sequences=False)))\n",
    "model_LSTM.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "model_LSTM.compile(loss='categorical_crossentropy',\n",
    "                   optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model_LSTM.fit(x_train_lstm, y_train_lstm, batch_size=1024,\n",
    "                         shuffle=False, epochs=20, validation_data=(x_val_lstm, y_val_lstm))#,verbose=0\n",
    "\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Plot loss\n",
    "epochs = range(1, len(train_accuracy) + 1)\n",
    "plt.plot(epochs, train_accuracy, 'bo-', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'ro-', label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12302096189872760406\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# print if keras can use the gpu to train the model\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
